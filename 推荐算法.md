
## 传统模型

### 矩阵分解模型


#### 问题阐述

假设有 $N$ 个用户和 $M$ 个物体，每个用户对于部分物体有一个评分（没有评的设置为 0），这样会生成一个 $N\times M$ 维的矩阵 $R$，这个矩阵中许多位置为0，为了预测这些位置的评分，可以使用矩阵分解算法。即初始化一个用户矩阵 $U\in R^{N\times d}$ 和物体矩阵 $P\in R^{d\times M}$，使得 $R- U\times P$ 的损失最小，优化的目标函数为

$$
\min \sum\limits_{{r_{nm}} \ne 0} {{{\left( {{r_{nm}} - u_n^T{p_m}} \right)}^2}}  + \lambda \left\| {{u_n}} \right\|_2^2
$$

其中 $\lambda \left\| {{u_n}} \right\|_2^2$ 为正则项，防止过拟合。

#### 求解方法

求解 $U$ 和 $P$ 可以通过交替最小二乘法（ALS），先固定 $U$ 优化 $P$，再固定 $P$ 优化 $U$。

（1）固定 $P$，优化 $U$

将 $P$ 当作常数，这样可以分成多个用户同时求解。目标函数为

$$
J({u_n}) = {\left( {{R_n} - P_n^T{u_n}} \right)^T}\left( {{R_n} - P_n^T{u_n}} \right) + \lambda u_n^T{u_n}
$$

其中，$R_n$ 是用户 $n$ 对 $m$ 个物体的评分构成的向量，$P_n$ 为这 $m$ 个物体向量构成的矩阵，顺序与 $R_n$ 中的物品的顺序一致。对目标函数求导，得到 $u_n$ 的解析解为

$$
{u_n} = {\left( {{P_n}P_n^T + \lambda I} \right)^{ - 1}}{I_n}{R_n}
$$

（2）固定 U，优化 P

同理可得 $p_m$ 的解析解为
$$
{p_m} = {\left( {{U_m}U_m^T + \lambda I} \right)^{ - 1}}{U_m}{R_m}
$$
其中 $R_m$ 是 n 个用户对于物品 m 的评分构成的向量，$U_m$ 为这 n 个用户的矩阵。

#### 隐式矩阵分解

隐式矩阵分解会拟合评分矩阵中的零，即没有评分也会去拟合。定义一个二值变量 $d_{nm}$ 表示用户的行为强度

$$
{d_{nm}} = \left\{ \matrix{
  1\quad {r_{nm}} > 0 \hfill \cr 
  0\quad {r_{nm}} = 0 \hfill \cr}  \right.
$$
定义一个置信度 $c_{nm}$

$$
{c_{nm}} = 1 + \alpha {r_{nm}}
$$
当 $r_{nm}>0$，$c_{nm}$ 关于 $r_{nm}$ 线性递增，即评分越高，置信度越大，而当 $r_{nm}=0$ 时，$c_{nm}$ 为 1，置信度相同。隐式矩阵分解的目标函数为

$$
\min \sum\limits_{n = 1}^N {\sum\limits_{m = 1}^M {{c_{nm}}{{\left( {{d_{nm}} - u_n^T{p_m}} \right)}^2}} }  + \lambda \left( {\sum\limits_{n = 1}^N {\left\| {{u_n}} \right\|_2^2}  + \sum\limits_{m = 1}^M {\left\| {{p_m}} \right\|_2^2} } \right)
$$
仍然可以通过交替最小二乘法求解。

#### 增量矩阵分解

为了解决新用户的问题，可以使用增量矩阵分解。只需要使用新用户的历史行为数据 $r_{nm}$ 和在训练集上学习到的物品矩阵 $P$，求解的用户向量为 $u'$

$$
\min \sum\limits_{m = 1}^M {{c_{nm}}{{\left( {{d_{nm}} - u{'^T}{p_m}} \right)}^2}}  + \lambda \left\| {u'} \right\|_2^2
$$
对于历史数据 $r_{nm}$ 要过滤掉在 $P$ 没有出现的物体，并且 $P$ 是固定的，不需要迭代。

