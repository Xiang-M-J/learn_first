
# onnxruntime



onnxruntime 是一个加速多种语言训练和推理的库，支持 Python、C++、C、C#、Java、JavaScript、Objective-C、Julia、Ruby 语言，支持Windows、Mobile 平台


> [!NOTE] 
> 如果想要导出别人的模型，注意别人的模型是否存在 export 函数，使用 export 函数可以方便导出


> [!WARNING] 
> 如果导出的模型体积很小，仅有 1 kB，这是由于没有导出模型的参数，可能是因为 forward 函数中返回的值没有包括（有参数）模型的输出，需要返回该输出


> [!DANGER] 
> ONNX 默认只会导出和模型参数有关的操作，在这种情况下，无论怎么修改 forward 函数，都不能得到与模型参数无关的数据，为了能够导出 forward 函数中的所有操作，需要在 export 时设置 `export_modules_as_functions=True`（设置这个似乎没有什么用），onnx 的输入只有模型的输入，强行添加输入似乎是无效的，并且相关的输出也是固定的




## 导出模型


### pytorch

```python
# Export the model
torch.onnx.export(model,             # model being run
                (text, offsets),     # model input (or a tuple for multiple inputs)
                "ag_news_model.onnx",  # where to save the model (can be a file or file-like object)
                export_params=True,  # store the trained parameter weights inside the model file
                opset_version=10,          # the ONNX version to export the model to
                do_constant_folding=True,  # whether to execute constant folding for optimization
                input_names = ['input', 'offsets'],   # the model's input names
                output_names = ['output'], # the model's output names
                dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes
                              'output' : {0 : 'batch_size'}})

```


### paddlepaddle

1. 使用自带的函数导出

```python
# export to ONNX
save_path = 'onnx.save/lenet' # 需要保存的路径
x_spec = paddle.static.InputSpec([None, 1, 28, 28], 'float32', 'x') # 为模型指定输入的形状和数据类型，支持持 Tensor 或 InputSpec ，InputSpec 支持动态的 shape。
paddle.onnx.export(lenet, save_path, input_spec=[x_spec], opset_version=11)
```


2. 使用 paddle2onnx 导出

需要先安装 paddle2onnx，pip install paddle2onnx

```python
paddle2onnx --model_dir mobilenetv3 --model_filename inference.pdmodel --params_filename inference.pdiparams --save_file model.onnx --enable_dev_version True --opset_version 13 --enable_onnx_checker True
```

pdmodel 和 pdiparams 文件可以通过下面的方法获得

```python
input_spec = [InputSpec(shape=(-1, -1), dtype=paddle.int64), InputSpec(shape=(-1, -1), dtype=paddle.int64)]
paddle.jit.save(layer=model, path=os.path.join(args.infer_model_path, 'model'), input_spec=input_spec)
```



## 推理

**使用 CPU 进行推理**

```python
options = ort.SessionOptions()  
options.inter_op_num_threads = 4  
options.intra_op_num_threads = 4  # 设置线程数可以加速推理
session = ort.InferenceSession("model.onnx", options)
onnx_inputs = {inp.name: input_feature for inp in self.session.get_inputs()}  
output = session.run(None, onnx_inputs)
```

**使用 GPU 进行推理**

```python
providers = [("CUDAExecutionProvider", {"use_tf32": 0})]
sess_options = ort.SessionOptions()
sess = ort.InferenceSession("my_model.onnx", sess_options=sess_options, providers=providers)
```


**使用 onnx 进行量化**

可以使用 onnxruntime.quantization 中的 quantize_dynamic 进行量化

```python
quantized_model = quantize_dynamic(model_fp32, model_quant,  
                                   op_types_to_quantize=["MatMul"],  
                                   per_channel=True,  
                                   reduce_range=False,  
                                   )
```

有时候使用 quantize_dynamic 量化后得到的模型无法正常使用，可能是因为没有设置 op_types_to_quantize.


# tensorflow

## 安装

> windows 平台的GPU版本只支持到 2.10.0


```powershell
pip install tensorflow-gpu==2.10.0
```

然后下载 cuda 和 cudnn，经过测试，cuda 的版本可以为 **11.8**，cudnn 下载完之后会有 bin, include 和 lib 三个文件夹，将这三个文件放在 cuda 安装位置对应的文件夹。

测试代码如下

```python
import tensorflow as tf
print(tf.config.list_physical_devices('GPU'))
```


## 训练模板

参考 [deepLearning_basic/tf_custom/main.py at main · Xiang-M-J/deepLearning_basic (github.com)](https://github.com/Xiang-M-J/deepLearning_basic/blob/main/tf_custom/main.py)




## 基础使用

### 张量

#### 创建张量

```python
# 创建一个张量
a = tf.constant(4) 
params = tf.constant([[1,2], [3,4],[5,6]], dtype=tf.float16) 
# 将列表转换成 Tensor
tf.convert_to_tensor([1,2,3])

# 创建零张量
zero1 = tf.zeros([1,2])
zero2 = tf.zeros_like(zero1)

# 创建随机张量
g1 = tf.random.Generator.from_seed(1)
g1.normal(shape=[2,3])
tf.random.normal([1,2])
# 创建随机整数（前包后不包）
tf.random.uniform(shape=(2,2), minval=1, maxval=5, dtype=tf.int32) 
```

#### 操作形状

```python
# 获取张量形状
x = tf.constant([[1], [2], [3]])
print(x.shape)

# reshape
reshaped = tf.reshape(x, [1, 3])
reshaped = tf.reshape(x, [-1])  # -1 表示展平
```

#### 广播

在大多数情况下，广播的时间和空间效率更高，因为广播运算不会在内存中具体化扩展的张量。

```python
print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))
```

```
tf.Tensor(
[[1 2 3]
 [1 2 3]
 [1 2 3]], shape=(3, 3), dtype=int32)
```

#### 稀疏张量

```python
# Sparse tensors store values by index in a memory-efficient manner
sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],
                                       values=[1, 2],
                                       dense_shape=[3, 4])

tf.sparse.to_dense(sparse_tensor)  # 转为 dense 张量
```

indices 每一行代表坐标，如 [[0, 0], [1, 2]] 表示有两个值，分别位于 (0,0) 和 (1,2)。

#### 张量操作

```python
a + b
a - b
a * b == tf.multiply(a, b)    # 点乘
a @ b == tf.matmul(a, b)      # 矩阵乘法
tf.transpose(a)               # 转置
tf.expand_dims(a, 1)          # 在维度 1 增加一个维度，该维度在维度 0 和维度 2 之间
tf.squeeze(a, 1)              # 删除维度 1
```



### 变量

要创建变量，请提供一个初始值。tf.Variable 与初始值的 dtype 相同。

```python
my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])
my_variable = tf.Variable(my_tensor)

# Variables can be all kinds of types, just like tensors
bool_variable = tf.Variable([False, False, False, True])
complex_variable = tf.Variable([5 + 4j, 6 + 1j])
```

大部分张量运算在变量上也可以按预期运行，不过变量无法重构形状。

变量可以使用 assign 分配：

```python
a = tf.Variable([2.0, 3.0])
# This will keep the same dtype, float32
a.assign([1, 2]) 
# Not allowed as it resizes the variable: 
try:
  a.assign([1.0, 2.0, 3.0])
except Exception as e:
  print(f"{type(e).__name__}: {e}")

```

从现有变量创建新变量会复制支持张量。两个变量不能共享同一内存空间。

```python
a = tf.Variable([2.0, 3.0])
# Create b based on the value of a
b = tf.Variable(a)
a.assign([5, 6])

# a 和 b 不同
print(a.numpy())
print(b.numpy())

# There are other versions of assign
print(a.assign_add([2,3]).numpy())  # [7. 9.]
print(a.assign_sub([7,9]).numpy())  # [0. 0.]
```



### 自动微分

#### GradientTape

TensorFlow 为自动微分提供了 tf.GradientTape，即计算某个计算相对于某些输入（通常是 tf.Variable）的梯度。TensorFlow 会将在 tf.GradientTape 上下文内执行的相关运算“记录”到“条带”上。TensorFlow 随后会该使用条带通过反向模式微分计算“记录的”计算的梯度。

```python
x = tf.Variable(3.0)

with tf.GradientTape() as tape:
  y = x**2

dy_dx = tape.gradient(y, x)
dy_dx.numpy()
```

tf.GradientTape 在任何张量上都可以轻松运行，tf.GradientTape 参数 persistent 默认为 false，表示最多只能进行一次 tape.gradient，设置为 True 可以多次进行 tape.gradient。

```python
w = tf.Variable(tf.random.normal((3, 2)), name='w')
b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')
x = [[1., 2., 3.]]

with tf.GradientTape(persistent=True) as tape:
  y = x @ w + b
  loss = tf.reduce_mean(y**2)
```

要获得 loss 相对于两个变量的梯度，可以将这两个变量同时作为 gradient 方法的输入。

```python
[dl_dw, dl_db] = tape.gradient(loss, [w, b])  # 列表传递
my_vars = {'w': w,'b': b}
grad = tape.gradient(loss, my_vars)           # 字典传递
grad['b']
```



#### 相对于模型的梯度

在大多数情况下，需要计算相对于模型的可训练变量的梯度。

```python
layer = tf.keras.layers.Dense(2, activation='relu')
x = tf.constant([[1., 2., 3.]])

with tf.GradientTape() as tape:
  y = layer(x)
  loss = tf.reduce_mean(y**2)

# Calculate gradients with respect to every trainable variable
grad = tape.gradient(loss, layer.trainable_variables)
for var, g in zip(layer.trainable_variables, grad):
  print(f'{var.name}, shape: {g.shape}')
```



#### 控制 GradientTape 记录的内容

默认情况下通过 tf.Variable 创建的变量会记录运算，下面这些情况不会记录运算

```python
x0 = tf.Variable(3.0, name='x0')  # 可训练的变量
x1 = tf.Variable(3.0, name='x1', trainable=False)  # 不可训练的变量
x2 = tf.Variable(2.0, name='x2') + 1.0    # A variable + tensor returns a tensor
x3 = tf.constant(3.0, name='x3')          # 不是变量

with tf.GradientTape() as tape:
  y = (x0**2) + (x1**2) + (x2**2)

grad = tape.gradient(y, [x0, x1, x2, x3])

for g in grad:
  print(g)
# 6.0 None None None
```

使用 GradientTape.watched_variables 方法列出 GradientTape 正在监视的变量：

```python
[var.name for var in tape.watched_variables()]  # ['x0:0']
```

tf.GradientTape 提供了钩子，让用户可以控制被监视或不被监视的内容。要记录相对于 tf.Tensor 的梯度，您需要调用 GradientTape.watch(x)：

```python
x = tf.constant(3.0)
with tf.GradientTape() as tape:
  tape.watch(x)
  y = x**2

# dy = 2x * dx
dy_dx = tape.gradient(y, x)
print(dy_dx.numpy())
```

相反，要停用监视所有 tf.Variables 的默认行为，需要在创建梯度带时设置 watch_accessed_variables=False。下面这个例子使用两个变量，但仅记录其中一个变量 x1 的梯度：

```python
x0 = tf.Variable(0.0)
x1 = tf.Variable(10.0)

with tf.GradientTape(watch_accessed_variables=False) as tape:
  tape.watch(x1)
  y0 = tf.math.sin(x0)    # x0 的梯度不会记录
  y1 = tf.nn.softplus(x1)
  y = y0 + y1
  ys = tf.reduce_sum(y)
```

> 在梯度带上下文内进行运算会有一个微小的开销。对于大多数 Eager Execution 来说，这一成本并不明显，但是您仍然应当仅在需要的地方使用梯度带上下文。

> 梯度带使用内存来存储中间结果，包括输入和输出，以便在后向传递中使用。
>
> 为了提高效率，某些运算（例如 ReLU）不需要保留中间结果，而是在前向传递中进行剪枝。不过，如果在梯度带上使用 persistent=True，则*不会丢弃任何内容*，并且峰值内存使用量会更高。



#### 非标量目标的梯度

```python
x = tf.Variable(2.0)
with tf.GradientTape(persistent=True) as tape:
  y0 = x**2
  y1 = 1 / x

print(tape.gradient(y0, x).numpy())   # 4
print(tape.gradient(y1, x).numpy())   # -0.25
```

因此，如果需要多个目标的梯度，则每个源的结果为

- 目标总和的梯度，或等效
- 每个目标的梯度总和。

```python
x = tf.Variable(2.0)
with tf.GradientTape() as tape:
  y0 = x**2
  y1 = 1 / x

print(tape.gradient({'y0': y0, 'y1': y1}, x).numpy())  # 3.75 = 4 - 0.25
```



梯度返回 None 的情况：[梯度和自动微分简介  | TensorFlow Core (google.cn)](https://tensorflow.google.cn/guide/autodiff?hl=zh-cn#gradient_返回_none_的情况)








## API

### tf

#### tf.gather

```python
tf.gather(
    params, indices, validate_indices=None, axis=None, batch_dims=0, name=None
)
```

根据 indices  从 axis 轴（axis 默认为0）在 params 中收集切片，indices 可以是任意维（通常为 1 维）。

```python
params = tf.constant(['p0', 'p1', 'p2', 'p3', 'p4', 'p5'])
tf.gather(params, [1,2,3]).numpy()
```

```
array([b'p1', b'p2', b'p3'], dtype=object)
```

indices 可以有任何形状。当 params 有1个轴时，输出形状等于输入形状：

```python
tf.gather(params, [[2, 0], [2, 5]]).numpy()
```

```
array([[b'p2', b'p0'],
       [b'p2', b'p5']], dtype=object)
```

params 也可以有任何形状。gather 可以根据 axis 参数选择任何坐标轴上的切片：

```python
params = tf.constant([[0, 1.0, 2.0],
                      [10.0, 11.0, 12.0],
                      [20.0, 21.0, 22.0],
                      [30.0, 31.0, 32.0]])
tf.gather(params, indices=[3,1]).numpy()  # 默认按行切片，[3,1] 表示选择第 3 和第 1 行
```

```
array([[30., 31., 32.],
       [10., 11., 12.]], dtype=float32)
```

```python
tf.gather(params, indices=[1,2], axis=1).numpy() # 按列切片，[1,2] 表示选择第 1 和第 2 列
```

```
array([[ 1.,  2.],
       [11., 12.],
       [21., 22.],
       [31., 32.]], dtype=float32)
```

当 params 和 indices 都有多个维度时：

```python
params = tf.random.uniform([3,2,2])
slices = tf.gather(params, indices=[[1,2], [0,1]])
```

```
params:
<tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=
array([[[0.4477837 , 0.6067594 ],
        [0.16130972, 0.485245  ]],

       [[0.61720157, 0.46546352],
        [0.32832325, 0.448591  ]],

       [[0.26026368, 0.9072639 ],
        [0.68530643, 0.16594708]]], dtype=float32)>
slices:
<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=
array([[[[0.61720157, 0.46546352],
         [0.32832325, 0.448591  ]],

        [[0.26026368, 0.9072639 ],
         [0.68530643, 0.16594708]]],

       [[[0.4477837 , 0.6067594 ],
         [0.16130972, 0.485245  ]],

        [[0.61720157, 0.46546352],
         [0.32832325, 0.448591  ]]]], dtype=float32)>
```

默认 axis = 0，所以从第一维度抽取切片。因为 indices 为 `[[1,2], [0,1]]`，是一个 2 × 2 的矩阵，所以切片的第一维变成了 (2,2)，可以看到 slices 变成了 (2,2,2,2) 维的张量。而 `indices[0, :] = [1,2]`，表明 `slices[0, :, :, :] = params[1:3, :, :]`，`indices[1, :] = [0, 1]`，表明 `slices[1, :, :, :] = params[0:2, :, :]`。


### tf.keras.layers

#### tf.keras.layers.LSTM

参数中的

return_sequences = True：返回值为 `[batch_size, seq_len, feature_dim]`

return_state = True：返回值为两个 `[batch_size, feature_dim]` （作为列表的形式返回）

如果 return_sequences 和 return_state 均为 True，那么返回值为
`[batch_size, seq_len, feature_dim], [[batch_size, feature_dim],[batch_size, feature_dim]]`

如果需要让 LSTM 支持 GPU 训练，需要满足下面的条件
1. `activation` == `tanh`
2. `recurrent_activation` == `sigmoid`
3. `recurrent_dropout` == 0
4. `unroll` is `False`
5. `use_bias` is `True`
6. Inputs, if use masking, are strictly right-padded.
7. Eager execution is enabled in the outermost context.






# PyTorch

## 安装

直接去官网下载对应版本即可，默认会下载 cudatoolkit，似乎不需要额外安装 cuda 和 cudnn，测试代码如下

```python
import torch
print(torch.cuda.is_available())
```

在安装时，如果遇到下载速度慢的情况，可以重试几次或者使用下载工具下载 whl 文件后再安装，最好不要换源，换源之后下载的是cpu版本。

## 操作

### 生成带状矩阵

```python
e = torch.ones([16, 16])
torch.tril(e, 4) * torch.triu(e, -4)
```


### 自定义归一化层

假设希望仅对每个通道进行归一化，即假设输入数据为 `[N C H W]`，只对 C 通道计算均值和方差

```python
class ChannelNormalization(nn.Module):  
    def __init__(self, input_dimension, eps=1e-5):  
        super().__init__()  
        param_size = [1, input_dimension, 1, 1]  
        self.gamma = Parameter(torch.Tensor(*param_size).to(torch.float32))  
        self.beta = Parameter(torch.Tensor(*param_size).to(torch.float32))  
        init.ones_(self.gamma)  
        init.zeros_(self.beta)  
        self.eps = eps  
  
    def forward(self, x):  
        if x.ndim == 4:  
            _, C, _, _ = x.shape  
            stat_dim = (1,)  
        else:  
            raise ValueError("Expect x to have 4 dimensions, but got {}".format(x.ndim))  
        mu_ = x.mean(dim=stat_dim, keepdim=True)  # [B,1,T,F]  
        std_ = torch.sqrt(  
            x.var(dim=stat_dim, unbiased=False, keepdim=True) + self.eps  
        )  # [B,1,T,F]  
        x_hat = ((x - mu_) / std_) * self.gamma + self.beta  
        return x_hat
```



## API


### torch

#### torch.chunk

试图将张量分割成指定数量（chunks）的块。每个块是输入张量的一个视图（分块）。

```python
torch.chunk(input, chunks, dim=0) → List of Tensors
```

> [!TIP]
>
> chunk 函数可能会返回小于指定 chunks 的分块（如 input 对应的维度），如果需要确切分块，使用 torch.tensor_split()


#### torch.einsum

和 einops 库类似，可以用来指定矩阵计算方式，einsum 的基本用法如下

```python
torch.einsum('ii', torch.randn(4, 4))
```

上式实现了对矩阵主对角线元素求和的功能，其中 i 表示维度，一共可以使用 a-z 共 26 个字母，即 26 个维度。



**提取主对角线元素**

```python
torch.einsum('ii->i', torch.randn(4, 4))
```


**向量外积**

```python
torch.einsum('i,j->ij', x, y)
```


**矩阵点积**

```python
torch.einsum("ij,ij->ij", [d,e])
```



**矩阵乘法**


```python
torch.einsum('bij,bjk->bik', As, Bs)
torch.einsum('tbij,bjk->bik', As, Bs)
```


>对于那些不关心的维度，可以使用 ...

```python
torch.einsum("...ij, ...jk-> ...ik", [a,b])
```


**矩阵转置**

```python
torch.einsum("...ij->...ji", c)
```



### nn.functional

#### nn.functional.unfold

从分批输入张量中提取滑动局部块

> 同 nn.Unfold，支持四维数据

```python
torch.nn.functional.unfold(input, kernel_size, dilation=1, padding=0, stride=1)
# or
torch.nn.Unfold(kernel_size, dilation=1, padding=0, stride=1)
```

input: (N, C, H, W)，N 为批次大小，C 为特征维度

output: (N, C×∏(kernel_size), L)，其中 L 为
$$
L = \mathop \prod \limits_d \left[ {{{{\rm{spatial\_size}}[d]{\rm{ + 2}} \times {\rm{padding}}[d] - {\rm{dilation}}[d] \times ({\rm{kernel\_size}}[d] - 1) - 1} \over {{\rm{stride}}[d]}} + 1} \right]
$$
unfold 的运算很简单，先不考虑 input 的 N 和 C 维度，只考虑 H 和 W，类似于卷积，将核对应的那一块特征图直接抽取展平，将一个 (H W) 维度的特征图全部抽取展平后连在一起，形成 ∏(kernel_size) × L 维数据，之后对于每个 C 维度，都进行相同的操作，将展平后的数据堆在一起，数据的个数为 C×∏(kernel_size)。下面是一个示例

```python
import torch.nn as nn
import torch

kernel_size=(2,2)
unfold = nn.Unfold(kernel_size=kernel_size)
input = torch.randn(2,2,3,4)
output = unfold(input)

print(output[0, :, 0]) 
# tensor([ 1.2555,  1.4594,  1.9301, -0.0237,  0.4073,  0.6424, -0.8624,  1.0444])

output1 = input[0, :, :kernel_size[0], :kernel_size[1]]
print(output1.flatten())
# tensor([ 1.2555,  1.4594,  1.9301, -0.0237,  0.4073,  0.6424, -0.8624,  1.0444])
```



#### nn.functional.pad

填充张量

```python
torch.nn.functional.pad(input, pad, mode='constant', value=None)
```

该函数主要作用体现在 pad 中，当 pad 的形式为 (padding_left, padding_right)，填充最后 1 个维度，当 pad 的形式为 (padding_left, padding_right, padding_top, padding_bottom)，填充最后 2 个维度，以此类推。



### nn

#### Normalization

各种 normalization 的作用都是归一化，表示为

$$
y = {{x - E[x]} \over {\sqrt {Var[x] + \varepsilon } }}*\gamma  + \beta 
$$
只不过在计算均值和方差时有所不同。

batchNorm是在batch上，对小batchsize效果不好；layerNorm在通道方向上，主要对RNN作用明显；instanceNorm在图像像素上，用在风格化迁移；GroupNorm将channel分组，然后再做归一化, 在batchsize<16的时候, 可以使用这种归一化。

##### Batch Normalization

```python
class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)
```


与其它归一化方法最大的差距在于会对一个 mini-batch 的数据进行归一化，假设输入为 `[B C H W]`，那么计算 `[B H W]` 这三个维度的均值和方差。

```python
inputs = torch.rand([16,32,64,64])

# print(inputs)

mean = torch.mean(inputs, [0,2,3], keepdim=True) # 按通道维度即32那个维度，计算那个维度对应的16*64*64个值的平均值

var = torch.var(inputs, [0,2,3], unbiased=False, keepdim=True)

bn = nn.BatchNorm2d(32)(inputs)

bn_ = (inputs-mean)/torch.sqrt(var+1e-5)
```


> [!NOTE]
> 如果归一化数据数量少、批次不够多，那么手动计算和方法计算的误差会较大，增大 B、 H 和 W 可以有效降低误差


##### LayerNorm

```python
class torch.nn.LayerNorm(normalized_shape, eps=1e-05, elementwise_affine=True, bias=True, device=None, dtype=None)
```

layernorm 计算均值和方差时，完全按照 normalized_shape 来，normalized_shape 的维度是任意的，但是必须是输入数据的最后若干维，如输入数据维度为 `[B C H W]`（H 不等于 W），如果设置 normalized_shape 为 H，则会报错。如果设置 normalized_shape 为 W，则会按照最后一个维度来计算均值和方差，normalized_shape 为 `[H W]`，则按照最后两个维度来计算均值和方差，依次类推。

```python
ln = nn.LayerNorm((32, 3, 128, 128))  
x = torch.randn((32, 3, 128, 128))  
y = ln(x)  
y_ = (x - x.mean()) / torch.sqrt(x.var()+1e-5)   # 直接对全局求均值和方差
print(torch.sum(torch.abs(y-y_)))

ln = nn.LayerNorm((128, 128))  
x = torch.randn((32, 3, 128, 128))  
y = ln(x)  
y_ = (x - x.mean(dim=(-2, -1), keepdim=True)) / torch.sqrt(x.var(dim=(-2, -1), unbiased=False, keepdim=True)+1e-5)    # 对最后两个维度求均值和方差
print(torch.sum(torch.abs(y-y_))) 
```


##### InstanceNorm

```python
class torch.nn.InstanceNorm2d(num_features, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None)
```

InstanceNorm2d 和 LayerNorm 有点像，与 BatchNorm2d 的区别在于不会对一个mini-batch求均值和方差，而是在mini-batch的每个样本的每个通道上求均值和方差。

```python
In = nn.InstanceNorm2d(16)  
x = torch.randn((32, 16, 256, 256))  
y = In(x)  
y_ = (x - x.mean(dim=(-2, -1), keepdim=True)) / torch.sqrt(x.var(dim=(-2, -1), unbiased=False, keepdim=True)+1e-5)  
print(torch.sum(torch.abs(y-y_)))
```



> [!NOTE]
> 与 BatchNorm2d 类似，如果归一化数据数量少，那么手动计算和方法计算的误差会较大，但是可以通过增大 H 和 W 降低误差



##### GroupNorm

```python
class torch.nn.GroupNorm(num_groups, num_channels, eps=1e-05, affine=True, device=None, dtype=None)
```


介于LN和IN之间，其首先将channel分为许多组（group），对每一组做归一化，即先将feature的维度由 `[N, C, H, W]` reshape 为 `[N, G，C//G , H, W]`，归一化的维度为 `[C//G , H, W]`

```python
groups = 8

inputs = torch.rand([16,32,64,64])

inputs_ = inputs.reshape([16, groups, 32//groups, 64, 64])

mean = torch.mean(inputs_, [2,3,4], keepdim=True) # 按batch和group维度即[16,8]那个维度，计算那个维度对应的4*64*64个值的平均值

var = torch.var(inputs_, [2,3,4], unbiased=False, keepdim=True)

gn = nn.GroupNorm(groups, 32)(inputs)

gn_ = (inputs_-mean)/torch.sqrt(var+1e-5)

gn_ = gn_.reshape([16, 32, 64,64])

print(torch.sum(torch.abs(gn-gn_)))    # 结果差距很小

```

对于输入数据 `[N C H W]`

`GroupNorm(C, C)` 相当于 `InstanceNorm2d(C)`

`GroupNorm(1, C)` 相当于 `LayerNorm((C, H, W))` ，但是不需要额外计算 H 和 W 的大小

