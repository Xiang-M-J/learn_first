
## 概率论引论

## 随机变量

## 条件概率与条件期望


## 马尔可夫链

### 一些应用

#### 赌徒破产问题



考察一个赌徒，他在每次赌博中以概率p赢一个单位,并以概率q=1-p输一个单位。假设各次赌博都是独立的，赌徒在开始时有i个单位,问他的财富在达到0以前先达到N的概率是多少？

记$X_n$为玩家在时间n的财富，那么转移概率为
$$
{P_{00}} = {P_{NN}} = 1,\quad {P_{i,i + 1}} = p,\quad {P_{i,i - 1}} = 1 - p
$$
此马尔科夫链有三个类，即{0}，{1,2,...,N-1}，{N}。第一个和第三个类是常返的，第二个类是暂态的。由此推出在某个有限的时间后，此赌徒将达到他的目标N或者破产。

以$P_i$记赌徒在开始时有i个单位且他的财富最终达到N的概率，有
$$
\eqalign{
  & {P_i} = {P_{i,i + 1}}{P_{i + 1}} + {P_{i,i - 1}}{P_{i - 1}}  \cr 
  & {P_i} = p{P_{i + 1}} + q{P_{i - 1}} \cr}
$$
因为有$p+q=1$，所以有
$$
\eqalign{
  & p{P_i} + q{P_i} = p{P_{i + 1}} + q{P_{i - 1}}  \cr 
  & p({P_{i + 1}} - {P_i}) = q({P_i} - {P_{i - 1}})  \cr 
  & {P_{i + 1}} - {P_i} = {q \over p}({P_i} - {P_{i - 1}}) \cr} 
$$
因此有
$$
\eqalign{
  & {P_2} - {P_1} = {q \over p}{P_1}  \cr 
  & {P_3} - {P_2} = {q \over p}({P_2} - {P_1}) = {\left( {{q \over p}} \right)^2}{P_1}  \cr 
  &  \vdots   \cr 
  & {P_i} - {P_{i - 1}} = {q \over p}({P_{i - 1}} - {P_{i - 2}}) = {\left( {{q \over p}} \right)^{i - 1}}{P_1}  \cr 
  &  \vdots   \cr 
  & {P_N} - {P_{N - 1}} = {q \over p}({P_{N - 1}} - {P_{N - 2}}) = {\left( {{q \over p}} \right)^{N - 1}}{P_1} \cr} 
$$

$$
\eqalign{
  & {P_i} - {P_1} = {P_1}\left[ {{q \over p} + {{\left( {{q \over p}} \right)}^2} +  \cdots  + {{\left( {{q \over p}} \right)}^{i - 1}}} \right]  \cr 
  & {P_i} = {P_1}\left[ {1 + {q \over p} + {{\left( {{q \over p}} \right)}^2} +  \cdots  + {{\left( {{q \over p}} \right)}^{i - 1}}} \right] = \left\{ \matrix{
  {P_1}{{1 - {{(q/p)}^i}} \over {1 - (q/p)}}\quad\; q/p \ne 1 \hfill \cr 
  i{P_1}\quad \quad \quad \quad q/p = 1 \hfill \cr}  \right. \cr}
$$

由于$P_N=1$（开始就有N个单位那就不用赌了），有
$$
{P_1} = \left\{ \matrix{
  {{1 - (q/p)} \over {1 - {{(q/p)}^N}}}\quad q/p \ne 1 \hfill \cr 
  {1 \over N}\quad \quad \quad \; q/p = 1 \hfill \cr}  \right.
$$
所以$P_i$为
$$
{P_i} = \left\{ \matrix{
  {{1 - {{(q/p)}^i}} \over {1 - {{(q/p)}^N}}}\quad q/p \ne 1 \hfill \cr 
  {i \over N}\quad \quad \quad\; q/p = 1 \hfill \cr}  \right.  \tag{4.14}
$$
注意到，当$N\to \infty$，有
$$
{P_i} \to \left\{ \matrix{
  1 - {\left( {{q \over p}} \right)^i}\quad\;\; {q \over p} < 1\;or\;p > {1 \over 2} \hfill \cr 
  0\quad \quad \quad \quad \quad {q \over p} \ge 1\;or\;p \le {1 \over 2} \hfill \cr}  \right.
$$
假设麦克斯和帕蒂决定扔硬币,扔得离墙更近的人赢（得一枚硬币），帕蒂玩得更好，每次以概率0.6获胜。

1. 若帕蒂以5枚硬币开始，而麦克斯以10枚硬币开始，问帕蒂让麦克斯输光的概率是多少？
2. 若帕蒂以10枚硬币开始，而麦克斯以20枚开始，情况又如何？

根据公式4.14，i=5，帕蒂让麦克斯输光时，帕蒂所拥有的硬币数N=15，帕蒂赢的概率为
$$
P = {{1 - {{\left( {{2 \over 3}} \right)}^5}} \over {1 - {{\left( {{2 \over 3}} \right)}^{15}}}} = 0.87
$$
同理有
$$
P = {{1 - {{\left( {{2 \over 3}} \right)}^{10}}} \over {1 - {{\left( {{2 \over 3}} \right)}^{30}}}} = 0.98
$$
将**赌徒破产问题应用于药品检验**，假设开发了治疗某种病的两种新药。药品i有治愈率$P_i$，i=1,2。其含义为每个用药品i治疗的病人将以概率P被治愈。然而，治愈率是不知道的，并且假设我们想要确定是$P_1>P_2$还是$P_2>P_1$。为此考察如下的检验：成对的病人相继地接受治疗，其中的一个成员接受药品1，而另一个接受药品2。每对的结果是确定的，在一种药治愈的累计数超过另一种药治愈的累计数某个预定的固定数时，检验停止。更为正式地，令
$$
\eqalign{
  & {X_j} = \left\{ \matrix{
  1\quad drug1\;cure\;patient \hfill \cr 
  0\quad otherwise \hfill \cr}  \right.  \cr 
  & {Y_j} = \left\{ \matrix{
  1\quad drug2\;cure\;patient \hfill \cr 
  0\quad otherwise \hfill \cr}  \right. \cr}
$$
对于一个预定的正整数M，检验于N对病人以后停止，此处N是使
$$
{X_1} +  \cdots  + {X_n} - ({Y_1} +  \cdots  + {Y_n}) = M
$$
或者
$$
{X_1} +  \cdots  + {X_n} - ({Y_1} +  \cdots  + {Y_n}) =  - M
$$
的第一个n。第一种对应$P_1>P_2$，第二种对应$P_2>P_1$。

可以看到对于这个马尔科夫链来说，${X_1} +  \cdots  + {X_n} - ({Y_1} +  \cdots  + {Y_n})$增加1的概率为$P_1(1-P_2)$，减小1的概率为$P_2(1-P_1)$，保持不变的概率为$1-P_1(1-P_2)-P_2(1-P_1)$。

对应于赌徒问题，则有
$$
p = P( + 1| \pm 1) = {{{P_1}(1 - {P_2})} \over {{P_1}(1 - {P_2}) + {P_2}(1 - {P_1})}}
$$

$$
q = 1 - p = P( - 1| \pm 1) = {{{P_2}(1 - {P_1})} \over {{P_1}(1 - {P_2}) + {P_2}(1 - {P_1})}}
$$

因此，检验断言$P_2>P_1$的概率等于以概率p每注赢一个单位的赌徒在增长M前减少M的概率，设置i=M，N=2M，可得
$$
P({P_2} > {P_1}) = 1 - {{1 - {{\left( {q/p} \right)}^M}} \over {1 - {{\left( {q/p} \right)}^{2M}}}} = {1 \over {1 + {{\left( {q/p} \right)}^M}}}
$$
若$P_1=0.6$，$P_2=0.4$，则当M=5时，一个不正确判断的概率为0.017，而当M=10时，减小到0.0003。



#### 随机游动分析可满足性问题的概率算法

考察一个状态为0，1，...，n的马尔可夫链，其
$$
P_{0,1}=1,\quad P_{i,i+1}=p,\quad P_{i,i-1}=q=1-p,\;1\le i<n
$$
并且假设我们想要研究这个链从状态0到状态n所花的时间。得到达到状态n的平均时间的一种方法是以 $m_i$记从状态i走到状态n的平均时间，i=0,…,n-1。如果我们取条件于初始转移，就得到下面的方程：
$$
\eqalign{
  & {m_0} = 1 + {m_1}  \cr 
  & {m_i} = E[{\rm{time}}\;{\rm{to}}\;{\rm{reach}}\;n|{\rm{next}}\;{\rm{state}}\;{\rm{is}}\;i + 1]p  \cr 
  &  + E[{\rm{time}}\;{\rm{to}}\;{\rm{reach}}\;n|{\rm{next}}\;{\rm{state}}\;{\rm{is}}\;i - 1]q  \cr 
  &  = (1 + {m_{i + 1}})p + (1 + {m_{i - 1}})q  \cr 
  &  = 1 + p{m_{i + 1}} + q{m_{i - 1}}\quad i = 1,...,n - 1 \cr}
$$
这里的1表示转移到下一个状态时的一次转移。这个方程已经可以给出答案（借助p+q=1），但是我们并不想要它们的解，而是想利用这个马尔可夫链的特殊结构得到一组更简单的方程。首先，以$N_i$记这个链先进入状态i直至进入状态i+1所用的附加转移次数。由马尔可夫性质推出这些$N_i$是独立的。此外将这个链从状态0进入到状态n所用的时间$N_{0,n}$表示为
$$
{N_{0,n}} = \sum\limits_{i = 0}^{n - 1} {{N_i}} \tag{4.15}
$$
令$\mu_i=E[N_i]$，对这个链进入状态i的下一次转移取条件，对于i=1，...，n-1，如果这个链下一次进入状态i-1，那么为了到达i＋1，它必须先回到状态i，然后必须走向状态i+1。但如果下一次进入状态i+1，那么只需要1次转移即可。
$$
\eqalign{
  & {\mu _i} = \left( {1 + E[{\rm{transtions}}\;{\rm{to}}\;{\rm{reach}}\;i + 1|{\rm{chain}}\;{\rm{to}}\;i + 1]} \right)p  \cr 
  &  + \left( {1 + E[{\rm{transtions}}\;{\rm{to}}\;{\rm{reach}}\;i + 1|{\rm{chain}}\;{\rm{to}}\;i - 1]} \right)q  \cr 
  &  = 1 \times p + (1 + E[N_{i - 1}^* + N_i^*])q = 1 + \left( {{\mu _{i - 1}} + {\mu _i}} \right)q \cr}
$$
其中$N_{i-1}^*$和$N_i^*$分别是从状态`i-1`回到`i`的附加转移次数和从`i`到达`i+1`的次数。由马尔可夫性质推出这些随机变量分别与$N_{i-1}$和$N_i$有相同的分布。此外，它们是独立的。

由$\mu_0=1$，并令$\alpha=q/p$，由上面的递推公式得到
$$
\eqalign{
  & {\mu _1} = 1/p + \alpha   \cr 
  & {\mu _2} = 1/p + \alpha (1/p + \alpha ) = 1/p + \alpha /p + {\alpha ^2}  \cr 
  &  \vdots   \cr 
  & {\mu _i} = {1 \over p}\sum\limits_{j = 0}^{i - 1} {{\alpha ^j}}  + {\alpha ^i},\quad i = 1, \cdots ,n - 1 \cr} 
$$
由方程4.15可得
$$
E[{N_{0,n}}] = 1 + {1 \over p}\sum\limits_{i = 1}^{n - 1} {\sum\limits_{j = 0}^{i - 1} {{\alpha ^j}} }  + \sum\limits_{i = 1}^{n - 1} {{\alpha ^i}}
$$
当$p=1/2$时有$\alpha=1$，所以
$$
E[{N_{0,n}}] = 1 + n(n - 1) + n - 1 = {n^2}
$$
当$p\neq 1/2$时，得到
$$
\eqalign{
  & E[{N_{0,n}}] = 1 + {1 \over {p(1 - \alpha )}}\sum\limits_{i = 1}^{n - 1} {\left( {1 - {\alpha ^i}} \right)}  + {{\alpha  - {\alpha ^n}} \over {1 - \alpha }}  \cr 
  &  = 1 + {{1 + \alpha } \over {1 - \alpha }}\left[ {n - 1 - {{\left( {\alpha  - {\alpha ^n}} \right)} \over {1 - \alpha }}} \right] + {{\alpha  - {\alpha ^n}} \over {1 - \alpha }}  \cr 
  &  = 1 + {{2{\alpha ^{n + 1}} - \left( {n + 1} \right){\alpha ^2} + n - 1} \over {{{\left( {1 - \alpha } \right)}^2}}} \cr} 
$$
其中第二个等式用了$p=1/(1+\alpha)$。方差的求解不过多介绍，详见原书P191页。当p=1/2时，$N_{0,n}$近似是均值为$n^2$和方差为${2\over 3} n^4$的正态分布。

**可满足性问题**：布尔变量x是只取真或假两个值之一的变量，如果$x_i$都是布尔变量，符号"+"表示或，符号"*"表示且。一个布尔公式是像这种句子的一个组合：
$$
\left( {{x_1} + {{\bar x}_2}} \right)*\left( {{x_1} + {x_3}} \right)
$$
可满足性问题是确定使公式结果是真的变量的值或确定使公式绝对不是真的变量的值。考察n个布尔变量$x_1,\cdots,x_n$的一个公式，并假设公式中的每个子句恰好包含两个变量。现在我们介绍一个概率算法，它将求得满足公式的值或者确定不可能满足此公式的一个大的概率。首先，开始于一组任意设置的值，然后，在每一步选取一个值是假的子句，而且随机地在此子句中选取一个布尔变量，并改变它的值。即若此变量值是真，则将它的值改为假，反之亦然。若这个新设置使公式为真，则停止，否则继续进行同样的改变方式。如果重复了${n^2}\left( {1 + 4\sqrt {{2 \over 3}} } \right)$次还没有停止，那么宣布此公式不可能满足。具体论证参见原书。原理与正态分布的sigma准则有关。



### 在暂态停留的平均时间

考察一个有限状态马尔可夫链，并假设其状态都标以一个数，因而以T={1,2,...,t}记其暂态集，令
$$
{P_T} = \left[ {\matrix{
   {{P_{11}}} & {{P_{12}}} &  \cdots  & {{P_{1t}}}  \cr 
    \vdots  &  \vdots  &  \vdots  &  \vdots   \cr 
   {{P_{t1}}} & {{P_{t2}}} &  \cdots  & {{P_{tt}}}  \cr 

 } } \right]
$$
注意由于$P_T$特指只从暂态到暂态的转移概率，其某些行的和小于1。

对于暂态i和j，以$s_{ij}$记给定开始在状态i的马尔科夫链在状态j的平均时段数。如果i=j，令$\delta_{i,j}=1$，其它情形，令它为0。
$$
{s_{i,j}} = {\delta _{i,j}} + \sum\limits_{k = 1}^t {{P_{ik}}{s_{kj}}} \tag{4.18}
$$
其中最后的等式是由于不可能从一个常返态转移到暂态，当k是常返态时，$s_{kj}=0$。
以S记分量为$s_{ij}(i,j=1,\cdots,t)$的矩阵，即
$$
S = \left[ {\matrix{
   {{s_{11}}} & {{s_{12}}} &  \cdots  & {{s_{1t}}}  \cr 
    \vdots  &  \vdots  &  \vdots  &  \vdots   \cr 
   {{s_{t1}}} & {{s_{t2}}} &  \cdots  & {{s_{tt}}}  \cr 

 } } \right]
$$
方程4.18可以用矩阵记号写为
$$
S = I+P_TS
$$
其中$I$是t阶单位矩阵，因为上面的方程等价于
$$
\eqalign{
  & (I - {P_T})S = I  \cr 
  & S = {(I - {P_T})^{ - 1}} \cr}
$$
对于$i\in T$，$j\in T$，$f_{ij}$等于给定初始状态为`i`的马尔可夫链最终转移到状态`j`的概率，它可以容易地由$P_T$确定。为了确定其关系，我们先对是否最终进入状态`j`取条件以推导一个$s_{ij}$的表达式。这引出
$$
\eqalign{
  & {s_{ij}} = E[{\rm{time}}\;{\rm{in}}\;j|{\rm{start}}\;{\rm{in}}\;i,{\rm{final}}\;{\rm{transit}}\;{\rm{to}}\;j]{f_{ij}}  \cr 
  &  + E[{\rm{time}}\;{\rm{in}}\;j|{\rm{start}}\;{\rm{in}}\;i,{\rm{never}}\;{\rm{transit}}\;{\rm{to}}\;j]\left( {1 - {f_{ij}}} \right)  \cr 
  &  = \left( {{\delta _{i,j}} + {s_{jj}}} \right){f_{ij}} + {\delta _{i,j}}\left( {1 - {f_{ij}}} \right)  \cr 
  &  = {\delta _{i,j}} + {f_{ij}}{s_{jj}} \cr}
$$
由于$s_{jj}$是给定从状态`i`出发最终进入`j`时停留在状态`j`的附加时段个数的期望，求解上面的方程得到
$$
{f_{ij}} = {{{s_{ij}} - {\delta _{ij}}} \over {{s_{jj}}}}
$$

### 分支过程
考察一个总体，它由能产生同类型后代的个体所组成。假设每个个体在其生命结束时，以概率$P_j(j\ge0)$产生`j`个后代，它们独立于其他个体所产生的后代的个数。我们假设对于一切j≥0有$P_j<1$。将最初的个体数记为$X_0$，称为第零代的大小。所有第零代的后代组成第一代，它们的个数记为$X_1$。一般地，以$X_n$记第n代的大小。由此推出$\{X_n,n\ge0\}$是一个以非负整数集合为状态空间的马尔可夫链。
由于显然有$P_{00}=1$，转移状态0是常返态。此外，若P>0，则其他状态都是暂态。这是由于$P_{i0}=P_0^i$，它表明开始有i个个体时存在一个至少为$P_0^i$的正概率使最终不再有后代。此外，由于暂态的任意有限集{1,2,…,n}只能有限次地被访问，这就导出重要的结论：如果P>0，总体或者灭绝，或者趋于无穷。
令$\mu$为单个个体的后代个数均值
$$
\mu  = \sum\limits_{j = 0}^\infty  {j{P_j}}
$$
令$\sigma^2$为单个个体的后代个数的方差
$$
{\sigma ^2} = \sum\limits_{j = 0}^\infty  {{{\left( {j - \mu } \right)}^2}{P_j}}
$$
假设$X_0=1$，即初始只有一个个体，下面计算$E[X_n]$和$Var(X_n)$，可以写出
$$
{X_n} = \sum\limits_{i = 1}^{{X_{n - 1}}} {{Z_i}}
$$
其中$Z_i$表示第n-1代的第i个个体的后代的个数，取条件于$X_{n-1}$得到
$$
\eqalign{
  & E[{X_n}] = E[E[{X_n}|{X_{n - 1}}]]  \cr 
  &  = E\left[ {E\left[ {\sum\limits_{i = 1}^{{X_{n - 1}}} {{Z_i}} |{X_{n - 1}}} \right]} \right]  \cr 
  &  = E\left[ {{X_{n - 1}}\mu } \right] = \mu E\left[ {{X_{n - 1}}} \right] \cr}
$$
其中用到了条件期望公式$E[X]=E[E[X|Y]]$，$E[Z]=\mu$。可以解得$E[X_n]=\mu^n$。
类似$Var(X_n)$可以用到条件方差公式
$$
{\mathop{\rm Var}\nolimits} ({X_n}) = E[{\mathop{\rm Var}\nolimits} ({X_n}|{X_{n - 1}})] + {\mathop{\rm Var}\nolimits} (E[{X_n}|{X_{n - 1}}])
$$
已知$E[X_n|X_{n-1}]=X_{n-1}\mu$，${\mathop{\rm Var}\nolimits} ({X_n}|{X_{n - 1}}) = {X_{n - 1}}{\sigma ^2}$，可以解得
$$
{\mathop{\rm Var}\nolimits} ({X_n}) = \left\{ \matrix{
  {\sigma ^2}{\mu ^{n - 1}}\left( {{{1 - {\mu ^n}} \over {1 - \mu }}} \right)\quad \mu  \ne 1 \hfill \cr 
  n{\sigma ^2}\quad \quad \quad \quad \mu  = 1 \hfill \cr}  \right.
$$
以$\pi_0$记总体最终灭绝的概率，即
$$
{\pi _0} = \mathop {\lim }\limits_{n \to \infty } P\{ {X_n} = 0|{X_0} = 1\}
$$
首先可以注意到$\mu<1$时，$\mu^n\to0$，所以$\pi_0\to1$
事实上，即使$\mu=1$，也可以证明$\pi_0=1$，当$\mu>1$时，有$\pi_0<1$。一个确定$\pi_0$的方程可以通过取条件于初始个体的后代的个数推导如下：
$$
{\pi _0} = P\{ {\rm{die}}\;{\rm{out}}\}  = \sum\limits_{j = 0}^\infty  {P\{ {\rm{die}}\;{\rm{out|}}{X_1} = j\} } {P_j}
$$
现在给定$X_1=j$，总体最终灭绝当且仅当从第一代成员开始的`j`个家庭中的每一个都灭绝。由于每个家庭假定为独立地行动的，并且由于每个特定的家庭灭绝的概率正是$\pi_0$，这就导致
$$
P\{ {\rm{die}}\;{\rm{out}}|{X_1} = j\}  = \pi _0^j
$$
从而$\pi_0$满足
$$
{\pi _0} = \sum\limits_{j = 0}^\infty  {\pi _0^j{P_j}}  \tag{4.20}
$$
事实上，当$\mu>1$时，可以证明$\pi_0$是满足方程(4.20)的最小正解。


### 时间可逆的马尔可夫链
考察一个具有转移概率$P_j$和平稳概率$\pi_i$的平稳的遍历马尔可夫链（即一个已经长时间运行的遍历的马尔可夫链），假设它开始于某个时间，我们沿时间的反向追踪其状态序列。即从时间n开始，考察状态序列$X_n$，$X_{n-1}$，...，这个状态序列显示它本身是一个马尔可夫链，其转移概率$Q_{ij}$定义为
$$
\eqalign{
  & {Q_{ij}} = P\{ {X_m} = j|{X_{m + 1}} = i\}   \cr 
  &  = {{P\{ {X_m} = j,{X_{m + 1}} = i\} } \over {P\{ {X_{m + 1}} = i\} }}  \cr 
  &  = {{P\{ {X_{m + 1}} = i|{X_m} = j\} P\{ {X_m} = j\} } \over {P\{ {X_{m + 1}} = i\} }}  \cr 
  &  = {{{\pi _j}{P_{ji}}} \over {{\pi _i}}} \cr}
$$
这也是一个马尔可夫链，如果对于一切`i`，`j`都有$Q_{ij}=P_{ji}$，那么这个马尔可夫链称为时间可逆的。时间可逆的条件可以表示为
$$
\pi_iP_{ij}=\pi_jP_{ji}  \tag{4.21}
$$
方程(4.21)的条件可以陈述为，对于一切状态`i`，`j`，过程从`i`到`j`的转移率（即$\pi_jP_{ji}$）等于从`j`到`i`的转移率（即$\pi_jP_{ji}$）。值得注意的是这显然是时间可逆性的一个必要条件，因为一个从i到j的逆向转移等于从j到i的正向转移。就是说，如果$X_m=i$且$X_{m-1}=j$，那么如果我们向后看，就观察到从`i`到`j`的一个转移，而如果我们向前看，就观察到从`j`到`i`的一个转移。于是，正向过程从`j`到`i`的转移率总等于反向过程从`i`到`j`的转移率；如果时间是可逆的，它必须等于正向过程从`i`到`j`的转移率。

考虑一个状态为0,1,...,M，转移概率如下的随机游动
$$
\eqalign{
  & {P_{i,i + 1}} = {\alpha _i} = 1 - {P_{i,i - 1}}\quad i = 1, \cdots ,M - 1  \cr 
  & {P_{0,1}} = {\alpha _0} = 1 - {P_{0,0}}  \cr 
  & {P_{M,M}} = {\alpha _M} = 1 - {P_{M,M - 1}} \cr}
$$
无需任何计算便可论证这个马尔可夫链是时间可逆的。这是因为从`i`到`i＋1`的转移数必须总是在从`i＋1`到`i`的转移数相差1以内。这是由于任何两次从`i`到`i＋1`的转移间必须有一次从`i＋1`到`i`的转移（而且相反也对），因为从一个较高的状态再进入`i`必须经过状态`i＋1`。因此推出从`i`到`i+1`的转移率等于从`i＋1`到`i`的转移率，所以此过程是时间可逆的。
我们可以很容易地通过对每个状态i=0, 1,…  , M-1将从i到i+1的转移率与从i＋1到i的转移率取成相等以得到极限概率，这样导出
$$
\eqalign{
  & {\pi _0}{\alpha _0} = {\pi _1}(1 - {\alpha _1})  \cr 
  & {\pi _1}{\alpha _1} = {\pi _2}(1 - {\alpha _2})  \cr 
  &  \vdots   \cr 
  & {\pi _i}{\alpha _i} = {\pi _{i + 1}}(1 - {\alpha _{i + 1}}) \cr}
$$
用$\pi_0$作为参数求解，可以解得
$$
{\pi _i} = {{{\alpha _{i - 1}} \cdots {\alpha _0}} \over {(1 - {\alpha _i}) \cdots (1 - {\alpha _1})}}{\pi _0},\quad i = 1,2, \cdots ,M
$$
又有$\sum\limits_{i = 0}^M {{\pi _i}}  = 1$，可以给出结果。


考虑一个连通图，每个弧(i,j)有一个权重$w_{ij}$。现在考察一个以如下方式移动的质点：如果在任意时间质点停在顶点`i`，那么下一次它以概率$P_{ij}$移向顶点`j`，$P_{ij}$定义如下
$$
{P_{ij}} = {{{w_{ij}}} \over {\sum\nolimits_j {{w_{ij}}} }}
$$
由时间可逆性方程
$$
\eqalign{
  & {\pi _i}{{{w_{ij}}} \over {\sum\nolimits_j {{w_{ij}}} }} = {\pi _j}{{{w_{ji}}} \over {\sum\nolimits_i {{w_{ji}}} }}  \cr 
  & {{{\pi _i}} \over {\sum\nolimits_j {{w_{ij}}} }} = {{{\pi _j}} \over {\sum\nolimits_i {{w_{ji}}} }}  \cr 
  & {{{\pi _i}} \over {\sum\nolimits_j {{w_{ij}}} }} = c  \cr 
  &  \cr}
$$
由$1=\sum_i\pi_i$得到
$$
{\pi _i} = {{\sum\nolimits_j {{w_{ij}}} } \over {\sum\nolimits_i {\sum\nolimits_j {{w_{ij}}} } }}
$$
因为由这个方程给出的$\pi_i$满足时间可逆性方程，这就推出过程对此极限概率是时间可逆的。


### 马尔可夫链蒙特卡罗方法
令$X$是一个离散的随机向量，它的可能值的集合是$x_j$，$j\ge 1$。令$X$的概率质量函数为$P\{X=x_j\}$，$j\ge 1$，而且假设我们想对某些特殊的函数$h$计算
$$
\theta  = E[h(X)] = \sum\limits_{j = 1}^\infty  {h({x_j})P\{ X = {x_j}\} }
$$
在求函数$h(x_j)(j\ge1)$的值在计算上有困难的情形，我们常常转为用模拟近似$\theta$。通常的方法称为蒙特卡罗方法，是利用随机数生成概率质量函数为$P\{X=x_j\}$，$j\ge 1$的独立同分布部分随机向量序列$X_1$，$X_2$，...，$X_n$。由强大数定律可以导出
$$
\mathop {\lim }\limits_{n \to \infty } \sum\limits_{i = 1}^n {{{h({X_i})} \over n}}  = \theta
$$
随之我们可以取很大的n，用$h(X_i)(i=1,\cdots,n)$的平均值作为估计量去估计$\theta$。
然而，常常很难生成具有特定的概率质量函数的随机向量，特别地，如果X是一个（分量之间有）相依的随机向量。此外，它的概率质量函数有时取$P(X=x_j)=Cb_j(j\ge1)$的形式，其中$b_j$是指定的，但是必须计算C，而在很多应用中，用对$b_j$求和来确定C在计算上并不可行。幸而，在这种情形存在利用模拟估计$\theta$的另一种途径。即不是生成独立的随机向量列，而是生成一个取向量值的，且以$P(X=x_j)(j\ge1)$为平稳概率的马尔可夫链$X_1$，$X_2$，$\cdots$的相继状态的一个序列。
现在我们说明如何生成一个具有任意平稳概率的马尔可夫链，而此平稳概率可以只特定到一个常数倍数。令$b(j)(j=1,\cdots)$是其和$B=\sum_{j=1}^{\infty}b(j)$为有限的正数。下面的黑斯廷斯—梅特罗波利斯算法可以用于生成一个时间可逆的马尔可夫链，使其平稳概率是
$$
\pi (j) = b(j)/B,\quad j = 1,2, \cdots
$$
黑斯廷斯—梅特罗波利斯算法最广泛的应用版本是吉布斯抽样。令${\bf{X}} = \left( {{X_1}, \cdots ,{X_n}} \right)$是一个离散的随机向量，具有只特定到一个常数倍数的概率质量函数$p(x)$，假设我们要生成与$\bf{X}$同分布的一个随机向量。即我们要生成具有概率质量函数
$$
p(x) = Cg(x)
$$
的随机变量$\bf{X}$，其中$g(x)$已知，但是$C$未知。应用吉布斯抽样时假定对于任意`i`和$x_j,j\neq i$，我们能够生成一个具有概率质量函数
$$
P\{ X = x\}  = P\{ {X_i} = x|{X_j} = {x_i},j \ne i\}
$$
的随机变量$\bf{X}$。它通过黑斯廷斯—梅特罗波利斯算法运行在状态为${\bf{x}} = ({x_1}, \cdots ,{x_n})$的一个马尔可夫链上，其转移概率定义为：只要目前的状态是x，就等可能地从1,…,n中任意选取一个作为坐标。如果选取了坐标i，那么就生成了一个具有概率质量函数$P\{ X = x\}  = P\{ {X_i} = x_i|{X_j} = {x_j},j \ne i\}$的随机变量X。如果$X=x$，那么就将状态$y=(x_1,\cdots,x_{i-1},x,x_{i+1},\cdots,x_n)$考虑为下一个候选状态。


### 马尔可夫决策过程
考察一个过程，它在离散时间点上的观测是标号为1,…,M 的M个可能的状态中任意一个。在观测到过程的状态后必须选取一个动作，而我们以A记所有可能的动作的集合，并且假定它是有限集。
如果过程在时间n处在状态i，并且选取了动作a，则系统的下一个状态由转移概率$P_{ij}(a)$确定。如果我们以$X_n$记过程在时间n的状态，以$a_n$记在时间n选取的动作，那么上面就等价于
$$
P\{ {X_{n + 1}} = j|{X_0},{a_0},{X_1},{a_1}, \cdots ,{X_n} = i,{a_n} = a\}  = {P_{ij}}(a)
$$
于是，转移概率只是目前的状态和随后的动作的函数。
将选取动作的一个规则称为一个策略。我们局限于下述形式的策略，即在任意时间他们指定的动作只依赖于当时过程的状态（而不依赖于过程以前的任何状态和动作）。然而，我们容许一个策略是“随机化”的，即可以按概率分布选取动作。换句话说，一个策略$\beta$是一个数的集合$\beta  = \{ {\beta _i}(a),a \in A,i = 1, \cdots ,M\}$，即如果过程在状态i，则以概率$\beta_i(a)$选取动作a。当然，我们需要假定
$$
\eqalign{
  & 0 \le {\beta _i}(a) \le 1  \cr 
  & \sum\limits_a {{\beta _i}(a)}  = 1 \cr}
$$
在任意给定的策略$\beta$下，状态序列$\{X_n,n=0,1,...\}$构成一个马尔可夫链，其转移概率$P_{ij}(\beta)$给定为
$$
{P_{ij}}(\beta ) = {P_\beta }\{ {X_{n + 1}} = j|{X_n} = i\}  = \sum\limits_a {{P_{ij}}(a){\beta _i}(a)}
$$
其中最后的等式是由取条件于状态i时所选取的动作得到的。我们假设对于每一个选取的策略$\beta$所确定的马尔可夫链$\{X_n,n=0,1,...\}$是遍历的。
对于一个策略$\beta$，以$\pi_{ia}$记在使用了策略$\beta$时，过程在状态i并且选取动作a时的极限（或稳态）概率。即
$$
{\pi _{ia}} = \mathop {\lim }\limits_{n \to \infty } {P_\beta }\{ {X_n} = j,{a_n} = a\}
$$
向量$\pi=(\pi_{ia})$满足
（1）对于一切i，a，${\pi _{ia}} \ge 0$
（2）$\sum\nolimits_i {\sum\nolimits_a {{\pi _{ia}}} }  = 1$
（3）对于一切j，$\sum\nolimits_a {{\pi _{ja}}}  = \sum\nolimits_i {\sum\nolimits_a {{\pi _{ia}}{P_{ij}}(a)} }$

### 隐马尔可夫链

令$\{ {X_n},n = 1,2, \cdots \}$是一个转移概率为$P_{ij}$和初始状态概率为${p_i} = P\{ {X_1} = i\} (i \ge 0)$的马尔可夫链。假设有一个信号的有限集$\ell$使马尔可夫链在每次进入一个状态时发射一个在$\ell$中的信号。此外，假设当马尔可夫链进入状态j时，独立于以前马尔可夫链的状态和信号，以概率$p(s|j)$发射信号s，$\sum\nolimits_{s \in \ell } {p(s|j)}  = 1$，即如果以$S_n$表示第n个发射的信号，那么
$$
P\{ {S_1} = s|{X_1} = j\}  = p(s|j),\;P\{ {S_1} = s|{X_1},{S_1}, \cdots ,{X_{n - 1}},{S_{n - 1}},{X_n} = j\}  = p(s|j)
$$
上述类型的模型，其中信号的序列$S_1,S_2,\cdots$被观测到，而潜在的马尔可夫链的状态序列$X_1,X_2,\cdots$是观测不到的，这称为一个隐马尔可夫链模型。


## 指数分布与泊松过程
### 指数分布
指数分布的概率密度函数为
$$
f(x) = \left\{ \matrix{
  \lambda {e^{ - \lambda x}},\quad x \ge 0 \hfill \cr 
  0,\quad \quad \;\;\;x < 0 \hfill \cr}  \right.
$$
均值为$1/\lambda$，方差为$1/\lambda^2$。

**指数随机变量和平均折扣回报**：假设我们自始至终连续地以随机地变化的速率接受报酬。以$R(x)$记在时刻x正在接受报酬的随机速率。对于一个称为折扣率的值$\alpha\ge0$。
$$
R = \int_0^\infty  {{e^{ - \alpha x}}R(x)} dx
$$
表示总折扣报酬。（在某些应用中，$\alpha$称为连续复合利率，而R是无穷报酬流的折现值。）而
$$
E[R] = E\left[ {\int_0^\infty  {{e^{ - \alpha x}}R(x)} dx} \right] = \int_0^\infty  {{e^{ - \alpha x}}E[R(x)]} dx
$$
是平均总折扣报酬，我们将证明它也等于在以$\alpha$为速率的指数分布的随机时间里所得的平均总报酬。
令T是一个以$\alpha$为速率的指数随机变量，它独立于所有的随机变量$R(x)$。我们要论证
$$
\int_0^\infty  {{e^{ - \alpha x}}E[R(x)]} dx = E\left[ {\int_0^T  {R(x)} dx} \right]
$$
为了证明，对于每个$x\ge0$，定义随机变量$I(x)$为
$$
I(x) = \left\{ \matrix{
  1\quad \;x \le T \hfill \cr 
  0\quad x > T \hfill \cr}  \right.
$$
注意到
$$
\int_0^T {R(x)} dx = \int_0^\infty  {R(x)I(x)} dx
$$
于是
$$
\eqalign{
  & E\left[ {\int_0^T {R(x)} dx} \right] = E\left[ {\int_0^\infty  {R(x)I(x)} dx} \right]  \cr 
  &  = \int_0^\infty  {E\left[ {R(x)I(x)} \right]} dx = \int_0^\infty  {E\left[ {R(x)} \right]E\left[ {I(x)} \right]} dx  \cr 
  &  = \int_0^\infty  {E\left[ {R(x)} \right]P\{ T \ge x\} } dx = \int_0^\infty  {{e^{ - \alpha x}}E[R(x)]} dx \cr}
$$
注意到，$P\{ T \ge x\}  = 1 - F(x) = {e^{ - \alpha x}}$。所以，平均总折扣报酬等于在速率等于这个折扣因子时的指数分布的随机时间里所得的平均总（无折扣的）报酬。

**指数分布的无记忆性**：$P\{ X > s + t\}  = P\{ X > s\} P\{ X > t\}$

在一次汽车事故中损失的金额数量是均值为1000的指数随机变量，其中保险公司只赔付超出（可扣除的金额）400的金额。求保险公司赔付事故金额的期望值和标准差。
如果X是由一次事故导致的损失的金额数量，那么保险公司赔付的金额是$(X-400)^+$（其中$a^+$定义为：如果a>0则等于a，如果a≤0则等于0。虽然从第一个原则我们可以肯定地确定$(X-400)^+$的期望值和方差，但是取条件于X是否超过400将更为简便。所以，令
$$
I = \left\{ \matrix{
  1\quad \;X > 400 \hfill \cr 
  0\quad X \le 400 \hfill \cr}  \right.
$$
令$Y=(X-400)^+$是赔付的金额。由指数分布缺乏记忆的性质推出，如果损害的金额超过400，那么它超出400的金额也是均值为1000的指数随机变量。所以
$$
\eqalign{
  & E\left[ {Y|I = 1} \right] = 1000\quad E\left[ {Y|I = 0} \right] = 0  \cr 
  & {\mathop{\rm Var}\nolimits} (Y|I = 1) = {1000^2}\quad {\mathop{\rm Var}\nolimits} (Y|I = 0) = 0 \cr}
$$
可以简写成
$$
E[Y|I] = {10^3}I,\quad {\mathop{\rm Var}\nolimits} (Y|I) = {10^6}I
$$
因为I是以概率$e^{-0.4}$等于1的伯努利随机变量，所以
$$
E[Y] = E[E[Y|I]] = {10^3}E[I] = {10^3}{e^{ - 0.4}} \approx 670.32
$$
由条件方差公式
$$
{\mathop{\rm Var}\nolimits} (Y) = E[{\mathop{\rm Var}\nolimits} (Y|I)] + {\mathop{\rm Var}\nolimits} (E[Y|I]) = {10^6}{e^{ - 0.4}} + {10^6}{e^{ - 0.4}}(1 - {e^{ - 0.4}})
$$
指数分布是无记忆的，而且它是**唯一具有这种性质的分布**。
考察一个具有分布函数F和密度f的连续的正随机变量X。失败（或风险）率函数r(t)定义为
$$
r(t) = {{f(t)} \over {1 - F(t)}}
$$
为了解释r(t)，假设某个具有寿命X的部件已经存活了t小时，并且我们要求它在一个附加时间dt内不存活的概率。即考虑$P\{ X \in (t,t + dt)|X > t\}$。现在
$$
\eqalign{
  & P\{ X \in (t,t + dt)|X > t\}  = {{P\{ X \in (t,t + dt),X > t\} } \over {P\{ X > t\} }}  \cr 
  &  = {{P\{ X \in (t,t + dt)\} } \over {P\{ X > t\} }} \approx {{f(t)dt} \over {1 - F(t)}} = r(t)dt \cr}
$$
即r(t)表示一个年龄为t年的部件损坏的条件概率密度。

### 泊松过程
一个计数过程`N(t)`必须满足：
（1）N(t)≥0
（2）N(t)取整数值
（3）若s<t，则N(s)≤N(t)
（4）对于s<t，N(t)-N(s)表示在区间`(s,t]`中发生的事件的个数
如果发生在不相交的时间区间中的事件的个数是彼此独立的，称计数过程具有**独立增量**。例如，这意味着发生在时刻10以前的事件个数（即 N(10)）必须独立于在时刻10与15之间发生的事件个数（即N(15)-N(10)）。如果在任意时间区间中发生的事件的个数的分布只依赖于时间区间的长度，称计数过程具有**平稳增量**。
**定义5.2**：计数过程$\{N(t),t\ge0\}$称为具有速率$\lambda(\lambda>0)$的泊松过程，如果
（1）N(0)=0
（2）$\{N(t),t\ge0\}$过程有平稳增量和独立增量
（3）$P\{ N(t + h) - N(t) = 1\}  = \lambda h + o(h)$
（4）$P\{ N(t + h) - N(t) \ge 2\}  = o(h)$

**泊松分布的公式**：$P(N(t) = k) = {{{\lambda ^k}} \over {k!}}{e^{ - \lambda }}$
**泊松过程的定义**：$P\{ N(t + s) - N(s) = n\}  = {e^{ - \lambda t}}{{{{\left( {\lambda t} \right)}^n}} \over {n!}}$

#### 到达间隔时间与等待时间的分布
考虑一个泊松过程，我们将第一个事件到达的时间记为$T_1$。此外，对于n >1，以$T_n$记在第n-1个事件与第n个事件之间用去的时间。序列$\{ {T_n},n = 1,2, \cdots \}$称为到达间隔时间列。例如，若$T_1=5$而$T_2=10$，则泊松过程的第一个事件发生在时刻5，而第二个事件发生在时刻15。
现在我们来确定$T_n$的分布，为此，我们首先注意事件$T_1>t$发生当且仅当泊松过程在区间`[0,t]`中没有事件发生，从而
$$
P\{ {T_1} > t\}  = P\{ N(t) = 0\}  = {e^{ - \lambda t}}
$$
因此，$T_1$具有均值为$1/\lambda$的指数分布。现在
$$
P\{ {T_2} > t\}  = E\{ P\{ {T_2} > t|{T_1}\} \}
$$
然而
$$
\eqalign{
  & P\{ {T_2} > t|{T_1} = s\}  = P\{ 0\;{\rm{events}}\;{\rm{in}}\;(s,s + t]|{T_1} = s\}   \cr 
  &  = P\{ 0\;{\rm{events}}\;{\rm{in}}\;(s,s + t]\}   \cr 
  &  = P\{ {N_s}(t) = 0\}  = {e^{ - \lambda t}} \cr}  \tag{5.12}
$$
最后两个等式由独立增量性与平稳增量性得到。所以由方程5.12得出结论：$T_2$也是一个均值为$1/\lambda$的指数随机变量，$T_2$独立于$T_1$。重复上面的论证可以得到下面的命题：
**命题5.2**：$T_n(n=1,2,\cdots)$是独立同分布的指数随机变量，具有均值$1/\lambda$

另一个我们所关注的量是第n个事件到达的时间$S_n$，也称为直到第n个事件的等待时间。容易看出
$$
{S_n} = \sum\limits_{i = 1}^n {{T_i}}
$$
因此由命题5.2的结果推出$S_n$具有参数为n和$\lambda$的伽马分布。即$S_n$的概率密度为
$$
{f_{{S_n}}}(t) = \lambda {e^{ - \lambda t}}{{{{\left( {\lambda t} \right)}^{n - 1}}} \over {\left( {n - 1} \right)!}},\quad t \ge 0  \tag{5.13}
$$

方程(5.13)也可以如下推导，只要注意第n个事件在时刻t前发生当且仅当直到t为止发生事件的个数至少是n，即
$$
N(t) \ge n \Leftrightarrow {S_n} \le t
$$
上式还可以如下推导，只要注意第n个事件在时刻t前发生当且仅当直到t为止发生事件的个数至少是n，即
$$
{F_{{S_n}}}(t) = P\{ {S_n} \le t\}  = P\{ N(t) \ge n\}  = \sum\limits_{j = n}^\infty  {{e^{ - \lambda t}}{{{{\left( {\lambda t} \right)}^j}} \over {j!}}}
$$
对上式求微分即可导出概率密度函数。

考虑一个速率为$\lambda$的泊松过程$\{ N(t),t \ge 0\}$，而且假设每次发生的事件分为Ⅰ型事件和Ⅱ型事件。进一步假设每个事件独立于所有其他事件，以概率p为Ⅰ型事件，以概率1-p为Ⅱ型事件。例如，假设顾客按照速率为$\lambda$的泊松过程到达一个商店，并且假设每个到达的顾客以概率1/2为男性，1/2概率为女性。那么Ⅰ型事件对应于一个男性到达，而Ⅱ型事件对应于一个女性到达。
以$N_1(t)$和$N_2(t)$分别记在`[0,t]`发生的Ⅰ型事件和Ⅱ型事件的个数。$N(t)=N_1(t)+N_2(t)$。
**命题5.3**：$\{N_1(t),t\ge0\}$和$\{N_2(t),t\ge0\}$两者分别是速率为$\lambda p$和$\lambda(1-p)$的泊松过程。此外，这两个泊松过程是彼此独立的。

**例5.14**：如果移民以每星期10人的泊松速率到达A地区，若每个移民是英格兰后裔的概率是1/12，那么在二月份没有英格兰后裔移民到A地区的概率是多少？

在二月份英格兰人移民到A地区的人数是均值为$4\times10\times{1\over 12}={10\over 3}$的泊松分布，因此所需要的概率是
$$
P\{ N(t) = 0\}  = {e^{ - \lambda }} = {e^{ - {{10} \over 3}}} \approx 0.036
$$

**例5.15**：假设购买想出售的部件的非负出价以速率为入的泊松过程到达。假定每次出价是具有密度函数f(x)的随机变量的值。一旦出价提供给你，你必须接受或者拒绝并等待下一个出价。假设部件卖出以前，你以每个单位时间c的速率需要花费，而你的目标是使你的期望总回报最大，其中总回报等于收到的钱的数目减去总的花费价格。假设你使用的策略是接受第一个超过某个特定值y的出价。(这种类型的策略称为y策略，可以证明它是最优的。)y的最优值是多少？

计算使用y策略时的期望总回报，选取y使之最大。以X记一个随机出价的值，以$\bar F(x) = P(X > x) = \int_x^\infty  {f(u)} du$记它的尾分布函数。因为每次出价以概率$\bar F(y)$大于y，这就推出这种出价按速率为$\lambda \bar F(y)$的泊松过程发生（由命题5.3得出）。因此，直到一次出价被接受的时间是一个速率为$\lambda \bar F(y)$的指数随机变量。以R(y)记从接受首次超过y的出价的策略得到的总回报，我们有
$$
\eqalign{
  & E[R(y)] = E[{\rm{accept}}] - cE[{\rm{time}}\;{\rm{to}}\;{\rm{accept}}]  \cr 
  &  = E[X|X > y] - {c \over {\lambda \bar F(y)}}  \cr 
  &  = \int_0^\infty  {x{f_{X|X > y}}(x)} dx - {c \over {\lambda \bar F(y)}}  \cr 
  &  = \int_y^\infty  {x{{f(x)} \over {\bar F(y)}}} dx - {c \over {\lambda \bar F(y)}}  \cr 
  &  = {{\int_y^\infty  {xf(x)} dx - c/\lambda } \over {\bar F(y)}} \cr}
$$
对y求微分可得y的最优值满足
$$
\int_y^\infty  {(x - y)f(x)} dx = {c \over \lambda }
$$
**例5.17（奖劵收集问题）** 有m种不同类型的奖券。独立于过去得到的奖券，某人每次以概率${p_j}\left( {\sum\nolimits_{j = 1}^m {{p_j}}  = 1} \right)$收集一张类型`j`的奖券。以N记他为了每种类型至少有一张的全套收藏所需要收集的奖券的张数。求`E[N]`。

如果我们以$N_j$记得到类型j的奖券必须收集的奖券张数，那么我们可以将N表示为
$$
N = \mathop {\max }\limits_{1 \le j \le m} {N_j}
$$
然而，即使每个$N_j$是以$p_j$为参数的几何随机变量，N的上述表示并非那么有用，因为随机变量$N_j$不是独立的。
然而，我们可以将问题转化为确定独立随机变量的最大值的期望值问题。为此，假设奖券收集的时间是按速率为$\lambda=1$的泊松过程选取的。如果此时得到类型j的奖券，就称这个泊松过程的一个事件为类型$j(1\le j\le m)$。现在我们以$N_j(t)$记在直到时刻t为止收集到的类型j的奖券的张数，那么由命题5.3推出$\{N_j(t),t\ge0\}(j=1,\cdots,m)$是以$\lambda p_j = p_j$为参数的独立的泊松过程。以$X_j$记第j个过程的首个事件的时间，并且令
$$
X = \mathop {\max }\limits_{1 \le j \le m} {X_j}
$$
为收集到全套收藏的时间。因为$X_j$是分别以$p_j$为速率的独立指数随机变量，可以推出
$$
P\{ X < t\}  = P\left\{ {\mathop {\max }\limits_{1 \le j \le m} {X_j} < t} \right\} = \prod\limits_{j = 1}^m {\left( {1 - {e^{ - {p_j}t}}} \right)}
$$
$$
E[X] = \int_0^\infty  {P\{ X > t\} } dt = \int_0^\infty  {\left\{ {1 - \prod\limits_{j = 1}^m {\left( {1 - {e^{ - {p_j}t}}} \right)} } \right\}} dt
$$
我们现在计算在全套收集中只出现一张的类型数的期望。令$I_i$等于1，如果在最后的全套中只有一张奖券i，而在其他情形令它为0。于是我们需要知道
$$
E\left[ {\sum\limits_{i = 1}^m {{I_i}} } \right] = \sum\limits_{i = 1}^m {E\left[ {{I_i}} \right]}  = \sum\limits_{i = 1}^m {P\left\{ {{I_i} = 1} \right\}}
$$
现在，如果每一种类型的奖券在类型i奖券第二次出现前已经出现，那么在最后的全套中将只有一张奖券i。于是，以$S_i$记得到第二张类型i奖券的时间，我们有
$$
P\{ {I_i} = 1\}  = P\{ {X_j} < {S_i},{\rm{for}}\;{\rm{all}}\;j \ne i\}
$$
$S_i$具有参数为$(2,p_i)$的伽马分布，$f_{S_i}(x)=p_ie^{-p_i x}p_i x$
$$
\eqalign{
  & P\{ {I_i} = 1\}  = \int_0^\infty  {P\{ {X_j} < {S_i},{\rm{for}}\;{\rm{all}}\;j \ne i|{S_i} = x\} {p_i}{e^{ - {p_i}x}}{p_i}x} dx  \cr 
  &  = \int_0^\infty  {P\{ {X_j} < x,{\rm{for}}\;{\rm{all}}\;j \ne i\} p_i^2x{e^{ - {p_i}x}}} dx  \cr 
  &  = \int_0^\infty  {\prod\limits_{j \ne i} {\left( {1 - {e^{ - {p_j}x}}} \right)} p_i^2x{e^{ - {p_i}x}}} dx \cr}
$$

#### 到达时间的条件分布
假设被告知直到时间t为止泊松过程的事件恰好发生一个，而我们要确定这个事件发生的时间的分布，现在，由于泊松过程有平稳和独立增量，在`[0,t]`中每个相等长度的区间应该有相同的概率包含这个事件。换句话说，事件发生的时间应该均匀地分布在`[0,t]`上。这是容易检查的，因为对于$s\le t$
$$
\eqalign{
  & P\{ {T_1} < s|N(t) = 1\}  = {{P\{ {T_1} < s,N(t) = 1\} } \over {P\{ N(t) = 1\} }}  \cr 
  &  = {{P\{ 1\;{\rm{event}}\;{\rm{in}}\;[0,s),0\;{\rm{events}}\;{\rm{in}}\;[s,t]\} } \over {P\{ N(t) = 1\} }}  \cr 
  &  = {{P\{ 1\;{\rm{event}}\;{\rm{in}}\;[0,s)\} P\{ 0\;{\rm{events}}\;{\rm{in}}\;[s,t]\} } \over {P\{ N(t) = 1\} }}  \cr 
  &  = {{\lambda s{e^{ - \lambda s}}{e^{ - \lambda (t - s)}}} \over {\lambda t{e^{ - \lambda t}}}} = {s \over t} \cr}
$$
令$Y_1,\cdots,Y_n$是n个随机变量，我们说$Y_{(1)},\cdots,Y_{(n)}$是对应于$Y_1,\cdots,Y_n$的次序统计量，如果$Y_{(k)}$是在$Y_1,\cdots,Y_n$中第k个最小的值。例如，若n=3而$Y_1$=4，$Y_2$=5，$Y_3$=1，则$Y_{(1)}$=1，$Y_{(2)}$=4，$Y_{(3)}$=5。如果$Y_i(i=1,\cdots,n)$是具有概率密度f的独立同分布的连续随机变量，那么次序统计量$Y_{(1)},\cdots,Y_{(n)}$的联合密度为
$$
f({y_1},{y_2}, \cdots ,{y_n}) = n!\prod\limits_{i = 1}^n {f({y_i})} ,\quad {y_1} < {y_2} <  \cdots  < {y_n}
$$
上式的得到是由于
（1）如果$(Y_1,\cdots,Y_n)$等于$(y_1,\cdots, y_n)$的n!个排列中的任意一个，那么$(Y_1,\cdots,Y_n)$将等于$(y_1,\cdots, y_n)$;
（2）当$i_1,\cdots,i_n$是$1,2,\cdots,n$的一个排列时，$(Y_1,\cdots,Y_n)$等于$(y_1,\cdots, y_n)$的概率密度是$\prod\nolimits_{j = 1}^n {f({y_{{i_j}}})}  = \prod\nolimits_{j = 1}^n {f({y_j})}$
如果$Y_i(i=1,\cdots,n)$都在`(0,t)`上均匀分布，那么从前面可得次序统计量$Y_{(1)},\cdots,Y_{(n)}$的联合密度函数是
$$
f({y_1},{y_2}, \cdots ,{y_n}) = {{n!} \over {{t^n}}},\quad 0 < {y_1} < {y_2} <  \cdots  < {y_n} < t
$$
**定理5.2**：给定N(t)=n，n个到达时间$S_1,\cdots,S_n$与n个在`(0,t)`上均匀分布的独立随机变量所对应的次序统计量有相同的分布。
定理5.2可以应用于泊松过程的抽样，在命题5.3中证明了：如果泊松过程的每一个事件被独立地以概率p分类为Ⅰ型事件，以概率1-p分类为Ⅱ型事件，那么Ⅰ型事件和Ⅱ型事件的计数过程是分别以$\lambda p$和$\lambda(1-p)$为速率的相互独立的泊松过程。然而，现在假设有k种可能类型的事件，而一个事件被分类为类型i(i= 1,… ,k)事件的概率依赖于事件发生的时间。特别地，假设若一个事件在时刻y发生，则独立于以前发生的任何事件，它将以概率$P_i(y)(i=1,\cdots,k)$被分类为类型i事件，其中$\sum\nolimits_{i = 1}^k {{P_i}(y)}  = 1$。

**命题5.4**：如果$N_i(t)(i=1,\cdots,k)$表示到时刻t为止i事件发生的个数，那么$N_i(t)(i=1,\cdots,k)$是具有均值
$$
E[{N_i}(t)] = \lambda \int_0^t {{P_i}(s)} ds
$$
的独立泊松随机变量。
命题5.4可用于无穷条服务线的排队问题和不准超车的单车道公路等等。


### 泊松过程的推广
#### 非时齐泊松过程
非时齐泊松过程与泊松过程相比，没有了平稳增量的条件，常量$\lambda$变成了强度函数$\lambda(t)$
定义m(t)为非时齐泊松过程的均值函数
$$
m(t) = \int_0^t {\lambda (y)} dy
$$
**定理5.3**：若$\{ N(t),t \ge 0\}$是强度函数为$\lambda(t)$的非时齐泊松过程，则$\{ N(t + s) - N(s),t \ge 0\}$是泊松随机变量，均值如下
$$
m(t + s) - m(s) = \int_s^{t + s} {\lambda (y)} dy
$$


#### 复合泊松过程

一个随机过程$\{X(t),t\ge0\}$称为复合泊松过程，如果它可以表示为
$$
X(t) = \sum\limits_{i = 1}^{N(t)} {{Y_i}} ,\;t \ge 0
$$
其中$\{N(t),t\ge0\}$是一个泊松过程，而$\{Y_i,i\ge1\}$是独立于$\{N(t),t\ge0\}$的一组独立同分布的随机变量。


#### 条件（混合）泊松过程
令$\{N(t),t\ge0\}$是一个计数过程，其概率定义如下。存在一个正随机变量L，在$L=\lambda$条件下，这个计数过程是速率为$\lambda$的泊松过程。这样的计数过程称为条件（混合）泊松过程。
假设L是具有密度函数g的连续随机变量。因为
$$
\eqalign{
  & P\{ N(t + s) - N(t) = n\}  = \int_0^\infty  {P\{ N(t + s) - N(s) = n|L = \lambda \} g(\lambda )} d\lambda   \cr 
  &  = \int_0^\infty  {{e^{ - \lambda t}}{{{{\left( {\lambda t} \right)}^n}} \over {n!}}g(\lambda )} d\lambda  \cr}
$$
我们看到条件泊松过程有平稳增量。然而，因为知道在一个区间中有多少事件发生给出了有关L的可能值的信息，它影响任意其他区间中的事件个数的分布，由此推出条件泊松过程一般不具有独立增量。因此，一个条件泊松过程一般不是泊松过程。


## 连续时间的马尔可夫链

假设我们有一个取值于非负整数集合的连续时间的随机过程$\{X(t),t\ge0\}$。与第4章中给出的离散时间的马尔可夫链的定义相似，我们说过程$\{X(t),t\ge0\}$是连续时间的马尔可夫链，如果对于一切s，t≥0和非负整数i，j，x(u)，0≤u<s有$P\{ X(t + s) = j|X(s) = i,X(u) = x(u),0 \le u < s\}  = P\{ X(t + s) = j|X(s) = i\}$，换句话说，连续时间的马尔可夫链是具有马尔可夫性质的随机过程，即给定现在X(s)和过去X(u)，0≤u <s，将来X(t＋s)的条件分布只依赖现在并独立于过去。此外，如果
$$
P\{ X(t + s) = j|X(s) = i\}
$$
独立于s，那么这个连续时间的马尔可夫链，称为具有平稳的或者时齐的转移概率。
如果我们以$T_i$记在转移到一个不同的状态以前，过程在状态i停留的时间，对一切$s,t\ge0$
$$
P\{ {T_i} > s + t|{T_i} > s\}  = P\{ {T_i} > t\}
$$
因此，这个随机时间$T_i$是无记忆的，而必须是指数地分布。
事实上，上面的事实给了我们定义连续时间的马尔可夫链的另一个途径。即它是一个具有以下性质的随机过程：每次进入状态i时有
（1）在转移到不同的状态前，它处在这个状态的时间是均值为$1/v_i$的指数随机变量；
（2）当过程离开状态i时，以某个概率$P_{ij}$进入下一个状态j，当然$P_{ij}$必须满足
$$
{P_{ii}} = 0,\quad {\rm{for}}\;{\rm{all}}\;i\quad \quad \sum\limits_j {{P_{ij}}}  = 1,\quad {\rm{for}}\;{\rm{all}}\;i
$$
换句话说，连续时间的马尔可夫链是一个随机过程，它按一个（离散的）马尔可夫链从一个状态运动到另一个状态，但是在进入下一个状态前，停留在每个状态的时间是按指数分布的。此外，过程停留在状态i的时间和下一个访问的状态必须是独立的随机变量。因为如果下一个访问的状态依赖$T_i$，那么过程已经在状态i停留多久的信息将影响下一个状态的预报，而这与马尔可夫性假定矛盾。

### 生灭过程

考虑一个系统，在任意时间它的状态用这个时间在系统中的人数表示。假设只要系统中有n个人，则（1）新到达者以指数速率$\lambda_n$进入系统，而（2）人们以指数速率$\mu_n$离开系统。即只要系统中有n个人，则直到下一个到达的时间是按均值为$1/\lambda_n$指数地分布的，而且独立于直到下一个离开的时间，后者是按均值为$1/\mu_n$指数地分布的。这样的系统称为生灭过程，参数$\{ {\lambda _n}\} _{n = 0}^\infty$和$\{ {\mu _n}\} _{n = 0}^\infty$分别称为到达（或出生）和离开（或灭亡）的速率。
于是，生灭过程是具有状态{0,1,…}的连续时间的马尔可夫链，它从状态n只能转移到状态n-1或者状态n＋1，生灭率和状态转移率与概率的关系是
$$
\eqalign{
  & {v_0} = {\lambda _0}  \cr 
  & {v_i} = {\lambda _i} + {\mu _i}\quad i > 0  \cr 
  & {P_{01}} = 1  \cr 
  & {P_{i,i + 1}} = {{{\lambda _i}} \over {{\lambda _i} + {\mu _i}}}  \cr 
  & {P_{i,i - 1}} = {{{\mu _i}} \over {{\lambda _i} + {\mu _i}}} \cr}
$$
### 时间可逆性

假设现在这个连续时间的马尔可夫过程已经运行了很长的时间，而且假设它开始于某个（很大的）时间T，我们按时间的倒向进行追踪这个过程。为了确定这个逆向过程的概率结构，我们首先注意，给定在某个时刻t处于状态i，已经处在这个状态的时间大于s的概率$e^{-v_is}$。正是这是由于
$$
\eqalign{
  & P\{ {\rm{state}}\;i\;{\rm{throughout}}\;[t - s,t]|X(t) = i\}   \cr 
  &  = {{P\{ {\rm{state}}\;i\;{\rm{throughout}}\;[t - s,t]\} } \over {P\{ X(t) = i\} }}  \cr 
  &  = {{P\{ X(t - s) = i\} {e^{ - {v_i}s}}} \over {P\{ X(t) = i\} }} = {e^{ - {v_i}s}} \cr}
$$
对于大的t，$P\{ X(t - s) = i\}  = P\{ X(t) = i\}  = {P_i}$。
换句话说，按时间倒向地进行，过程在状态i停留的时间也是速率为$v_i$的指数随机变量。此外，逆向过程所访问的状态序列构成一个离散时间的马尔可夫链，其转移概率$Q_{ij}$为
$$
{Q_{ij}} = {{{\pi _j}{P_{ji}}} \over {{\pi _i}}}
$$
因此，我们从上面看到，这个逆向过程是一个连续时间的马尔可夫链，与具有一步转移概率$Q_{ij}$的向前时间过程有相同的转移速率。所以如果嵌入链是时间可逆的，即若
$$
{\pi _i}{P_{ij}} = {\pi _j}{P_{ji}}\quad {\rm{for}}\;{\rm{all}}\;i,j
$$
连续时间的马尔可夫链在时间倒向的过程与原过程有相同的概率结构的意义下，是时间可逆的。

**命题6.5**：一个遍历的生灭过程是时间可逆的

## 更新理论及其应用

我们已经看到泊松过程是一个计数过程，它的相继事件之间的时间是有相同指数分布的独立随机变量。一种可能的推广是考虑一个计数过程，其两次相继事件之间的时间是独立同分布的随机变量。这样的计数过程，称为**更新过程**。

令$\{N(t),t\ge0\}$是一个计数过程，而以$X_n$记这个过程的第n-1个和第n个事件之间的时间，n≥1。
**定义7.1**：如果非负随机变量列${X_1,X_2,\cdots}$是独立同分布的，那么计数过程$\{N(t),t\ge0\}$称为**更新过程**。

于是一个更新过程是一个计数过程，其直到第一次事件发生的时间有某个分布F，第一个和第二个事件之间的时间独立于第一个事件的时间，并且有同样的分布F，以此类推，当一个事件发生时，我们说发生了更新。

举一个更新过程的例子。假设我们有无穷多个灯泡，它们的寿命是独立同分布的。再假设在某个时间我们使用一个灯泡，而当它失效时，就立刻换上一个新的。在这些条件下，用N(t)表示直到时刻t为止失效的灯泡个数，则$\{N(t),t\ge0\}$是一个更新过程。
对于到达间隔时间为${X_1,X_2,\cdots}$的一个更新过程，令
$$
{S_0} = 0,{S_n} = \sum\limits_{i = 1}^n {{X_i}} ,n \ge 1
$$
即$S_1=X_1$是第一次更新的时间，$S_2=X_1+X_2$是第一次更新加上第一次和第二次更新的间隔，即第二次更新的时间。我们将以F记到达间隔分布，而为了避免平凡情形，我们假定$F(0)=P\{X_n=0\}<1$，此外，令
$$
\mu  = E[{X_n}],\quad n \ge 1
$$
是相继更新之间的平均时间。由$X_n$的非负性并且$X_n$不恒等于0推出$\mu>0$。
我们想要回答的第一个问题是，在总量为有限的时间中，是否可能有无穷多个事件发生。即对于t的某个（有限的）值，N(t)能否是无穷？为了说明这不可能发生，首先注意到，因为$S_n$是第n次更新的时间，故N(t)可以写成
$$
N(t) = \max \{ n:{S_n} \le t\}  \tag{7.1}
$$
为了弄明白方程(7.1)为什么成立，假设$S_4\le t$，但是$S_5>t$。因此，第4次更新已经在时刻t之前发生，但是第5次更新在t后面发生，或者换句话说，在时刻t之前发生的更新次数N(t)必须等于4。现在，利用强大数定律，由此推出以概率1有
$$
{{{S_n}} \over n} \to \mu ,\quad n \to \infty
$$
但是，由于$\mu>0$，这意味着，当$n\to\infty$时，$S_n$必须趋于无穷，于是，至多只有有限个n，使$S_n$小于等于t，因此，由方程(7.1)推出N(t)必须有限。
然而，虽然对于每个t，$N(t)<\infty$，下面以概率1成立
$$
N(\infty ) \equiv \mathop {\lim }\limits_{t \to \infty } N(t) = \infty
$$
这是由于发生的更新总数$N(\infty)$可能是有限的唯一途经，是到达间隔之一是无穷的。所以
$$
\eqalign{
  & P\{ N(\infty ) < \infty \}  = P\{ {X_n} = \infty ,\exists n\}   \cr 
  &  = P\left\{ {\bigcup\limits_{n = 1}^\infty  {\{ {X_n} = \infty \} } } \right\} \le \sum\limits_{n = 1}^\infty  {P\{ {X_n} = \infty \} }  = 0 \cr}
$$
### N(t) 的分布

N(t) 的分布至少在理论上可以得到，首先注意下面的重要关系：时刻 t 之前的更新个数大于或等于 n当且仅当第 n 次更新发生在时刻t之前或在时刻 t。即
$$
N(t) \ge n \Leftrightarrow {S_n} \le t   \tag{7.2}
$$
从方程(7.2)得到
$$
\eqalign{
  & P\{ N(t) = n\}  = P\{ N(t) \ge n\}  - P\{ N(t) \ge n + 1\}   \cr 
  &  = P\{ {S_n} \le t\}  - P\{ {S_{n + 1}} \le t\}  \cr} \tag{7.3}
$$
现在由于随机变量$X_i(i\ge 1)$是独立的，而且有共同的分布F，由此推出$S_n=\sum_{i=1}^nX_i$与$F_n$（F和它自己的n次卷积）同分布。所以，从方程(7.3)我们得到
$$
P\{ N(t) = n\}  = {F_n}(t) - {F_{n + 1}}(t)
$$
到达间隔分布可以是几何分布、指数分布、均匀分布等。
利用方程(7.2)还可以计算N(t)的均值$m(t)$
$$
\eqalign{
  & m(t) = E[N(t)] = \sum\limits_{k = 1}^\infty  {N(t)P\{ N(t) = k\} }   \cr 
  &  = \sum\limits_{k = 1}^\infty  {\sum\limits_{n = 1}^k {P\{ N(t) = k\} } }  = \sum\limits_{n = 1}^\infty  {\sum\limits_{k = n}^\infty  {P\{ N(t) = k\} } }   \cr 
  &  = \sum\limits_{n = 1}^\infty  {P\{ N(t) \ge n\} }  = \sum\limits_{n = 1}^\infty  {P\{ {S_n} \le t\} }  = \sum\limits_{n = 1}^\infty  {{F_n}(t)}  \cr}
$$
函数$m(t)$是均值函数，即更新函数。

### 极限定理及其应用
上面我们已经证明了，当t趋于无穷时，N(t)以概率1趋于无穷。然而，如果知道N(t)趋于无穷的速率就更好了。即我们更想知道有关$\mathop {\lim }\limits_{t \to \infty } {{N(t)} \over t}$的情况。

**命题7.1**：依概率1有
$$
\mathop {\lim }\limits_{t \to \infty } {{N(t)} \over t} \to {1 \over \mu }
$$
由于$S_{N(t)}$是早于或等于时刻t的最后的更新时间，而$S_{N(t)+1}$是时刻t后的第一个更新时间，所以有
$$
{S_{N(t)}} \le t < {S_{N(t) + 1}}
$$
从而
$$
{{{S_{N(t)}}} \over {N(t)}} \le {t \over {N(t)}} < {{{S_{N(t) + 1}}} \over {N(t)}}
$$
而${S_{N(t)}}/N(t) = \sum\nolimits_{i = 1}^{{N(t)}} {{X_i}} /N(t)$是$N(t)$个独立同分布的随机变量的平均值，由强大数定律推出当$N(t)\to\infty$时，$S_{N(t)}/N(t)\to\mu$。但是，因为当$t\to\infty$时，$N(t)\to\infty$，所以
$$
\mathop {\lim }\limits_{t \to \infty } {{{S_{N(t)}}} \over {N(t)}} \to \mu
$$
同理
$$
{{{S_{N(t) + 1}}} \over {N(t)}} = {{{S_{N(t) + 1}}} \over {N(t) + 1}}{{N(t) + 1} \over {N(t)}}
$$
>（1）即使更新间隔的平均时间u等于无穷时，上面的命题也正确。在这种情形，$1/\mu$为0；
（2）数 $1/\mu$称为**更新过程的速率**；
（3）因为在更新间隔的平均时间是$\mu$，显然，每$\mu$个时间单位发生更新的平均速率为1。

**定理7.1（基本更新定理）**
$$
\mathop {\lim }\limits_{t \to \infty } {{m(t)} \over t} \to {1 \over \mu }
$$

### 更新报酬过程
大量的概率模型是下述模型的特殊情形。考虑到达间隔时间$X_n(n\ge 1)$的更新过程$\{N(t),t \ge 0\}$，并且假设每次更新发生时我们接受一个报酬。以$R_n$记在第n次更新时得到的报酬。假定$R_n(n\ge 1)$独立同分布，然而，我们允许$R_n$可以依赖于（而通常是依赖于）第n个更新区间的长度$X_n$。如果我们令
$$
R(t) = \sum\limits_{n = 1}^{N(t)} {{R_n}}
$$
那么$R(t)$表示到时刻t为止赚到的全部报酬。令
$$
E[R] = E[{R_n}],\quad E[X] = E[{X_n}]
$$
**命题7.3**：如果$E[R]<\infty$且$E[X]<\infty$，有
（1）依概率1，$\mathop {\lim }\limits_{t \to \infty } {{R(t)} \over t} = {{E[R]} \over {E[X]}}$
（2）$\mathop {\lim }\limits_{t \to \infty } {{E[R(t)]} \over t} = {{E[R]} \over {E[X]}}$
>（1）如果每发生一次更新，就说完成一个循环，那么命题7.3说明单位时间的长程平均报酬，等于在一个循环中赚到的期望报酬除以一个循环的期望长度。
（2）虽然我们假设了报酬是在更新的时间赚到的，当报酬是在整个循环逐步赚到时，结果仍然成立。

**例7.14（汽车购买模型）**：汽车的寿命是一个具有分布H和概率密度h的连续的随机变量。布朗先生使用一个策略是，一旦他的车坏了或者用了T年，他就购买一辆新车。假设一辆新车的价格为$C_1$美元，而且只要布朗先生的车坏了就招致一个附加花费$C_2$美元。在用过的车没有再卖的价值的假定下，布朗先生的长程平均费用是多少？
如果每次布朗先生买一辆新车（坏了就会买新车，但是坏了再买会有一个额外的费用），我们就说完成了一个循环，那么从命题7.3推出（用价格替代报酬）他的长程平均花费等于
$$
{{E[{\rm{cost}}\;{\rm{incurred}}\;{\rm{during}}\;{\rm{a}}\;{\rm{cycle}}]} \over {E[{\rm{length}}\;{\rm{of}}\;{\rm{a}}\;{\rm{cycle}}]}}
$$
现在令X是在一个任意的循环中布朗先生的车的寿命，那么在这个循环中招致的费用将由
$$
\eqalign{
  & {C_1},\quad X > T  \cr 
  & {C_1} + {C_2},\quad X \le T \cr}
$$
表示。所以，在一个循环上招致的期望费用是
$$
{C_1}P\{ X > T\}  + \left( {{C_1} + {C_2}} \right)P\{ X \le T\}  = {C_1} + {C_2}H(T)
$$
同样，循环的长度为
$$
\eqalign{
  & X\quad X \le T  \cr 
  & T\quad X > T \cr}
$$
所以一个循环的期望长度是
$$
\int_0^T {xh(x)} dx + \int_T^\infty  {Th(x)} dx = \int_0^T {xh(x)} dx + T[1 - H(T)]
$$
于是，布朗先生的长程平均费用是
$$
{{{C_1} + {C_2}H(T)} \over {\int_0^T {xh(x)} dx + T[1 - H(T)]}}
$$
**例7.15（火车发车）**：假设旅客按到达间隔时间的均值为$\mu$的一个更新过程到达某火车站。一旦有N个乘客等候在火车站，就发出一辆火车。如果火车站在有n个乘客等待时会招致速率为每个单位时间$nc$美元的费用，问火车站招致的平均费用是多少？
如果发出一辆火车，我们就说完成了一个循环，那么上面的是一个更新报酬过程。一个循环的期望长度是需要到达N个乘客的期望时间，而由于到达间隔时间的均值为$\mu$，它等于
$$
E[{\rm{length}}\;{\rm{of}}\;{\rm{a}}\;{\rm{cycle}}] = N\mu
$$
如果我们以$T_n$记在一个循环中第n个到达者与第n+1个到达者之间的时间，那么一个循环中的期望费用可以表示为
$$
E[{\rm{cost}}\;{\rm{incurred}}\;{\rm{during}}\;{\rm{a}}\;{\rm{cycle}}] = E[c{T_1} + 2c{T_2} +  \cdots  + (N - 1)c{T_{N - 1}}]
$$
由于$E[T_n]=\mu$，它等于${{N\left({N - 1} \right)c \mu} \over 2}$
因此，火车站招致的平均费用是
$$
{{N\left( {N - 1} \right)c\mu } \over {2N\mu }} = {{\left( {N - 1} \right)c} \over 2}
$$

### 再生过程
考虑一个状态空间为$0,1,2,...$的随机过程{X(t),t ≥ 0}，它具有如下的性质：存在一些（随机的）时间点使过程（概率地）在这些点重新开始。即假设以概率1存在一个时间$T_1$，使这个过程的时间超过$T_1$的部分是从0出发的整个过程的概率复制品。注意，这个性质表明存在更多的时间$T_2,T_2,\cdots$与$T_1$有同样的性质。这样的随机过程，称为再生过程。

由上面推出$T_2,T_2,\cdots$构成一个更新过程的到达时间，每当一个更新出现，我们就说完成了一个循环。
（1）一个更新过程是再生的，而$T_1$表示首次更新的时间；
（2）一个常返的马尔可夫链是再生的，而$T_1$表示首次转移回初始状态的时间。


### 半马尔可夫过程
现在我们将上述结果推广到以下的情况。假设一个过程可以处在N个状态$1,2,\cdots,N$中的任意一个，而且在每一个状态i保持一个具有均值$\mu_i$的随机时间，然后以概率$P_{ij}$转移到状态j。这样的过程称为半马尔可夫过程。注意如果过程在转移以前在每一个状态停留的时间恒等于1，那么这样的半马尔可夫过程正是马尔可夫链。


### 检验悖论
假设一个设备（例如电池）被装配使用直至它损坏。在损坏时，立刻用一个相似的电池替代以使这个过程不中断地继续。以N(t)记到时刻t为止损坏的电池数，则$\{N(t),t\ge0\}$是一个更新过程。
进一步假设电池寿命的分布F是未知的，需要用以下的样本检查方案来估计。我们固定某个t，并观察在时刻t使用的电池的总寿命。由于F是所有电池的寿命分布，似乎它也应该是这个电池的寿命分布。然而，这是一个检验悖论，因为它导出在时刻t正在使用的电池倾向于有比普通的电池更长的寿命。
>为了得到所谓的检验悖论，推理如下：我们想象整个直线被更新区间覆盖，其中一个包含点t。覆盖点t的区间相比于较短的区间是不是更像一个较大的区间？

### 计算更新函数
使用恒等式
$$
m(t) = \sum\limits_{n = 1}^\infty  {{F_n}(t)}
$$
计算更新函数是困难的，确定$F_n(t)=P\{X_1+\cdots+X_n\le t\}$需要n重积分，下面介绍一个有效算法，该算法只需要一维积分作为输入。
令Y是一个速率为$\lambda$的指数随机变量，而且假设Y与更新过程$\{N(t),t \ge 0\}$独立。我们先确定到随机时间Y为止的期望更新次数`E[N(Y)]`。为此我们先对首次更新的时间$X_1$取条件，这就得到
$$
E[N(Y)] = E[E[N(Y)|{X_1}]] = \int_0^\infty  {E[N(Y)|{X_1}]f(x)} dx   \tag{7.30}
$$
其中f是到达间隔密度。为了确定$E[N(Y)|X_1=x]$，我们对Y是否超出x取条件。现在，如果Y<x，那么因为首次更新发生在时刻x，就推出到时刻Y为止的更新次数等于0。另一方面，如果我们给出了x<Y，那么到时刻Y为止的更新次数等于1（在x的那一个）加上在x与Y之间的附加更新次数。但是，由指数随机变量的无记忆性质推出，给定Y>x。它超过x的数量也是速率为$\lambda$的指数随机变量。所以给定Y>x，在x与Y之间的更新次数与N(Y)同分布。因此
$$
\eqalign{
  & E[N(Y)|{X_1} = x,Y < x] = 0  \cr 
  & E[N(Y)|{X_1} = x,Y > x] = 1 + E[N(Y)] \cr} 
$$
所以
$$
\eqalign{
  & E[N(Y)|{X_1} = x] = E[N(Y)|{X_1} = x,Y < x]P\{ Y < x|{X_1} = x\}   \cr 
  &  + E[N(Y)|{X_1} = x,Y > x]P\{ Y > x|{X_1} = x\}   \cr 
  &  = \left( {1 + E[N(Y)]} \right)P\{ Y > x\} \quad Y{\rm{ and}}\;{X_1}\;{\rm{are independent}}  \cr 
  &  = \left( {1 + E[N(Y)]} \right){e^{ - \lambda x}} \cr}
$$
代入(7.30)可得
$$
E[N(Y)] = \left( {1 + E[N(Y)]} \right)\int_0^\infty  {{e^{ - \lambda x}}f(x)} dx
$$
即
$$
E[N(Y)] = {{E[{e^{ - \lambda X}}]} \over {1 - E[{e^{ - \lambda X}}]}}  \tag{7.31}
$$
其中X为更新到达间隔分布。

如果令$\lambda=1/t$，那么方程(7.31)给出了（不是直到t为止，而是）直到一个具有均值t的随机指数分布时间为止的平均更新次数的表达式。然而，因为这样的随机变量未必近似于它的均值（它的方差是$t^2$），方程(7.31)就未必特别地近似m(t)。为了得到一个精确的近似，假设$Y_1,\cdots, Y_n$是速率为$\lambda$的独立指数随机变量，而且假设它们也独立于更新过程。对于$r=1,\cdots,n$，令
$$
{m_r} = E[N({Y_1} +  \cdots  + {Y_r})]
$$
为了算得$m_r$的表达式，我们也先对首次更新的时间$X_1$取条件
$$
{m_r} = \int_0^\infty  {E[N({Y_1} +  \cdots  + {Y_r})|{X_1} = x]f(x)} dx  \tag{7.32}
$$
此时考虑部分和$\sum\nolimits_{i = 1}^j {{Y_i}} (j = 1, \cdots ,r)$中小于x的个数取条件。如果所有的r个部分和都小于x，那么显然知道$\sum\nolimits_{i = 1}^j {{Y_i}}$为止的更新次数是0。另一方面，如果给定$k(k<r)$个部分和都小于x，有指数随机变量的无记忆性推出，直到$\sum\nolimits_{i = 1}^j {{Y_i}}$为止的更新次数将与1加上$N(Y_{k+1}+\cdots+Y_r)$有相同的分布，因此
$$
\eqalign{
  & E\left[ {N({Y_1} +  \cdots  + {Y_r})|{X_1} = x,k\;{\rm{of}}\;{\rm{the}}\;{\rm{sums}}\sum\nolimits_{i = 1}^j {{Y_i}} \;{\rm{are}}\;{\rm{less}}\;{\rm{than}}\;x} \right]  \cr 
  &  = \left\{ \matrix{
  0\quad \quad \quad \;\;k = r \hfill \cr 
  1 + {m_{r - k}}\quad k < r \hfill \cr}  \right. \cr}  \tag{7.33}
$$
为确定小于x的部分和的个数的分布，注意到部分和$\sum\nolimits_{i = 1}^j {{Y_i}} (j = 1, \cdots ,r)$中相继的值与速率为$\lambda$的泊松过程的前r个事件的时间有相同的分布（由于每个相继的部分和是前面的和加上一个独立的速率为$\lambda$的指数随机变量）。由此推出，对于k<r，
$$
P\left\{ {k\;{\rm{of}}\;{\rm{the}}\;{\rm{sums}}\sum\nolimits_{i = 1}^j {{Y_i}} \;{\rm{are}}\;{\rm{less}}\;{\rm{than}}\;x|{X_1} = x} \right\} = {{{e^{ - \lambda x}}{{\left( {\lambda x} \right)}^k}} \over {k!}}  \tag{7.34}
$$
将方程(7.33)和方程(7.34)代入方程(7.32)，得到
$$
{m_r} = \int_0^\infty  {\sum\limits_{k = 0}^{r - 1} {\left( {1 + {m_{r - k}}} \right)} {{{e^{ - \lambda x}}{{\left( {\lambda x} \right)}^k}} \over {k!}}f(x)} dx
$$
或者，等价地
$$
{m_r} = {{\sum\limits_{k = 1}^{r - 1} {\left( {1 + {m_{r - k}}} \right)E[{X^k}{e^{ - \lambda X}}]\left( {{\lambda ^k}/k!} \right) + E[{e^{ - \lambda X}}]} } \over {1 - E[{e^{ - \lambda X}}]}}   \tag{7.35}
$$
先通过公式(7.31)求出$m_1$，再利用公式(7.35)进行迭代求解。



## 可靠性理论


## 布朗运动与平稳过程

### 布朗运动
本章首先讨论对称随机游动，对称随机游动在每个单位时间等可能地向左或向右走一个单位的一步。就是说，这是一个具有$P_{i,i-1}=P_{i,i+1}={1\over 2}$的马尔可夫链。现在假设通过在越来越小的时间区间取越来越小的步长来加快这个过程，如果我们现在以正确的方式趋于极限，得到的就是布朗运动。
更确切地说，假设每个$\Delta t$时间单位等概率地向左或向右移动大小为$\Delta x$的一步。如果以X(t)记在时刻t的位置，那么
$$
X(t) = \Delta x\left( {{X_1} +  \cdots  + {X_{[t/\Delta t]}}} \right)
$$
其中
$$
{X_i} = \left\{ \matrix{
   + 1 \hfill \cr 
   - 1 \hfill \cr}  \right.
$$
**定义10.1**：如果
（1）$X(0)=0$；
（2）$\{X(t),t\ge 0\}$有平稳独立的增量
（3）对于任意$t>0$，$X(t)$是均值为0，方差为$\sigma^2t$的正态随机变量
那么称随机过程$\{X(t),t\ge 0\}$为布朗运动过程。

### 击中时刻、最大随机变量和赌徒破产问题

以$T_a$记布朗运动首次击中a的时刻。当a>0时，我们通过考虑P{X(t)≥a}（X(t)是t时刻的位置）并取条件于是否有$T_a\le t$来计算$P\{T_a\le t\}$，这给出
$$
\eqalign{
  & P\{ X(t) \ge a\}  = P\{ X(t) \ge a|{T_a} \le t\} P\{ {T_a} \le t\}   \cr 
  &  + P\{ X(t) \ge a|{T_a} > t\} P\{ {T_a} > t\}  \cr}   \tag{10.5}
$$
现在如果$T_a\le t$，那么过程在`[0,t]`的某个点击中a，由对称性，它等可能地或者比a大或者比a小。即
$$
P\{ X(t) \ge a|{T_a} \le t\}  = {1 \over 2}
$$
方程(10.5)右边的第二项显然等于0（因为由连续性，过程的值不可能还没有击中a而大于a）。方程(10.5)等价于
$$
\eqalign{
  & P\{ X(t) \ge a\}  = {1 \over 2}P\{ {T_a} \le t\}   \cr 
  & P\{ {T_a} \le t\}  = 2P\{ X(t) \ge a\}   \cr 
  &  = {2 \over {\sqrt {2\pi t} }}\int_a^\infty  {{e^{ - {x^2}/2t}}} dx = {2 \over {\sqrt {2\pi } }}\int_{a/\sqrt t }^\infty  {{e^{ - {y^2}/2}}} dy,\quad a > 0 \cr}
$$
对于a<0，由对称性，$T_a$的分布与$T_{-a}$的分布相同，因此可得到
$$
P\{ {T_a} \le t\}  = {2 \over {\sqrt {2\pi } }}\int_{\left| a \right|/\sqrt t }^\infty  {{e^{ - {y^2}/2}}} dy,\quad a > 0
$$
另一个重要的随机变量是过程在`[0,t]`中达到的最大值，它的分布如下：对于a>0
$$
P\left\{ {\mathop {\max }\limits_{0 \le s \le t} X(s) \ge a} \right\} = P\{ {T_a} \le t\}  = {2 \over {\sqrt {2\pi } }}\int_{a/\sqrt t }^\infty  {{e^{ - {y^2}/2}}} dy
$$
第一个等式是因为连续性（最大值大于a，那么布朗运动击中a）

我们现在考虑布朗运动在击中-B前先击中A的概率，其中A>0，B>0。为了计算它，我们利用将布朗运动解释为对称随机游动的极限。回忆[赌徒破产问题](#赌徒破产问题)的结果，当每一步或者增加或者减少一个距离$\Delta x$时，对称随机游动在减少到B前先增加到A的概率，$N=(A+B)/\Delta x$，$i=B/\Delta x$等于$B\Delta x/(A + B)\Delta x = B/(A + B)$
因此，令$\Delta x\to 0$，得到
$$
P\{ {\rm{up}}\;A\;{\rm{before}}\;{\rm{down}}\;B\}  = {B \over {A + B}}
$$

### 布朗运动的变形
#### 漂移布朗运动
我们称随机过程$\{X(t),t\ge 0\}$是漂移系数为$\mu$和方差参数为$\sigma^2$的布朗运动，如果
（1）$X(0)=0$；
（2）$\{X(t),t\ge 0\}$有平稳独立的增量；
（3）$X(t)$是均值为$\mu t$，方差为$\sigma^2t$的正态分布。
一个等价定义是令$\{B(t),t\ge 0\}$的标准布朗运动，然后定义
$$
X(t) = \sigma B(t) + \mu t
$$


#### 几何布朗运动
如果$\{Y(t),t\ge 0\}$是漂移系数为$\mu$和方差参数为$\sigma^2$的布朗运动，那么由
$$
X(t) = {e^{Y(t)}}
$$
定义的过程$\{X(t),t\ge 0\}$称为几何布朗运动。

### 股票期权的定价
对于在不同时期收到或者支付钱的情形，我们必须考虑到钱的时间价值。就是说，在将来时刻t得到的钱v，不如立刻得到的钱v值钱。原因在于，如果我们立刻得到钱v，那么它可以带利息地贷出，从而在时刻t比v更值钱。为了考虑这些，我们假设在时刻t赚得钱的数量v在时刻0的价值（也称为现值）是$ve^{-\alpha t}$。量$\alpha$常称为折现因子。在经济学的术语中，折现函数$e^{-\alpha t}$的假定，等价于假定我们可以在单位时间赚取$100\alpha$%的连续复利率。
假设对于任意y，我们可以在时刻0以价格cy购买期权，以便在时刻1以每股150美元的价格购买y股股票。那么，若你确实购买了这个期权，而且股票升值为200美元，则你将在时刻1行使这个期权，且在所购买的y股期权单位中的每一股赚得200-150=50美元。另一方面，若在时刻1的价格降到50美元，则这个期权在时刻1没有价值。此外，你可以在时刻0以价格100x购买x个单位的股票，它在时刻1的价值，或者是200x美元，或者是50x美元。
我们假设x或y都可以为正也可以为负（或者0）。就是说，你可以购进或者卖出股票或期权。例如，若x是负的则你将卖出-x股股票，导致你有-100x的回报，而你负责在时刻1以每股50美元或者200美元购进-x股股票。
我们有兴趣确定期权合适的单位价格c。特别地，我们将证明，除非c=50/3，将总有一个购买的组合能得到正的获利。
假设在时刻0我们购进x单位股票，购进y单位期权。其中x和y（它们可以或者正，或者负）待定。在时刻1，我们持有的价值依赖股票的价格，它由下式给出
$$
{\rm{value}} = \left\{ \matrix{
  200x + 50y\quad {\rm{if}}\;{\rm{price}}\;{\rm{is}}\;200 \hfill \cr 
  50x\quad \quad \quad \quad {\rm{if}}\;{\rm{price}}\;{\rm{is}}\;50 \hfill \cr}  \right.
$$
上面的公式成立是因为，注意到若股票价格是200，则x单位股票值200x，而y单位的期权的价值是(200-150)y。另一方面，若股票价格是50，则x单位股票值50x，而y单位期权没有价值。现在假设不管在时刻1股票的价格是什么，我们总选取y使上面的两个值相同。就是说，我们选取y使得
$$
200x + 50y = 50x \Rightarrow y =  - 3x
$$
（注意y的符号与x相反，所以若x是正，作为结果，x单位的股票在时刻0购进，则3x单位的股票期权在同时卖出。类似地，若x是负，则-x单位的股票在时刻0卖出，而-3x单位的股票期权在时刻0购进。）
于是，由y=-3x，在时刻1我们持有的价值是
$$
{\rm{value}} = 50x
$$
因为原来购买x单位股票和-3x单位期权的价格是
$$
{\rm{original}}\;{\rm{cost}} = 100x - 3xc
$$
我们看到，在交易中我们的获利是
$$
{\rm{gain}} = 50x - (100x - 3xc) = x(3c - 50)
$$
若3c=50，则获利为0，若$3c\neq 50$，则我们可以保证有一个正的获利。
一定赢的下注方案称为**套利**。

#### 套利定理
考虑一个试验，其可能结果的集合是$S = \{ 1,2, \cdots ,m\}$，假设有n种赌注。如果试验的结果为j，而以金额x下注于赌注i时，则赚得回报$xr_i(j)$。换句话说，$r_i(\cdot)$是每个单位下注于赌注i的回报函数。在一个赌注上的下注金额允许或是正，或是负，或是0。
**定理10.1（套利定理）**：以下恰有一条是正确的：
（1）存在一个概率向量${\bf{p}} = ({p_1}, \cdots ,{p_m})$，使得
$$
\sum\limits_{j = 1}^m {{p_j}{r_i}(j)}  = 0,\quad {\rm{for}}\;{\rm{all}}\;i = 1, \cdots ,n
$$
（2）存在一个下注方案${\bf{x}} = ({x_1}, \cdots ,{x_n})$，使得
$$
\sum\limits_{i = 1}^n {{x_i}{r_i}(j)}  > 0,\quad {\rm{for}}\;{\rm{all}}\;j = 1, \cdots ,n
$$
>这个定理是(线性代数中的)分离超平面的定理的推论，它常用作证明线性规划对偶定理的一个技巧。

#### 布莱克—斯科尔斯期权定价公式
假设股票现在的价格是$X(0)=x_0$，且以$X(t)$记它在时刻t的价格，假设我们有兴趣于时间区间0到T的股票。假定折现因子是$\alpha$（等价于利率是$100\alpha$%的连续复利），所以在时刻t股票价格的现值是$e^{-\alpha t}X(t)$。
现在考虑购买一个期权的赌注，假设这个期权给我们在时刻t以价格K购买一股股票的权利。
期权的定价为
$$
c = {x_0}\phi (\sigma \sqrt t  + b) - K{e^{ - \alpha t}}\phi (b)
$$
其中
$$
b = {{\alpha t - {\sigma ^2}t/2 - \ln (K/{x_0})} \over {\sigma \sqrt t }}
$$

### 漂移布朗运动的最大值
对具有漂移系数$\mu$和方差参数$\sigma^2$的布朗运动$\{X(y),y\ge0\}$，定义
$$
M(t) = \mathop {\max }\limits_{0 \le y \le t} X(y)
$$
为过程直至时刻t的最大值。
我们要通过推导在给定$X(t)$的值时$M(t)$的条件分布，来确定$M(t)$的分布。


### 白噪声
以$\{X(t),t\ge0\}$记标准布朗运动，且令f为在区间`[a,b]`有连续导数的一个函数，定义随机积分$\int_a^b {f(t)} dX(t)$如下：
$$
\int_a^b {f(t)} dX(t) = \mathop {\mathop {\lim }\limits_{n \to \infty } \sum\limits_{i = 1}^n {} }\limits_{\max ({t_i} - {t_{i - 1}}) \to 0} f({t_{i - 1}})\left[ {X({t_i}) - X({t_{i - 1}})} \right]   \tag{10.15}
$$
其中$a=t_0<t_1<\cdots<t_n=b$是区间`[a,b]`的一个划分。利用恒等式（分部积分应用于和）
$$
\eqalign{
  & \sum\limits_{i = 1}^n {f({t_{i - 1}})\left[ {X({t_i}) - X({t_{i - 1}})} \right]}   \cr 
  &  = f(b)X(b) - f(a)X(a) - \sum\limits_{i = 1}^n {X({t_i})\left[ {f({t_i}) - f({t_{i - 1}})} \right]}  \cr}
$$
我们看到
$$
\int_a^b {f(t)} dX(t) = f(b)X(b) - f(a)X(a) - \int_a^b {X(t)} df(t)  \tag{10.16}
$$
通过利用方程(10.16)的右边，在假定期望与极限的可交换的情况下，我们得到
$$
E\left[ {\int_a^b {f(t)} dX(t)} \right] = 0
$$
同样
$$
\eqalign{
  & {\mathop{\rm Var}\nolimits} \left( {\sum\limits_{i = 1}^n {f({t_{i - 1}})\left[ {X({t_i}) - X({t_{i - 1}})} \right]} } \right) = \sum\limits_{i = 1}^n {{f^2}({t_{i - 1}}){\mathop{\rm Var}\nolimits} (X({t_i}) - X({t_{i - 1}}))}   \cr 
  &  = \sum\limits_{i = 1}^n {{f^2}({t_{i - 1}})\left( {{t_i} - {t_{i - 1}}} \right)}  \cr} 
$$
其中第一个等式来自布朗运动的独立增量性质，因此，我们在上式中取极限，由方程(10.15)得到
$$
{\mathop{\rm Var}\nolimits} \left( {\int_a^b {f(t)} dX(t)} \right) = \int_a^b {{f^2}(t)} dt
$$
注上面给出了一族量$\{dX(t),0 \le t < \infty\}$的运算含义，将它看成作用到函数f得到值${\int_a^b {f(t)} dX(t)}$的一个算子。这称为**白噪声变换**，或者更为一般地，$\{dX(t),0 \le t < \infty\}$称为白噪声，因为它可以想象为一个时变函数f在白噪声的介质中传播导致(在时间b的)一个输出${\int_a^b {f(t)} dX(t)}$。


### 高斯过程
**定义10.2**：随机过程$\{X(t),t\ge0\}$称为高斯过程，或者正态过程，如果对于一切$t_1,\cdots,t_n$，$X(t_1),\cdots,X(t_n)$具有多维正态分布。
如果$\{X(t),t\ge0\}$是布朗运动过程，那么因为$X(t_1),\cdots,X(t_n)$中的每一个都可以表示为独立的正态随机变量$X(t_1),X(t_2)-X(t_1),\cdots, X(t_n)-X(t_{n-1})$的线性组合，由此推出布朗运动是高斯过程。
令$\{X(t),t\ge0\}$是一个标准布朗运动，且考虑在0与1之间取条件于X(1)=0的过程值。即考虑条件随机过程$\{X(t),0\le t\le 1|X(1)=0\}$。由于$X(t_1),\cdots,X(t_n)$的条件分布是多维正态分布，由此推出这个条件过程是一个高斯过程，称为**布朗桥**（因为它在时间0和1都被系住了）。布朗桥的协方差函数为
$$
{\mathop{\rm Cov}\nolimits} \left( {(X(s),X(t))|X(1) = 0} \right) = s(1 - t)
$$
**命题10.1**：如果$\{X(t),t\ge0\}$是一个标准布朗运动，那么当$Z(t)=X(t)-tX(1)$时，$\{Z(t),t\ge0\}$是一个标准布朗桥过程。

### 平稳和弱平稳过程
一个随机过程$\{X(t),t\ge 0\}$称为平稳过程，如果对于一切n，s，$t_1,\cdots,t_n$，随机变量$X(t_1),\cdots,X(t_n)$和$X(t_1+s),\cdots,X(t_n+s)$有相同的联合分布。换句话说，一个过程是平稳的，如果在选取任意固定点s作为原点，过程都有相同的概率规律。平稳过程的两个例子是：
（1）一个遍历的连续时间马尔可夫链$\{X(t),t\ge 0\}$，当
$$
P\{ X(0) = j\}  = {P_j},\quad j \ge 0
$$
其中$\{P_j,j\ge 0\}$是极限概率。
（2）$\{X(t),t\ge 0\}$，当$X(t)=N(t+L)-N(t),t\ge0$，其中L>0是一个固定的常数，而$\{N(t),t\ge 0\}$是一个速率为$\lambda$的泊松过程。
一个过程是平稳过程的条件是相当严格的，所以如果E[X(t)]= c，且Cov(X(t),X(t+s))不依赖t，我们定义一个过程$\{X(t),t\ge 0\}$是二阶平稳或者弱平稳过程。即如果X(t)的前两个矩对于一切t都相同，且X(s)与X(t)的协方差只依赖于|t-s|，则一个过程是二阶平稳的。
因为高斯过程的有限维分布（是多维正态）由它们的均值和协方差确定，由此推出一个二阶平稳的高斯过程是平稳过程。

### 弱平稳过程的调和分析
假设随机过程$\{ X(t), - \infty  < t < \infty \}$和$\{ Y(t), - \infty  < t < \infty \}$的联系如下：
$$
Y(t) = \int_{ - \infty }^\infty  {X(t - s)h(s)} ds  \tag{10.21}
$$
我们可以想象一个在时刻t的值是X(t)的信号，通过一个物理系统将它的值变形为在时刻t收到的由方程(10.21)给出的值Y(t)。过程{X(t)}和{Y(t)}分别称为输入过程和输出过程，函数h称为脉冲响应函数。如果当s<0，h(s)= 0，那么h也称为一个加权函数，由于方程(10.21)将t的输出表示为所有早于t的输入的加权积分，以h(s)表示给定s单位时间前的输入权重。

**例题**：
$B(s)+B(t)(s\le t)$的分布是什么
$$
B(s) + B(t) = 2B(s) + B(t) - B(s)
$$
其中$2B(s)$的方差为4s，$B(t)-B(s)$的方差为$t-s$，因为$B(s)$和$B(t)-B(s)$不相关，所以$B(s)+B(t)$的方差为4s+t-s=3s+t。（注意不能认为$B(s)$和$B(t)$不相关，不能认为方差为s+t）


## 模拟
以${\bf{X}} = ({X_1}, \cdots ,{X_n})$记一个具有密度函数$f({x_1}, \cdots ,{x_n})$的随机向量，并且假设对于某个n维函数g，我们想计算
$$
E[g({\bf{X}})] = \int {\int { \cdots \int {g({x_1}, \cdots ,{x_n})f({x_1}, \cdots ,{x_n})} d{x_1}d{x_2} \cdots } } d{x_n}
$$
例如，当X的值代表前`[n/2]`个到达间隔和服务时间时，g可能代表在队列中前`[n/2]`个顾客的总延迟时间。在许多情况下，我们不可能解析地准确计算上述的多重积分，甚至不可能在给定的精度之内用数值逼近。剩下的一种可能就是用模拟的手段逼近`E[g(X)]`。
为了逼近`E[g(X)]`，首先生成一个具有联合密度函数$f({x_1}, \cdots ,{x_n})$的随机向量${{\bf{X}}^{(1)}} = (X_1^{(1)}, \cdots ,X_n^{(1)})$，然后计算${Y^{(1)}} = g({{\bf{X}}^{(1)}})$。再生成第二个随机向量（与第一个独立）${{\bf{X}}^{(2)}}$，并计算${Y^{(2)}} = g({{\bf{X}}^{(2)}})$。继续这样做，直至已经生成r（一个固定的数）个独立同分布的随机变量${Y^{(i)}} = g({{\bf{X}}^{(i)}})(i = 1, \cdots ,r)$为止。由强大数定律我们知道
$$
\mathop {\lim }\limits_{r \to \infty } {{{Y^{(1)}} +  \cdots  + {Y^{(r)}}} \over r} = E[{Y^{(i)}}] = E[g({\bf{X}})]
$$
从而我们可以用生成的Y的平均作为`E[g(X)]`的一个估计，这种估计`E[g(X)]`方法，称为蒙特卡罗模拟方法。生成随机数的方法可以参见数值分析的随机数和应用。

**例11.2（在很大的列表中不同条目个数的估计）**：考虑有n个条目的一个列表，其中n非常大，假设我们有兴趣估计这个表中不同元素的个数d。如果将在位置i的元素在此列表中出现的次数记为$m_i$，那么我们可以将d表示为
$$
d = \sum\limits_{i = 1}^n {{1 \over {{m_i}}}}
$$
为了估计d，假设我们生成了等可能地是$1,2,\cdots,n$之一的一个随机值$X=[nU]+1$，而后以m(X)记在位置X的元素在列表中出现的次数，那么
$$
E\left[ {{1 \over {m(X)}}} \right] = \sum\limits_{i = 1}^n {{1 \over {{m_i}}}{1 \over n}}  = {d \over n}
$$
因此，如果生成了k个这样的随机变量$X_1,\cdots,X_k$，那么可以用
$$
d \approx {{n\sum\limits_{i = 1}^k {{1 \over {m({X_i})}}} } \over k}
$$

### 模拟连续随机变量的一般方法

#### 逆变换方法

**命题11.1**：令U是一个(0,1)上的均匀随机变量。对于任意连续分布函数F，如果我们定义随机变量X为
$$
X = {F^{ - 1}}(U)
$$
那么随机变量X有分布函数F。
证明：
$$
{F_X}(a) = P(X \le a) = P({F^{ - 1}}(U) \le a)
$$
由于$F(x)$是单调函数，由此推出${F^{ - 1}}(U) \le a$当且仅当$U\le F(a)$。因此
$$
{F_X}(a) = P({F^{ - 1}}(U) \le a) = P(U \le F(a)) = F(a)
$$
因此，当$F^{-1}$可计算时，可以通过模拟一个随机数U，然后置$X = {F^{ - 1}}(U)$由一个连续分布F来模拟随机变量X。注意当$U$是一个(0,1)上的均匀随机变量，有以下的结论
$$
P(U \le F(a)) = {F_U}(F(a)) = \int_0^1 {F(a)} du = F(a)
$$

#### 拒绝法
假设我们有办法模拟一个具有密度函数g(x)的随机变量。对模拟出具有密度f(x)的连续分布函数的随机变量，我们可以以此为基础，通过模拟出自g的随机变量Y，然后以比例f(Y)/g(Y)的概率接受这个模拟值。
特别地，令c是一个常数，使得
$$
{{f(y)} \over {g(y)}} \le c\quad {\rm{for}}\;{\rm{all}}\;y
$$
那么，我们用下述技术模拟出具有密度f的连续分布函数的随机变量。
**拒绝法**
步骤1：模拟具有密度g的随机变量Y，并且模拟一个随机数U。
步骤2：如果$U \le {{f(Y)} \over {cg(Y)}}$，那么置X=Y。否则返回步骤1。
**命题11.2**：由拒绝法生成的随机变量X具有密度f。
令X是得到的值，而以N记必需重复的次数。那么
$$
\eqalign{
  & P\{ X \le x\}  = P\{ {Y_N} \le x\}   \cr 
  &  = P\{ Y \le x|U \le f(Y)/cg(Y)\}   \cr 
  &  = {{P\{ Y \le x,U \le f(Y)/cg(Y)\} } \over K}  \cr 
  &  = {{\int {P\{ Y \le x,U \le f(Y)/cg(Y)|Y = y\} g(y)} dy} \over K}  \cr 
  &  = {{\int_{ - \infty }^x {\left( {f(y)/cg(y)} \right)g(y)} dy} \over K} = {{\int_{ - \infty }^x {f(y)} dy} \over {Kc}} \cr} 
$$
其中$K = P\{ U \le f(Y)/cg(Y)\}$。令$x\to\infty$，表明$K=1/c$，证明完成。

#### 风险率方法
令F是连续的分布函数且$\bar F(0) = 1$。由
$$
\lambda (t) = {{f(t)} \over {\bar F(t)}},\quad t \ge 0
$$
可以定义F的风险率函数$\lambda(t)$（其中$f(t)=F'(t)$是密度函数）。$\lambda(t)$表示给定已经存活到时刻t的一个寿命分布为F的物体在时刻t失效的瞬时概率强度。
现在假设我们给定了一个有界函数$\lambda(t)$，使得$\int_0^\infty  {\lambda (t)} dt = \infty$，我们要求模拟一个以$\lambda(t)$为风险率函数的随机变量S。
为此取$\lambda$使得
$$
\lambda (t) \le \lambda ,\quad {\rm{for}}\;{\rm{all}}\;t \ge 0
$$
为了由$\lambda(t)(t\ge0)$模拟，我们将
（1）模拟一个具有速率$\lambda$的泊松过程。我们将只“接受”或“计数”某种泊松事件。特别地，我们将
（2）独立于其他的一切，以概率$\lambda(t)/\lambda$计数一个在t发生的事件。

**命题11.3**：第一个被计数的事件的时间（记为S）是一个随机变量，其分布有风险率函数$\lambda(t),t\ge0$。
$$
\eqalign{
  & P\{ t < S < t + dt|S > t\}   \cr 
  &  = P\{ {\rm{first}}\;{\rm{counted}}\;{\rm{event}}\;{\rm{in}}\;(t,t + dt)|{\rm{no}}\;{\rm{counted}}\;{\rm{events}}\;{\rm{prior}}\;{\rm{to}}\;t\}   \cr 
  &  = P\{ {\rm{Poisson}}\;{\rm{event}}\;{\rm{in}}\;(t,t + dt),{\rm{it}}\;{\rm{is}}\;{\rm{counted}}|{\rm{no}}\;{\rm{counted}}\;{\rm{events}}\;{\rm{prior}}\;{\rm{to}}\;t\}   \cr 
  &  = P\{ {\rm{Poisson}}\;{\rm{event}}\;{\rm{in}}\;(t,t + dt),{\rm{it}}\;{\rm{is}}\;{\rm{counted}}\}   \cr 
  &  = [\lambda dt + o(dt)]{{\lambda (t)} \over \lambda } = \lambda (t)dt + o(dt) \cr}
$$
倒数第二个等式来自泊松过程的独立增量性质。

生成S：$\lambda_S(t)$=$\lambda(t)$的风险率方法
取$\lambda$使得对于一切t≥0有$\lambda (t) \le \lambda$。生成随机变量列对$U_i,X_i,i\ge 1$，使得$X_i$是速率为$\lambda$的指数随机变量，而$U_i$是(0,1)均匀随机变量，停止在
$$
N = \min \left\{ {n:{U_n} \le \lambda \left( {\sum\limits_{i = 1}^n {{X_i}} } \right)/\lambda } \right\}
$$
置
$$
S = \sum\limits_{i = 1}^N {{X_i}}
$$
因为N的定义，可以得到事件N=n独立于$X_{n+1},X_{n+1},\cdots$，因此，由瓦尔德方程
$$
E[S] = E[N]E[{X_i}] = {{E[N]} \over \lambda }
$$
从而
$$
E[N] = \lambda E[S]
$$
其中$E[S]$是所需的随机变量的均值。

### 模拟连续随机变量的特殊方法

#### 正态分布

**极坐标方法**
步骤1：生成随机数$U_1$和$U_2$；
步骤2：令$V_1=2U_1-1$，$V_2=2U_2-1$，$S=V_1^2+V_2^2$；
步骤3：若S>1，则返回步骤1；
步骤4：得到独立标准正态随机变量
$$
X = \sqrt {{{ - 2\ln S} \over S}} {V_1},\quad Y = \sqrt {{{ - 2\ln S} \over S}} {V_2}
$$

#### 伽马分布
为了对参数为$(n,\lambda)$的伽马分布模拟，其中n是整数，我们利用n个速率为$\lambda$的独立整数随机变量的和也具有这样分布的事实。因此，若$U_1,\cdots,U_n$是独立的(0,1)均匀随机变量，则
$$
X =  - {1 \over \lambda }\sum\limits_{i = 1}^n {\ln {U_i}}  =  - {1 \over \lambda }\ln \left( {\prod\limits_{i = 1}^n {{U_i}} } \right)
$$
具有所要的分布。


#### 卡方分布
参见原书P553页

#### 贝塔分布（$\beta(n,m)$分布）
参见原书P553页

#### 指数分布—冯洛伊曼算法
参见原书P554页


### 离散分布的模拟
所有从连续分布模拟的一般方法在离散情形都有其对应的版本。例如，如果我们要模拟一个具有概率质量函数
$$
P\{ X = {x_j}\}  = {P_j},\quad j = 1,2, \cdots ,\quad \sum\limits_j {{P_j}}  = 1
$$
的随机变量X。我们可以用逆变换技术的如下的离散版本：

为了模拟具有$P\{ X = {x_j}\}  = P_j$的X，令U在(0,1)上均匀地分布，且令
$$
X = \left\{ \matrix{
  {x_1},\quad {\rm{if}}\;U < {P_1} \hfill \cr 
  {x_2},\quad {\rm{if}}\;{P_1} < U < {P_1} + {P_2} \hfill \cr 
   \vdots  \hfill \cr 
  {x_j},\quad {\rm{if}}\;\sum\limits_{i = 1}^{j - 1} {{P_i}}  < U < \sum\limits_{i = 1}^j {{P_i}}  \hfill \cr 
   \vdots  \hfill \cr}  \right.
$$
因为
$$
P\{ X = {x_j}\}  = P\left\{ {\sum\limits_{i = 1}^{j - 1} {{P_i}}  < U < \sum\limits_{i = 1}^j {{P_i}} } \right\} = {P_j}
$$
还有一种建模较为复杂，但是运行较快的算法—别名方法，具体参见原书P559-561页。


### 随机过程

介绍了模拟泊松过程、非时齐泊松过程、二维泊松过程等的方法

### 方差缩减技术

令$X_1,\cdots,X_n$有给定的联合分布，并且假设我们想计算
$$
\theta  = E[g({X_1}, \cdots ,{X_n})]
$$
其中g是某个给定的函数。经常出现的情形是我们不可能解析地计算上式，而在这种情形,我们可以试图利用模拟来估计$\theta$。做法如下：生成与$X_1,\cdots,X_n$有相同的联合分布的$X_1^{(1)},\cdots,X_n^{(1)}$，并令
$$
{Y_1} = g(X_1^{(1)}, \cdots ,X_n^{(1)})
$$
继续计算$Y_2,\cdots,Y_n$，可以将$\bar Y = \sum\limits_{i = 1}^k {{Y_i}/k}$作为$\theta$的估计值，方差为$E\left[ {{{\left( {\bar Y - \theta } \right)}^2}} \right]$。
介绍了三种用于缩减估计方差的一般技术。

#### 对偶变量的应用
当g是单调函数，可以降低方差。具体做法为
两次运用随机变量$U_1,\cdots,U_n$的每个集合的对偶变量方法，利用先计算$g\left( {F_1^{ - 1}({U_1}), \cdots ,F_n^{ - 1}({U_n})} \right)$，然后计算$g\left( {F_1^{ - 1}(1 - {U_1}), \cdots ,F_n^{ - 1}(1 - {U_n})} \right)$，就会减少估计$E[g({X_1}, \cdots ,{X_n})]$的方差。就是说，不用生成n个随机数的k个集合，我们应该生成k/2个集合，并且每个集合使用两次（以$U$的形式计算一次，以$1-U$的形式计算一次）。
#### 通过取条件缩减方差
由条件方差公式
$$
{\mathop{\rm Var}\nolimits} (Y) = E[{\mathop{\rm Var}\nolimits} (Y|Z)] + {\mathop{\rm Var}\nolimits} (E(Y|Z))
$$
所以有
$$
{\mathop{\rm Var}\nolimits} (E(Y|Z)) \le {\mathop{\rm Var}\nolimits} (Y)
$$
又$E[E[Y|Z]]=E[Y]$，所以对于估计$E[Y]$而言，$E[Y|Z]$比Y更好。

#### 控制变量
同样假设我们要用模拟来估计$E[g(X)]$，其中${\bf{X}} = ({X_1}, \cdots ,{X_n})$。但是现在假设对于某个f，$f(\bf{X})$的期望值已知（例如$E[f({\bf{X}}))] = \mu$）。那么，对于任意常数a，我们也可以用
$$
W = g({\bf{X}}) + a\left( {f({\bf{X}}) - \mu } \right)
$$
作为$E[g(X)]$的估计。其中a的取值如下
$$
a = {{ - {\mathop{\rm Cov}\nolimits} (f({\bf{X}}),g({\bf{X}}))} \over {{\mathop{\rm Var}\nolimits} (f({\bf{X}}))}}
$$

### 确定运行的次数
估计的精确度可以用方差度量
$$
{\mathop{\rm Var}\nolimits} ({{\bar Y}_r}) = E\left[ {{{\left( {{{\bar Y}_r} - \mu } \right)}^2}} \right] = {{{\sigma ^2}} \over r}
$$
因此，我们要选取必需的运行次数r足够大，以使得$\sigma^2/r$小得可以接受。然而，困难在于$\sigma^2$事先是未知的。为了得到它，你应该最初模拟k次（其中k≥30），然后用模拟值${Y^{(1)}}, \cdots ,{Y^{(k)}}$通过样本方差
$$
\sum\limits_{i = 1}^k {{{\left( {{Y^{(i)}} - {{\bar Y}_k}} \right)}^2}/(k - 1)}
$$
来估计$\sigma^2$。


### 马尔可夫链的平稳分布的生成

考虑一个状态为$1,\cdots,m$且转移概率为$P_{i,j}$的不可约马尔可夫链，并且假设我们要生成一个随机变量的值，这个随机变量的分布是这个马尔可夫链的平稳分布。尽管我们能够近似地生成这样的随机变量，通过任意选取一个初始状态，对一个固定大的时间周期个数，模拟这个马尔可夫链,然后选取最后的状态作为这个随机变量的值。但是如果我们想生成一个随机变量，其分布精确地是平稳分布，可以使用**过去耦合法**（原书P584页）。

如果马尔可夫链满足下面的性质，对于某个称为0的状态，存在一个正数$\alpha$，使得对于一切状态i都有
$$
{P_{i,0}} \ge \alpha  > 0
$$
即，无论当前状态，下一个状态是0的概率至少是某个正值$\alpha$。
此时可以使用**另一种方法**（原书P585页）。

