
## 小知识

1. numpy 的数据按行存储，pandas 的数据按列存储，pandas的按行读取 iloc 比按列读取慢很多，而numpy按列和按行读取都很快
2. parquet 一种按列存储的二进制数据格式，可以使用 pandas 的 `to_parquet` 转换

3. NoSQL（Not only SQL）是一种非关联型数据库，主要包括文档模型和图模型。文档模型的目标用例一般数据来自自包含的文档，并且文档之间的联系很少。图模型则相反，目标是数据项之间的关系常见且重要的用例。


## 训练数据

### 采样数据

水塘采样：从流数据中采样 k 个数据，具体方法先将前 k 个数据放在水塘（采样的数据）中，为对于第 n 个到来的数据 `x`，随机生成一个 `[1, n]` 的数，如果这个数 `i` 位于 `[1, k]` 之间，那么就将水塘中第 `i` 个数替换为 `x`。


### 标记数据

当给数据做标记时，需要注意跟踪数据的来源，防止某一批标记不准确的数据干扰整体数据集。

下面介绍在没有高质量标签的情况下的几种技术：

**弱监督**：Snorkel 是一种基于标记函数（labeling function，LF）的开源工具，可以为无标注数据添加低质量的标注，LF 通过数据中的一些关键信息进行标注，每个数据样本都会被多个LF进行标注，然后结合这些LF的标注来获得最可能的标签。为了观察LF的效果，推荐包含一部分人工标注的数据。如果LF可以完美标注数据，那么还需要机器学习模型吗，答案是需要，因为需要模型泛化到其它没有被LF覆盖到的数据。

**半监督**：半监督基于一小部分有标签数据来生成新的标签。一种经典的半监督方法是自训练，先在一小部分数据上训练模型，然后用这个模型来在未标注的数据预测，将最大概率的数据加入训练中，这样重复操作直到模型达到满意的结果。另一种方法是假设类似结构的数据有着类似的标签，可以使用kmeans聚类来对样本进行聚类。还有一种流行的方法是对比学习。

**迁移学习**

**主动学习**：不是随机的标记样本，而是选择性的标记对模型最有帮助的样本，最直接的方法是标记模型最不确定的样本。先随机标记一些样本，训练模型，在未标记的样本进行测试，标记那些模型最不确定的样本。还有一种方法是训练一组模型，每个模型都对样本进行一次标记，然后人工标记那些争议最大的样本。主动学习可以用在实时数据上。



### 类别不平衡


下面介绍三种解决类别不平衡的方法：

**使用合适的评价标准**：如为每个类都计算一次准确率，使用召回率等


**重采样**：从数量较小的类别中采样更多的数据，从数量较多的类别中采样更少的数据。但是这种方法容易欠拟合数量较多的类别，而过拟合数量较少的类别。一种方法是，先在重采样的数据上（对于数量较多的类别，只选取一部分样本）进行训练，再在原始数据上微调。还有一种动态采样方法，[Dynamic Sampling in Convolutional Neural Networks for Imbalanced Data Classification | IEEE Conference Publication | IEEE Xplore](https://ieeexplore.ieee.org/document/8396983)

**修改算法（损失函数）**：1. 设置一个cost矩阵 $C_{ij}$ 来衡量第 i 个类被判成第 j 个类的损失加权值，其中 $C_{ii} = 0$。2. 类别平衡损失，为每个类设置一个权重 $W_i$，$W_i$ 为样本总数 / 类别样本数，3. focal loss，即将原本的交叉熵损失 $L=-\log(p_t)$ 改为 $L=-(1-p_t)^{\gamma}\log(p_t)$。


**数据增强**：


## 特征工程



### 常用特征工程操作



**缺失值处理**


**特征归一化**：例如将每个特征都进行归一化到 `[0, 1]` 区间，或者归一化到 `[a, b]` 区间

$$
\bar x = a + {{\left( {x - \min (x)} \right)(b - a)} \over {\max (x) - \min (x)}}
$$

**离散化**：将连续值量化，例如将连续值分成一个个小区间。

**编码类别特征**：为每个类别生成一个哈希值（Vowpal Wabbit），但是可能会遇到两个类别用着相同的哈希值

**特征交叉**：将两个和多个特征结合生成新的特征

**离散和连续位置嵌入**：参考Transformer中的位置嵌入


### 数据泄露

数据泄露不仅指在训练时使用了测试集的数据，还有另一种更难发现的情况，如一个模型训练的数据来自一个更先进的机器的测量结果，而实际上模型面对的数据可能来自另一个普通机器的测量结果，而模型没有这个普通机器的信息，因此模型训练时，标签实际上泄露了数据的信息。

数据泄露的一些原因：
1. 随机分割时序数据（应该按照时间分割数据），如预测股票股价，将前6天的数据作为训练集，第7天的数据用来验证。
2. 在分割之前进行scaling（应该在分割之后再进行scaling）
3. 使用测试集中的信息填补空缺数据（同样在分割之后再进行填补）
4. 在分割前没有处理好重复数据
5. 组泄露：如果一组数据有着强相关的标签，但是被分到不同的数据集中。
6. 数据收集时的泄露，如只收集一台机器产生的数据来训练和测试，解决这种泄露需要随机的收集数据。

归一化数据可以使得不同数据源的数据有着相同的均值和方差，一定程度上避免了数据泄露。

检查数据泄露：衡量每个特征与标签的相关程度，甚至是不同特征组合与标签的相关程度。做消融分析来衡量每个特征的重要程度

### 好的特征工程

特征泛化：如果一个特征只出现在很少的一部分数据中，那么这可能不是一个好的特征。此外如果一个特征值只出现在训练集而不出现在测试集，那么也不是一个好的特征（如训练集只收集周一到周六的数据，测试集是周日的数据，那么周几这个特征就不是一个好的特征，因为对于测试集，只有周日，而没有周一到周六）

## 模型开发


### 模型建模


如果一个模型有两个目标函数（并且这两个目标函数均有实际的意义），如

$$
L = \alpha L_1+\beta L_2
$$
如果直接用这个目标函数训练网络，那么如果 $\alpha$ 和 $\beta$ 有变动，就需要重新训练模型。为了避免这一问题，可以分别用 $L_1$ 和 $L_2$ 训练模型，然后将两个模型的输出相结合得到最终结果。


### 模型开发和训练

**模型集成**：训练多个模型（一般这些模型的结构不同）集成得到结果。有三种方式来创建一个模型集成

1. Bagging：对于一个数据集，有放回地采样来创建多个数据集，对于每个数据集都训练一个模型
2. Boosting：Boosting是一类迭代集成算法，Boosting中的样本被分配不同的权重，下一个学习器更加关注上一个学习器错分的样本。首先在数据集训练一个弱分类器，根据分类准确率来为样本设置权重（错分的样本设置更高的权重），在加权的数据集上训练第二个分类器，此时集成有两个分类器，根据这两个分类器的分类结果来为数据集重新分配权重，再用重分配权重的数据集训练第三个分类器，重复下去，最后的分类器为这些分类器的结合。算法有：Gradient Boosting Machine，xgboost等
3. Stacking：训练多个模型，将模型预测结果作为一个元学习器（可以是一个简单的逻辑回归模型）的输入，进行再一次学习。



